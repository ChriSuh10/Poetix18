{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generated_line_dictionary(in_paths, poem_type):\n",
    "    lines = {'keyword': [],\n",
    "             'line1': [],\n",
    "             'line2': [],\n",
    "             'line3': [],\n",
    "             'line4': [],\n",
    "             'line5': [],\n",
    "             'score': []}\n",
    "    for in_path in in_paths:\n",
    "        in_txt = open(in_path, 'rb')\n",
    "\n",
    "        counter = 0\n",
    "        # We only write to csv if it is the first poem in the \n",
    "        for line in in_txt:\n",
    "            line = line.rstrip().decode('utf-8')\n",
    "            # Process keyword\n",
    "            if len(line.split(':')) == 2:\n",
    "                category, data = line.split(':')\n",
    "                if category == 'prompt':\n",
    "                    lines['keyword'].append(data)\n",
    "                elif category == 'score':\n",
    "                    lines['score'].append(data)\n",
    "            # Write line to dictionary\n",
    "            elif len(line) >= 5:\n",
    "                # Process line\n",
    "                line = line.strip()\n",
    "                line = line[0].upper() + line[1:]\n",
    "                lines['line' + str(counter+1)].append(line)\n",
    "                counter += 1\n",
    "                counter %= 5\n",
    "    poem_count = len(lines['line1'])\n",
    "    lines['type'] = [poem_type] * poem_count\n",
    "    print(\"Dictionary created with \" + str(poem_count) + \" poems\")\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_line_dictionary(in_paths, poem_type):\n",
    "    lines = {'line1': [],\n",
    "             'line2': [],\n",
    "             'line3': [],\n",
    "             'line4': [],\n",
    "             'line5': []}\n",
    "    for in_path in in_paths:\n",
    "        in_txt = open(in_path, 'rb')\n",
    "\n",
    "        counter = 0\n",
    "        for line in in_txt:\n",
    "            line = line.rstrip().decode('utf-8')\n",
    "            if len(line) < 5 or len(line.split()) == 1:\n",
    "                continue\n",
    "            lines['line' + str(counter+1)].append(line)\n",
    "            counter += 1\n",
    "            counter %= 5\n",
    "    poem_count = len(lines['line1'])\n",
    "    lines['type'] = [poem_type] * poem_count\n",
    "    print(\"Dictionary created with \" + str(poem_count) + \" poems\")\n",
    "    return lines\n",
    "\n",
    "def print_single_poem(poem_dict, index):\n",
    "    for key in poem_dict:\n",
    "        print(poem_dict[key][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary created with 98 poems\n",
      "Dictionary created with 79 poems\n",
      "Dictionary created with 95 poems\n",
      "Dictionary created with 58 poems\n",
      "------EXAMPLE------\n",
      "holiday\n",
      "There was a bright grandma named Laure\n",
      "Who spent all her money in a store.\n",
      "It was for her birthday,\n",
      "But it was the last day,\n",
      "So she gave up and drank on the shore.\n",
      "-2.763656878110134\n",
      "DTS_STORY\n"
     ]
    }
   ],
   "source": [
    "# HUMAN = create_line_dictionary(['py_files/saved_objects/limericks.txt'], 'HUMAN')\n",
    "# BEST_GENERATED_POEM = create_line_dictionary(['py_files/saved_objects/curated_poems.txt'], 'GENERATED')\n",
    "\n",
    "DTS_NO_STORY = create_generated_line_dictionary(['automatic_no_story.txt'], 'DTS_NO_STORY')\n",
    "DTS_STORY = create_generated_line_dictionary(['automatic_story.txt'], 'DTS_STORY')\n",
    "SINGLE_NO_STORY = create_generated_line_dictionary(['baseline_automatic_no_story.txt'], 'SINGLE_NO_STORY')\n",
    "SINGLE_STORY = create_generated_line_dictionary(['baseline_automatic_story.txt'], 'SINGLE_STORY')\n",
    "\n",
    "print(\"------EXAMPLE------\")\n",
    "print_single_poem(DTS_STORY, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poem_list(dictionary, index, batch):\n",
    "    return [[dictionary[key][i] for key in dictionary] for i in range(index, index + batch)]\n",
    "\n",
    "def export_poetic_measure_experiment(batch, DTS_NO_STORY, DTS_STORY, SINGLE_NO_STORY, SINGLE_STORY, name=\"\"):\n",
    "    length = min(len(DTS_NO_STORY['line1']), len(DTS_STORY['line1']), len(SINGLE_NO_STORY['line1']), len(SINGLE_STORY['line1']))\n",
    "    index = 0\n",
    "    while index + batch <= length:\n",
    "        poem_list = get_poem_list(DTS_NO_STORY, index, batch) + get_poem_list(DTS_STORY, index, batch) + \\\n",
    "                    get_poem_list(SINGLE_NO_STORY, index, batch) + get_poem_list(SINGLE_STORY, index, batch)\n",
    "        random.shuffle(poem_list)\n",
    "        index += batch\n",
    "        out_path = 'csv/poetic_measure_'+ name + str(int(index/batch)) + '.csv'\n",
    "        df = DataFrame(poem_list, columns= ['keyword', 'line1', 'line2', 'line3', 'line4', 'line5', 'score', 'type'])\n",
    "        export_csv = df.to_csv (out_path, index = None, header=True)\n",
    "\n",
    "def export_turing_test_experiment(batch, HUMAN, GENERATED, name=\"\"):\n",
    "    length = min(len(HUMAN['line1']), len(GENERATED['line1']))\n",
    "    index = 0\n",
    "    while index + batch <= length:\n",
    "        poem_list = get_poem_list(HUMAN, index, batch) + get_poem_list(GENERATED, index, batch)\n",
    "        random.shuffle(poem_list)\n",
    "        index += batch\n",
    "        out_path = 'csv/turing_test_'+ name + str(int(index/batch)) + '.csv'\n",
    "        df = DataFrame(poem_list, columns= ['line1', 'line2', 'line3', 'line4', 'line5', 'type'])\n",
    "        export_csv = df.to_csv (out_path, index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_poetic_measure_experiment_new(DTS_NO_STORY, DTS_STORY, SINGLE_NO_STORY, SINGLE_STORY, name=\"\"):\n",
    "    reorganized_poems = defaultdict(list)\n",
    "    for poem_dict in [DTS_NO_STORY, DTS_STORY, SINGLE_NO_STORY, SINGLE_STORY]:\n",
    "        for i in range(len(poem_dict['line1'])):\n",
    "            reorganized_poems[poem_dict['keyword'][i]].append([poem_dict[key][i] for key in poem_dict])\n",
    "    output_poems = {}\n",
    "    \n",
    "    for keyword in reorganized_poems:\n",
    "        if len(reorganized_poems[keyword]) == 4:\n",
    "            output_poems[keyword] = reorganized_poems[keyword]\n",
    "            \n",
    "    output_poem_list = []\n",
    "    for keyword in output_poems:\n",
    "        poems = []\n",
    "        for i in random.sample([0,1,2,3],4):\n",
    "            poems += output_poems[keyword][i]\n",
    "        output_poem_list.append(poems)\n",
    "        \n",
    "    column_names = []\n",
    "    for i in range(1, 5):\n",
    "        column = [str(i) + '_' + n for n in ['keyword', 'line1', 'line2', 'line3', 'line4', 'line5', 'score', 'type']]\n",
    "        column_names += column\n",
    "\n",
    "    out_path = 'csv/poetic_measure_'+ name + '.csv'\n",
    "    df = DataFrame(output_poem_list, columns= column_names)\n",
    "    export_csv = df.to_csv (out_path, index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_poetic_measure_experiment_new(DTS_NO_STORY, DTS_STORY, SINGLE_NO_STORY, SINGLE_STORY,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_poetic_measure_experiment(5, DTS_NO_STORY, DTS_STORY, SINGLE_NO_STORY, SINGLE_STORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_turing_test_experiment(5, HUMAN, BEST_GENERATED_POEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = min(len(DTS_NO_STORY['line1']), len(DTS_STORY['line1']), len(SINGLE_NO_STORY['line1']), len(SINGLE_STORY['line1']))\n",
    "export_poetic_measure_experiment(length, DTS_NO_STORY, DTS_STORY, SINGLE_NO_STORY, SINGLE_STORY, \"complete_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = min(len(HUMAN['line1']), len(BEST_GENERATED_POEM['line1']))\n",
    "export_turing_test_experiment(length, HUMAN, BEST_GENERATED_POEM, \"complete_\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
