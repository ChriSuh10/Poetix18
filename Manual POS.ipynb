{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful links\n",
    "https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "https://sites.google.com/site/partofspeechhelp/home#TOC-IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggle if you don't have GPT-2/its dependencies\n",
    "use_gpt = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "if use_gpt:\n",
    "    from gpt2.src.encoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load local version of dicts\n",
    "with open('py_files/saved_objects/postag_dict_all.p', 'rb') as f:\n",
    "    postag = pickle.load(f)\n",
    "    \n",
    "pos_to_words = postag[1]\n",
    "words_to_pos = postag[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads latest copy of words that have been checked\n",
    "checked = set()\n",
    "checked_this_session = set()\n",
    "with open('data/checked_words.txt') as f:\n",
    "    for w in f:\n",
    "        checked.add(w.strip('\\n'))\n",
    "\n",
    "if use_gpt:\n",
    "    enc = get_encoder('117M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was a mania\n",
      "There was a benefit\n",
      "There was a rig\n",
      "There was a create\n",
      "There was a aria\n",
      "There was a mt\n",
      "There was a confirmed\n",
      "There was a profile\n",
      "There was a ail\n",
      "There was a cover\n",
      "There was a load\n",
      "There was a int\n",
      "There was a atom\n",
      "There was a author\n",
      "There was a history\n",
      "\n",
      "345 words checked this session, 1500 checked overall\n"
     ]
    }
   ],
   "source": [
    "# Edit this so the pos will make sense when appended\n",
    "line = ['There', 'was', 'a']\n",
    "\n",
    "# run this to get new batch of words\n",
    "num_words = 15\n",
    "\n",
    "### CHANGE THIS FOR YOUR POS ###\n",
    "# POS you will be working on\n",
    "# Chris - NN\n",
    "# Andre - VBG\n",
    "# Isaac - JJ\n",
    "# Henry - NNP\n",
    "# Matias - VB\n",
    "# Cynthia - RB\n",
    "pos = 'NN'\n",
    "to_print = []\n",
    "for i in range(num_words):\n",
    "    w = random.choice(pos_to_words[pos])\n",
    "    while w in checked or w in checked_this_session or (use_gpt and len(enc.encode(w)) != 1):\n",
    "        w = random.choice(pos_to_words[pos])\n",
    "    checked_this_session.add(w)\n",
    "    this_line = [*line, w]\n",
    "    to_print.append(' '.join(this_line))\n",
    "    \n",
    "for l in to_print:\n",
    "    print(l)\n",
    "print('')\n",
    "print('{:d} words checked this session, {:d} checked overall'.format(len(checked_this_session), \n",
    "                                                                     len(checked_this_session) + len(checked)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NN']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show pos of words you want to check\n",
    "word = 'int'\n",
    "words_to_pos[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove pos from word and word from pos\n",
    "remove_pos = ['NN']\n",
    "for pos in remove_pos:\n",
    "    words_to_pos[word].remove(pos)\n",
    "    pos_to_words[pos].remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pos to word and word to pos\n",
    "add_pos = 'JJ'\n",
    "words_to_pos[word].append(add_pos)\n",
    "pos_to_words[add_pos].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the word (for words that don't make sense)\n",
    "for pos in words_to_pos[word]:\n",
    "    try:\n",
    "        pos_to_words[pos].remove(word)\n",
    "    except:\n",
    "        continue\n",
    "_ = words_to_pos.pop(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At end, when you need to commit changes to the dictionary\n",
    "with open('data/checked_words.txt', 'a+') as f:\n",
    "    for w in checked_this_session:\n",
    "        f.write(w)\n",
    "        f.write('\\n')\n",
    "        \n",
    "postag[1] = pos_to_words\n",
    "postag[2] = words_to_pos\n",
    "with open('py_files/saved_objects/postag_dict_all.p', 'wb') as f:\n",
    "    pickle.dump(postag, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words that we don't know what to do with\n",
    "# wouldnt, doesnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Roman numerals as symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NN']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym = 'lv'\n",
    "words_to_pos[sym]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_to_words['NN'].remove(sym)\n",
    "words_to_pos[sym] = ['SYM']\n",
    "pos_to_words['SYM'] = sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lv, xc, ii, xx, xi, ll, xxx, ci"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
