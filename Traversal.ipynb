{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_similar(synsets):\n",
    "    # returns entries with highest wup similarity score\n",
    "    the_max = 0\n",
    "    for i in range(len(synsets)):\n",
    "        for j in range(i + 1, len(synsets)):\n",
    "            this_similarity = synsets[i].wup_similarity(synsets[j])\n",
    "            if this_similarity is not None and this_similarity > the_max:\n",
    "                the_max = this_similarity\n",
    "                s1 = synsets[i]\n",
    "                s2 = synsets[j]\n",
    "    return (s1, s2)\n",
    "\n",
    "def best_corresponding_pos(synset):\n",
    "    # inspects definition and returns most similar word with\n",
    "    # same pos as input word excluding the input word\n",
    "    # right now only works for nouns, verbs, adjectives\n",
    "    # returns a tuple with a boolean describing whether\n",
    "    # the same pos was found, similarity, and word\n",
    "    this_pos = synset.pos()\n",
    "    def_token = word_tokenize(synset.definition())\n",
    "    \n",
    "    if  this_pos == wn.NOUN:\n",
    "        pos_token = 'NN'\n",
    "    elif this_pos == wn.VERB:\n",
    "        pos_token = 'V'\n",
    "    elif this_pos == wn.ADJ:\n",
    "        pos_token = 'JJ'\n",
    "    else:\n",
    "        # don't care about pos\n",
    "        pos_token = 'z'\n",
    "#     else:\n",
    "#         raise ValueError('Input synset must be a Noun, Verb, or Adjective')\n",
    "        \n",
    "    lm = WordNetLemmatizer()\n",
    "    min_similarity = 2\n",
    "    min_similarity_other_pos = 2\n",
    "    best_corr_pos = None\n",
    "    best_corr_other_pos = None\n",
    "    \n",
    "    for tagged_word in pos_tag(def_token):\n",
    "        if pos_token in tagged_word[1]:\n",
    "            lemma = lm.lemmatize(tagged_word[0], pos=synset.pos())\n",
    "            other_synsets = wn.synsets(lemma, pos=synset.pos())\n",
    "            if len(other_synsets) > 0:\n",
    "                # just pick the first synset\n",
    "                this_similarity = synset.wup_similarity(other_synsets[0])\n",
    "                if this_similarity is not None and this_similarity < min_similarity:\n",
    "                    min_similarity = this_similarity\n",
    "                    best_corr_pos = tagged_word[0]\n",
    "        elif best_corr_pos is None:\n",
    "            lemma = lm.lemmatize(tagged_word[0])\n",
    "            other_synsets = wn.synsets(lemma)\n",
    "            if len(other_synsets) > 0:\n",
    "                # just pick the first synset\n",
    "                this_similarity = synset.wup_similarity(other_synsets[0])\n",
    "                if this_similarity is not None and this_similarity < min_similarity_other_pos:\n",
    "                    min_similarity_other_pos = this_similarity\n",
    "                    best_corr_other_pos = tagged_word[0]\n",
    "    # if no word with same pos found\n",
    "    if best_corr_pos is None:\n",
    "        return False, min_similarity_other_pos, best_corr_other_pos\n",
    "    return True, min_similarity, best_corr_pos\n",
    "\n",
    "def first_corresponding_pos(synset):\n",
    "    # inspects definition and returns first word with same pos\n",
    "    # as input word\n",
    "    # right now only works for nouns, verbs, adjectives\n",
    "    this_pos = synset.pos()\n",
    "    def_token = word_tokenize(synset.definition())\n",
    "    \n",
    "    if this_pos == 'n':\n",
    "        pos_token = 'NN'\n",
    "    elif this_pos == 'v':\n",
    "        pos_token = 'V'\n",
    "    elif this_pos == 'a':\n",
    "        pos_token = 'JJ'\n",
    "    else:\n",
    "        raise ValueError('Input synset must be a Noun, Verb, or Adjective')\n",
    "    \n",
    "    # in case same pos does not exist\n",
    "    if this_pos == 'n':\n",
    "        alt_pos = 'JJ'\n",
    "    else:\n",
    "        alt_pos = 'NN'\n",
    "        \n",
    "    first_alt = None\n",
    "    for tagged_word in pos_tag(def_token):\n",
    "        if pos_token in tagged_word[1]:\n",
    "            return tagged_word[0], synset.definition()\n",
    "        elif first_alt is None and alt_pos in tagged_word:\n",
    "            first_alt = tagged_word[0]\n",
    "    return first_alt, synset.definition()\n",
    "        \n",
    "def get_two_senses(seed_word):\n",
    "    synsets = wn.synsets(seed_word)\n",
    "    pair = least_similar(synsets)\n",
    "#     return best_corresponding_pos(pair[0])[2], best_corresponding_pos(pair[1])[2]\n",
    "    return first_corresponding_pos(pair[0]), first_corresponding_pos(pair[1])\n",
    "\n",
    "def traverse_wn(word):\n",
    "    # traverses wn synsets for word and returns best\n",
    "    # word in definition of synsets with same pos\n",
    "    \n",
    "    # best word\n",
    "#     min_similarity_other_pos = 2\n",
    "#     min_similarity = 2\n",
    "#     best_other_pos = None\n",
    "#     best_pos = None\n",
    "#     for synset in wn.synsets(word):\n",
    "#         is_same_pos, this_similarity, this_pos = best_corresponding_pos(synset)\n",
    "#         if is_same_pos and this_similarity < min_similarity:\n",
    "#             min_similarity = this_similarity\n",
    "#             best_pos = this_pos\n",
    "#         elif not is_same_pos and this_similarity < min_similarity_other_pos:\n",
    "#             min_similarity_other_pos = this_similarity\n",
    "#             best_other_pos = this_pos\n",
    "#     if best_pos is None:\n",
    "#         return best_other_pos\n",
    "#     return best_pos\n",
    "\n",
    "    # first word\n",
    "    for synset in wn.synsets(word):\n",
    "        first_pos = first_corresponding_pos(synset)\n",
    "        if first_pos is not None and first_pos != word:\n",
    "            return first_pos\n",
    "        \n",
    "def five_word_algorithm(seed_word):\n",
    "    word_c, word_d = get_two_senses(seed_word)\n",
    "    word_b = traverse_wn(word_c[0])\n",
    "    word_a = traverse_wn(word_b[0])\n",
    "    word_e = traverse_wn(word_d[0])\n",
    "    return word_a, word_b, word_c, word_d, word_e\n",
    "\n",
    "def print_five_words(seed_word):\n",
    "    words = five_word_algorithm(seed_word)\n",
    "    print(words[0][0] + '->' + words[1][0] + '->\\033[4m' + words[2][0] + \n",
    "          '\\033[0m\\033[1m~~>\\033[0m\\033[4m' + words[3][0] + '\\033[0m->' + words[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('vertebrates',\n",
       "  'warm-blooded egg-laying vertebrates characterized by feathers and forelimbs modified as wings'),\n",
       " ('bird',\n",
       "  'a domesticated gallinaceous bird thought to be descended from the red jungle fowl'),\n",
       " ('fowl',\n",
       "  'a domestic fowl bred for flesh or eggs; believed to have been developed from the red jungle fowl'),\n",
       " ('person', 'a person who lacks confidence, is irresolute and wishy-washy'),\n",
       " ('human', 'a human being'))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_word_algorithm('chicken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertebrates->bird->\u001b[4mfowl\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4mperson\u001b[0m->human\n",
      "person->follower->\u001b[4mdevotee\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4mfollower\u001b[0m->person\n",
      "sound->noise->\u001b[4mracket\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4mclub\u001b[0m->team\n",
      "property->number->\u001b[4mgroup\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4munit\u001b[0m->division\n",
      "document->act->\u001b[4mjourney\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4mlight\u001b[0m->physics\n",
      "kind->make->\u001b[4mprepare\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4mapplying\u001b[0m->put\n",
      "structure->buildings->\u001b[4mplant\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4mconsisting\u001b[0m->originate\n",
      "power->influence->\u001b[4mmanipulate\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4mfalsify\u001b[0m->make\n"
     ]
    }
   ],
   "source": [
    "# first word\n",
    "print_five_words('chicken')\n",
    "print_five_words('fan')\n",
    "print_five_words('Bat')\n",
    "print_five_words('Battery')\n",
    "print_five_words('Trip')\n",
    "print_five_words('Cook')\n",
    "print_five_words('Straw')\n",
    "print_five_words('Fiddle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person->names->\u001b[4mflesh\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4mconfidence\u001b[0m->state\n",
      "organisms->biology->\u001b[4msports\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4madmirer\u001b[0m->team\n",
      "biology->sports->\u001b[4mracket\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4mclub\u001b[0m->golf\n",
      "operate->pedal->\u001b[4mguns\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4mcatcher\u001b[0m->baseball\n",
      "dance->ball->\u001b[4mreturn\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4mlight\u001b[0m->sensation\n",
      "make->spoken->\u001b[4mprepare\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4mapplying\u001b[0m->convey\n",
      "plants->crop->\u001b[4mfodder\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4mseed\u001b[0m->tournament\n",
      "piece->performance->\u001b[4mor\u001b[0m\u001b[1m~~>\u001b[0m\u001b[4mfalsify\u001b[0m->falsifying\n"
     ]
    }
   ],
   "source": [
    "# best word\n",
    "print_five_words('chicken')\n",
    "print_five_words('fan')\n",
    "print_five_words('Bat')\n",
    "print_five_words('Battery')\n",
    "print_five_words('Trip')\n",
    "print_five_words('Cook')\n",
    "print_five_words('Straw')\n",
    "print_five_words('Fiddle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chicken.n.01'),\n",
       " Synset('chicken.n.02'),\n",
       " Synset('wimp.n.01'),\n",
       " Synset('chicken.n.04'),\n",
       " Synset('chicken.s.01')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('chicken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a person who lacks confidence, is irresolute and wishy-washy'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('wimp.n.01').definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('violin.n.01')\n",
      "bowed stringed instrument that is the highest member of the violin family; this instrument has four strings and a hollow body and an unfretted fingerboard and is played with a bow\n",
      "\n",
      "Synset('fiddle.v.01')\n",
      "avoid (one's assigned duties)\n",
      "\n",
      "Synset('fiddle.v.02')\n",
      "commit fraud and steal from one's employer\n",
      "\n",
      "Synset('fiddle.v.03')\n",
      "play the violin or fiddle\n",
      "\n",
      "Synset('fiddle.v.04')\n",
      "play on a violin\n",
      "\n",
      "Synset('toy.v.02')\n",
      "manipulate manually or in one's mind or imagination\n",
      "\n",
      "Synset('tamper.v.01')\n",
      "play around with or alter or falsify, usually secretively or dishonestly\n",
      "\n",
      "Synset('tinker.v.03')\n",
      "try to fix or mend\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets('Fiddle'):\n",
    "    print(synset)\n",
    "    print(synset.definition())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.11764705882352941\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('toy.v.02').wup_similarity(wn.synset('tamper.v.01')))\n",
    "print(wn.synset('toy.v.02').wup_similarity(wn.synset('violin.n.01')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
