{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('DT-JJ-JJ-NN-VBN-NNP', 1), ('VBN-TO-VB-DT-NN-VBN-NNP-.', 1), (\"``-CC-,-''-PRP-VBD-,-``-PRP-MD-VB\", 1), ('WP-DT-JJ-NN', 1), ('VB-IN-NNP-VB-NNP-NNP-.', 1), ('EX-VBD-DT-JJ-NN-RB-JJ', 1), ('PRP-RB-VBD-WRB-PRP-VBD-VBN-:', 1), ('PRP-MD-VB-TO-DT-NN', 1), ('CC-VB-RB-IN-NN-,', 1), ('IN-IN-PRP-MD-VBN-RB-VBN-.', 1), ('DT-NN-IN-NN-,-NNP-NNP-,', 1), ('VBN-RP-IN-NNP-CC-NNP-POS-,', 1), ('VBN-IN-DT-NN-,', 1), ('NNP-PRP$-NN-,-``-PRP-VBZ-NN', 1), (\"PRP-VBP-VBG-PRP-:-:-IN-NNS-.-''\", 1), ('DT-NN-,-WP-VBD-IN-NNP-NNP-,', 1), (\"VBN-CD-NNS-IN-PRP$-NN-''\", 1), ('PRP-VBD-,-IN-DT-NN-,', 1), ('``-DT-NN-NN-:-RB-PRP', 1), (\"RB-VBN-PRP-,-RB-WRB-PRP-VBP-JJ-.-''-''\", 1), ('DT-NN-,-RB-JJ-,', 1), ('CD-NN-VBD-TO-PRP$-NN-,', 1), ('``-DT-NN-MD-MD', 1), ('NN-IN-PRP-MD-:', 1), (\"CC-DT-NN-MD-RB-MD-DT-MD-,-MD-PRP-.-''\", 1), ('RB-VBZ-TO-DT-NN-,', 1), ('DT-NN-WDT-VBZ-DT-JJR', 1), ('IN-DT-NN-IN-DT-JJ-NN-:', 1), ('CC-DT-NN-IN-PRP-VBZ', 1), ('JJ-NNS-IN-NNS-,', 1), ('CC-DT-VBZ-WRB-DT-NN-VBZ-IN-.', 1), ('DT-JJ-JJ-NN-IN-NNP', 1), ('IN-DT-JJ-NN-VBD-VBN-:', 1), (\"WRB-VBD-,-``-WP-VBZ-JJ-.-''\", 1), ('PRP-VBD-CC-VBD-,', 1), (\"``-PRP-VBP-RB-VB-:-PRP-RB-VBD-IN-DT-NN-.-''\", 1), ('EX-VBD-DT-JJ-NN-IN-NNP-,', 1), ('NNP-NNP-VBD-DT-NN-IN-NN-:', 1), ('PRP-VBD-IN-PRP$-NN', 1), ('DT-NN-WP-VBD-PRP', 1), ('TO-VB-JJ-NNS-IN-PRP$-NN-.', 1), ('DT-NN-IN-PRP$-NN-VBD-NNP-NNP', 1), ('PRP-VBD-VBN-:-PRP-MD-VB-VBN-.', 1), ('RB-DT-JJ-NN-VBD-PRP-:', 1), ('TO-VB-RP-DT-NN-,', 1), ('PRP-VBD-RP-IN-NN-CC-NN-.', 1)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from numpy.random import choice\n",
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "sonnet_poets = {\"Shakespeare\" : \"Shakespeare_Sonnets.txt\", \"Frost\" : \"Robert_Frost.txt\", \"Whitman\" : \"Walt_Whitman.txt\"}\n",
    "limerick_poets = {\"Limericks\" : \"limericks.txt\"}\n",
    "\n",
    "def build_templates(poets):\n",
    "    templates = {}\n",
    "    row_map = {\n",
    "        1: [],\n",
    "        2: [],\n",
    "        3: [],\n",
    "        4: [],\n",
    "        5: []\n",
    "    }\n",
    "    \n",
    "    # Threshold for template length. Templates are ignored if they are longer than this value.\n",
    "    max_threshold = 20\n",
    "    min_threshold = 1\n",
    "\n",
    "    for poet, filename in poets.items():\n",
    "        poet_template = {}\n",
    "\n",
    "        with open(filename, \"r\") as f:\n",
    "            line_num = 1\n",
    "            for line in list(filter(lambda x: len(x) > 5, f)):\n",
    "                line = line.strip()\n",
    "                # Uncomment to strip punctuation\n",
    "                # line = re.sub(r'[^\\w\\s]', '', line)\n",
    "                text = nltk.word_tokenize(line)\n",
    "                template = [word[1] for word in nltk.pos_tag(text)]\n",
    "\n",
    "                # If the template length exceeds the threshold, don't include it\n",
    "                if len(template) > max_threshold or len(template) < min_threshold:\n",
    "                    continue\n",
    "                    \n",
    "                template_str = \"-\".join(template)\n",
    "                \n",
    "                count = poet_template.get(template_str, 0)\n",
    "                poet_template[template_str] = count + 1\n",
    "                row_map[line_num].append(template)\n",
    "                line_num = (line_num % 5) + 1\n",
    "                                \n",
    "        # Filter out rare templates that only occurred once in corpus\n",
    "        filtered_templates = { template : val for template, val in poet_template.items() if val > 0 }\n",
    "        sorted_x = sorted(filtered_templates.items(), key=operator.itemgetter(1))\n",
    "        print(sorted_x)\n",
    "        \n",
    "        # Find the total number of processed lines by summing the counts in the filtered dictionary\n",
    "        total_count = reduce(lambda a, b: a + b, filtered_templates.values())\n",
    "        \n",
    "        # Get a list of the unique templates\n",
    "        candidates = list(filtered_templates.keys())\n",
    "            \n",
    "        # Compute the probability distribution and store it under the poet's name\n",
    "        probability_dist = list(map(lambda x: filtered_templates[x] / total_count, candidates))\n",
    "        templates[poet] = (candidates, probability_dist)\n",
    "        \n",
    "    templates['Lines'] = row_map\n",
    "    return templates\n",
    "\n",
    "def random_weighted_template(templates, poet):\n",
    "    candidates, dist = templates[poet][0], templates[poet][1]\n",
    "    template_index = choice(range(len(candidates)), 1, p=dist).item()\n",
    "\n",
    "    return candidates[template_index].split(\"-\")\n",
    "\n",
    "templates = build_templates(limerick_poets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [['DT', 'JJ', 'JJ', 'NN', 'VBN', 'NNP'], ['EX', 'VBD', 'DT', 'JJ', 'NN', 'RB', 'JJ'], ['DT', 'NN', 'IN', 'NN', ',', 'NNP', 'NNP', ','], ['DT', 'NN', ',', 'WP', 'VBD', 'IN', 'NNP', 'NNP', ','], ['DT', 'NN', ',', 'RB', 'JJ', ','], ['RB', 'VBZ', 'TO', 'DT', 'NN', ','], ['CC', 'DT', 'VBZ', 'WRB', 'DT', 'NN', 'VBZ', 'IN', '.'], ['``', 'PRP', 'VBP', 'RB', 'VB', ':', 'PRP', 'RB', 'VBD', 'IN', 'DT', 'NN', '.', \"''\"], ['TO', 'VB', 'JJ', 'NNS', 'IN', 'PRP$', 'NN', '.'], ['PRP', 'VBD', 'RP', 'IN', 'NN', 'CC', 'NN', '.']], 2: [['VBN', 'TO', 'VB', 'DT', 'NN', 'VBN', 'NNP', '.'], ['PRP', 'RB', 'VBD', 'WRB', 'PRP', 'VBD', 'VBN', ':'], ['VBN', 'RP', 'IN', 'NNP', 'CC', 'NNP', 'POS', ','], ['VBN', 'CD', 'NNS', 'IN', 'PRP$', 'NN', \"''\"], ['CD', 'NN', 'VBD', 'TO', 'PRP$', 'NN', ','], ['DT', 'NN', 'WDT', 'VBZ', 'DT', 'JJR'], ['DT', 'JJ', 'JJ', 'NN', 'IN', 'NNP'], ['EX', 'VBD', 'DT', 'JJ', 'NN', 'IN', 'NNP', ','], ['DT', 'NN', 'IN', 'PRP$', 'NN', 'VBD', 'NNP', 'NNP']], 3: [['``', 'CC', ',', \"''\", 'PRP', 'VBD', ',', '``', 'PRP', 'MD', 'VB'], ['PRP', 'MD', 'VB', 'TO', 'DT', 'NN'], ['VBN', 'IN', 'DT', 'NN', ','], ['PRP', 'VBD', ',', 'IN', 'DT', 'NN', ','], ['``', 'DT', 'NN', 'MD', 'MD'], ['IN', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', ':'], ['IN', 'DT', 'JJ', 'NN', 'VBD', 'VBN', ':'], ['NNP', 'NNP', 'VBD', 'DT', 'NN', 'IN', 'NN', ':'], ['PRP', 'VBD', 'VBN', ':', 'PRP', 'MD', 'VB', 'VBN', '.']], 4: [['WP', 'DT', 'JJ', 'NN'], ['CC', 'VB', 'RB', 'IN', 'NN', ','], ['NNP', 'PRP$', 'NN', ',', '``', 'PRP', 'VBZ', 'NN'], ['``', 'DT', 'NN', 'NN', ':', 'RB', 'PRP'], ['NN', 'IN', 'PRP', 'MD', ':'], ['CC', 'DT', 'NN', 'IN', 'PRP', 'VBZ'], ['WRB', 'VBD', ',', '``', 'WP', 'VBZ', 'JJ', '.', \"''\"], ['PRP', 'VBD', 'IN', 'PRP$', 'NN'], ['RB', 'DT', 'JJ', 'NN', 'VBD', 'PRP', ':']], 5: [['VB', 'IN', 'NNP', 'VB', 'NNP', 'NNP', '.'], ['IN', 'IN', 'PRP', 'MD', 'VBN', 'RB', 'VBN', '.'], ['PRP', 'VBP', 'VBG', 'PRP', ':', ':', 'IN', 'NNS', '.', \"''\"], ['RB', 'VBN', 'PRP', ',', 'RB', 'WRB', 'PRP', 'VBP', 'JJ', '.', \"''\", \"''\"], ['CC', 'DT', 'NN', 'MD', 'RB', 'MD', 'DT', 'MD', ',', 'MD', 'PRP', '.', \"''\"], ['JJ', 'NNS', 'IN', 'NNS', ','], ['PRP', 'VBD', 'CC', 'VBD', ','], ['DT', 'NN', 'WP', 'VBD', 'PRP'], ['TO', 'VB', 'RP', 'DT', 'NN', ',']]}\n"
     ]
    }
   ],
   "source": [
    "print(templates[\"Lines\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DT', 'NN', 'WDT', 'VBZ', 'DT', 'JJR']\n"
     ]
    }
   ],
   "source": [
    "print(random_weighted_template(templates, \"Limericks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_common_words(poets):\n",
    "    word_counts = {}\n",
    "    \n",
    "    for poet, filename in poets.items():\n",
    "        with open(filename, \"r\") as f:\n",
    "            for line in list(filter(lambda x: len(x) > 10, f)):\n",
    "                line = line.strip()\n",
    "\n",
    "                words = line.split()\n",
    "                for word in words:\n",
    "                    count = word_counts.get(word, 0)\n",
    "                    word_counts[word] = count + 1\n",
    "                    \n",
    "    words = list(word_counts.keys())\n",
    "    words.sort(key=lambda x: -word_counts[x])\n",
    "                \n",
    "    return word_counts, words\n",
    "        \n",
    "word_counts, words = build_common_words(poets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'A', 'He', 'young', 'named', 'to', 'he', 'said,', 'the', 'Phoebe', 'was', 'by', 'with', 'certain', 'fellow', 'Bee-Bee', 'Wished', 'wed', 'woman', 'Phoebe.', '\"But,\"', '\"I', 'must', 'see', 'What', 'clerical', 'fee', 'Be', 'before', 'be', 'Bee-Bee.', 'There', 'man', 'so', 'benighted', 'never', 'knew', 'when', 'slighted;', 'would', 'go', 'party', 'And', 'eat', 'just', 'as', 'hearty,', 'As', 'if', \"he'd\", 'been', 'really', 'invited.', 'maiden', 'at', 'college,', 'Miss', 'Breeze,', 'Weighed', 'down', 'B.A.s', 'and', \"Lit.D's,\", 'Collapsed', 'from', 'strain,', 'Said', 'her', 'doctor,', '\"It\\'s', 'plain', 'You', 'are', 'killing', 'yourself', '---', 'degrees!\"', 'painter,', 'who', 'lived', 'in', 'Great', 'Britain,', 'Interrupted', 'two', 'girls', 'their', \"knittin'\", 'sigh,', '\"That', 'park', 'bench--well', 'I', 'Just', 'painted', 'it,', 'right', 'where', \"you're\", 'sittin.\\'\"']\n"
     ]
    }
   ],
   "source": [
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_collocations(filename):\n",
    "    collocations = {{}}\n",
    "    \n",
    "    with open(filename, \"r\") as f:\n",
    "            for line in list(filter(lambda x: len(x) > 10, f)):\n",
    "                line = line.strip()\n",
    "                \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
