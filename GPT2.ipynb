{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from py_files.Limericks import Limerick_Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "lg = Limerick_Generate(model_name='345M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.valid_permutation_sylls(6,['IN', 'DT', 'JJ', 'NN'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Enthusiastic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a8327b2854b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict_meters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Enthusiastic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'Enthusiastic'"
     ]
    }
   ],
   "source": [
    "lg.dict_meters['Enthusiastic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the entire poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\sample.py:51: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\sample.py:53: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\345M\\model.ckpt\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(1, 1024), b.shape=(1024, 3072), m=1, n=3072, k=1024\n\t [[node sample_sequence/while/model/h0/attn/c_attn/MatMul (defined at E:\\poetix\\gpt2\\src\\model.py:55) ]]\n\t [[node sample_sequence/while/Exit_3 (defined at E:\\poetix\\gpt2\\src\\sample.py:76) ]]\n\nCaused by op 'sample_sequence/while/model/h0/attn/c_attn/MatMul', defined at:\n  File \"E:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"E:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"E:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"E:\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"E:\\Anaconda3\\lib\\asyncio\\base_events.py\", line 523, in run_forever\n    self._run_once()\n  File \"E:\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1758, in _run_once\n    handle._run()\n  File \"E:\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"E:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"E:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"E:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"E:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-29e1adabd3b9>\", line 6, in <module>\n    ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n  File \"E:\\poetix\\py_files\\Limericks.py\", line 1782, in gen_poem_gpt\n    out = generate_prompt(model_name=self.model_name, seed_word=rhyme1, length=prompt_length)\n  File \"E:\\poetix\\gpt2\\src\\generate_prompt.py\", line 68, in generate_prompt\n    temperature=temperature, top_k=top_k\n  File \"E:\\poetix\\gpt2\\src\\sample.py\", line 76, in sample_sequence\n    back_prop=False,\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3556, in while_loop\n    return_same_structure)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3087, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3022, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3525, in <lambda>\n    body = lambda i, lv: (i + 1, orig_body(*lv))\n  File \"E:\\poetix\\gpt2\\src\\sample.py\", line 50, in body\n    next_outputs = step(hparams, prev[:, tf.newaxis], past=past)\n  File \"E:\\poetix\\gpt2\\src\\sample.py\", line 33, in step\n    lm_output = model(hparams=hparams, X=tokens, past=past, reuse=tf.AUTO_REUSE)\n  File \"E:\\poetix\\gpt2\\src\\model.py\", line 164, in model\n    h, present = block(h, 'h%d' % layer, past=past, hparams=hparams)\n  File \"E:\\poetix\\gpt2\\src\\model.py\", line 126, in block\n    a, present = attn(norm(x, 'ln_1'), 'attn', nx, past=past, hparams=hparams)\n  File \"E:\\poetix\\gpt2\\src\\model.py\", line 102, in attn\n    c = conv1d(x, 'c_attn', n_state*3)\n  File \"E:\\poetix\\gpt2\\src\\model.py\", line 55, in conv1d\n    c = tf.reshape(tf.matmul(tf.reshape(x, [-1, nx]), tf.reshape(w, [-1, nf]))+b, start+[nf])\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2455, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 5630, in mat_mul\n    name=name)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(1, 1024), b.shape=(1024, 3072), m=1, n=3072, k=1024\n\t [[node sample_sequence/while/model/h0/attn/c_attn/MatMul (defined at E:\\poetix\\gpt2\\src\\model.py:55) ]]\n\t [[node sample_sequence/while/Exit_3 (defined at E:\\poetix\\gpt2\\src\\sample.py:76) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(1, 1024), b.shape=(1024, 3072), m=1, n=3072, k=1024\n\t [[{{node sample_sequence/while/model/h0/attn/c_attn/MatMul}}]]\n\t [[{{node sample_sequence/while/Exit_3}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-29e1adabd3b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                                           \u001b[1;33m[\u001b[0m\u001b[1;34m'PRP'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VBD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RP'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                           \u001b[1;33m[\u001b[0m\u001b[1;34m'IN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'JJ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                                           \u001b[1;33m[\u001b[0m\u001b[1;34m'CC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VBD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'IN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'JJ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                                          ])\n",
      "\u001b[1;32mE:\\poetix\\py_files\\Limericks.py\u001b[0m in \u001b[0;36mgen_poem_gpt\u001b[1;34m(self, rhyme1, rhyme2, default_templates, story_line, prompt_length, save_as_pickle, search_space, enforce_syllables, enforce_stress, search_space_coef, use_word_embedding)\u001b[0m\n\u001b[0;32m   1780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m         \u001b[1;31m# Used the old method to generate the first line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1782\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_prompt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed_word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrhyme1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprompt_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1783\u001b[0m         \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1784\u001b[0m         \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\poetix\\gpt2\\src\\generate_prompt.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[1;34m(model_name, seed, seed_word, nsamples, batch_size, length, temperature, top_k)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnsamples\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             out = sess.run(output, feed_dict={\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[0mcontext\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcontext_tokens\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             })[:, len(context_tokens):]\n\u001b[0;32m     81\u001b[0m             \u001b[0mgenerated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(1, 1024), b.shape=(1024, 3072), m=1, n=3072, k=1024\n\t [[node sample_sequence/while/model/h0/attn/c_attn/MatMul (defined at E:\\poetix\\gpt2\\src\\model.py:55) ]]\n\t [[node sample_sequence/while/Exit_3 (defined at E:\\poetix\\gpt2\\src\\sample.py:76) ]]\n\nCaused by op 'sample_sequence/while/model/h0/attn/c_attn/MatMul', defined at:\n  File \"E:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"E:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"E:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"E:\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"E:\\Anaconda3\\lib\\asyncio\\base_events.py\", line 523, in run_forever\n    self._run_once()\n  File \"E:\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1758, in _run_once\n    handle._run()\n  File \"E:\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"E:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"E:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"E:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"E:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"E:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"E:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-29e1adabd3b9>\", line 6, in <module>\n    ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n  File \"E:\\poetix\\py_files\\Limericks.py\", line 1782, in gen_poem_gpt\n    out = generate_prompt(model_name=self.model_name, seed_word=rhyme1, length=prompt_length)\n  File \"E:\\poetix\\gpt2\\src\\generate_prompt.py\", line 68, in generate_prompt\n    temperature=temperature, top_k=top_k\n  File \"E:\\poetix\\gpt2\\src\\sample.py\", line 76, in sample_sequence\n    back_prop=False,\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3556, in while_loop\n    return_same_structure)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3087, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3022, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\", line 3525, in <lambda>\n    body = lambda i, lv: (i + 1, orig_body(*lv))\n  File \"E:\\poetix\\gpt2\\src\\sample.py\", line 50, in body\n    next_outputs = step(hparams, prev[:, tf.newaxis], past=past)\n  File \"E:\\poetix\\gpt2\\src\\sample.py\", line 33, in step\n    lm_output = model(hparams=hparams, X=tokens, past=past, reuse=tf.AUTO_REUSE)\n  File \"E:\\poetix\\gpt2\\src\\model.py\", line 164, in model\n    h, present = block(h, 'h%d' % layer, past=past, hparams=hparams)\n  File \"E:\\poetix\\gpt2\\src\\model.py\", line 126, in block\n    a, present = attn(norm(x, 'ln_1'), 'attn', nx, past=past, hparams=hparams)\n  File \"E:\\poetix\\gpt2\\src\\model.py\", line 102, in attn\n    c = conv1d(x, 'c_attn', n_state*3)\n  File \"E:\\poetix\\gpt2\\src\\model.py\", line 55, in conv1d\n    c = tf.reshape(tf.matmul(tf.reshape(x, [-1, nx]), tf.reshape(w, [-1, nf]))+b, start+[nf])\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2455, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 5630, in mat_mul\n    name=name)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(1, 1024), b.shape=(1024, 3072), m=1, n=3072, k=1024\n\t [[node sample_sequence/while/model/h0/attn/c_attn/MatMul (defined at E:\\poetix\\gpt2\\src\\model.py:55) ]]\n\t [[node sample_sequence/while/Exit_3 (defined at E:\\poetix\\gpt2\\src\\sample.py:76) ]]\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"plane\", \"wind\", \n",
    "                        prompt_length=20, search_space=50,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'RP', 'CD', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-74a18fc12acb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m poem = lg.gen_poem_gpt(\"plane\", \"wind\", \n\u001b[0m\u001b[0;32m      2\u001b[0m                        \u001b[0mprompt_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                        default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n\u001b[0;32m      4\u001b[0m                                           \u001b[1;33m[\u001b[0m\u001b[1;34m'PRP'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VBD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RP'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                           \u001b[1;33m[\u001b[0m\u001b[1;34m'IN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'JJ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lg' is not defined"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"plane\", \"wind\", \n",
    "                       prompt_length=50, search_space=50,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'RP', 'CD', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'once', 'was', 'a', 'woman', 'enjoying', 'her', 'life', 'in', 'lamar']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "['who', 'had', 'men', 'in', 'a', 'car']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "['i', 'took', 'up', 'one', 'tune']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "['of', 'a', 'new', 'moon']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "['and', 'was', 'in', 'a', 'th', 'bar']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"star\", \"moon\", \n",
    "                       first_line_sylls=14, prompt_length=50, search_space=150,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'RP', 'CD', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'was', 'an', 'enthusiastic', 'man', 'that', 'lived', 'in', 'dakar']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['who', 'saw', 'things', 'from', 'another', 'star']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['i', 'found', 'out', 'one', 'afternoon']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['that', 'the', 'dark', 'moon']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['and', 'lost', 'in', 'the', 'dark', 'scar']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"star\", \"moon\", \n",
    "                       first_line_sylls=14, prompt_length=50, search_space=150,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'RP', 'CD', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'RP', 'CD', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ]\n",
    "rhyme1 = \"plane\"\n",
    "rhyme2 = \"wind\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\score.py:55: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['who', 'raised', 'funds', 'for', 'the', 'campaign']\n"
     ]
    }
   ],
   "source": [
    "# Generate second sentence\n",
    "f = open('gpt2.pkl', 'rb')\n",
    "prompt = pickle.load(f)\n",
    "new_sentence = lg.gen_line_gpt(w=None, encodes=prompt, default_template = default_templates[0], rhyme=rhyme1, search_space=75)\n",
    "prompt += new_sentence[1]\n",
    "print(new_sentence[0])\n",
    "f = open('gpt2.pkl', 'wb')\n",
    "pickle.dump(prompt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\score.py:55: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['she', 'set', 'up', 'one', 'mind']\n"
     ]
    }
   ],
   "source": [
    "# Generate third sentence\n",
    "f = open('gpt2.pkl', 'rb')\n",
    "prompt = pickle.load(f)\n",
    "new_sentence = lg.gen_line_gpt(w=None, encodes=prompt, default_template = default_templates[1], rhyme=rhyme2, search_space=60)\n",
    "prompt += new_sentence[1]\n",
    "print(new_sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\score.py:55: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['for', 'a', 'new', 'kind']\n"
     ]
    }
   ],
   "source": [
    "# Generate fourth sentence\n",
    "f = open('gpt2.pkl', 'rb')\n",
    "prompt = pickle.load(f)\n",
    "new_sentence = lg.gen_line_gpt(w=None, encodes=prompt, default_template = default_templates[2], rhyme=rhyme2, search_space=30)\n",
    "prompt += new_sentence[1]\n",
    "print(new_sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\score.py:55: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['and', 'moved', 'for', 'a', 'new', 'campaign']\n"
     ]
    }
   ],
   "source": [
    "# Generate fifth sentence\n",
    "f = open('gpt2.pkl', 'rb')\n",
    "prompt = pickle.load(f)\n",
    "new_sentence = lg.gen_line_gpt(w=None, encodes=prompt, default_template = default_templates[3], rhyme=rhyme1, search_space=10)\n",
    "prompt += new_sentence[1]\n",
    "print(new_sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'once', 'was', 'an', 'enthusiastic', 'woman', 'named', 'romaine']\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\sample.py:51: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\sample.py:53: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['who', 'told', 'stories', 'about', 'the', 'pain']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['she', 'felt', 'off', 'one', 'kind']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['of', 'a', 'high', 'wind']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['and', 'fell', 'off', 'a', 'high', 'plane']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"plane\", \"wind\", \n",
    "                       first_line_sylls=14, prompt_length=100, search_space=15,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'RP', 'CD', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'once', 'was', 'an', 'enthusiastic', 'man', 'named', 'roan']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['who', 'had', 'aspirations', 'of', 'a', 'loan']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['it', 'was', 'a', 'glue']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-6cdba9db1f54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                                           \u001b[1;33m[\u001b[0m\u001b[1;34m'PRP'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VBD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                           \u001b[1;33m[\u001b[0m\u001b[1;34m'IN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'JJ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                                           \u001b[1;33m[\u001b[0m\u001b[1;34m'CC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VBD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'IN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'JJ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                                          ])\n",
      "\u001b[1;32mE:\\poetix\\py_files\\Limericks.py\u001b[0m in \u001b[0;36mgen_poem_gpt\u001b[1;34m(self, rhyme1, rhyme2, default_templates, first_line_sylls, story_line, prompt_length, save_as_pickle, search_space)\u001b[0m\n\u001b[0;32m    942\u001b[0m             \u001b[0mprompt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnew_sentence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 944\u001b[1;33m             \u001b[0mnew_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_line_gpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_template\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_templates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhyme_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfive_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    945\u001b[0m             \u001b[0mprompt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnew_sentence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\poetix\\py_files\\Limericks.py\u001b[0m in \u001b[0;36mgen_line_gpt\u001b[1;34m(self, w, encodes, default_template, rhyme_word, rhyme_set, search_space)\u001b[0m\n\u001b[0;32m    848\u001b[0m             \u001b[1;31m# Get the most probable N sentences by sorting the list according to probability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m             \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheapq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnsmallest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_sentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 850\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    851\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"joan\", \"\",\n",
    "                       first_line_sylls=12, prompt_length=75, search_space=150, story_line=True,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'DT', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'once', 'was', 'an', 'enthusiastic', 'man', 'named', 'case']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['who', 'did', 'wonders', 'for', 'the', 'birthplace']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['i', 'got', 'a', 'report']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['from', 'a', 'local', 'court']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['and', 'asked', 'for', 'a', 'special', 'grace']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"grace\",\n",
    "                       first_line_sylls=12, prompt_length=100, search_space=100, story_line=True,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'DT', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the sentence with highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['he', 'ordered', 'a', 'porterhouse', 'steak,', 'sauerkraut,', 'mince', 'pie', 'and', 'fruit', 'cake.', 'then', 'sat', 'down', 'to', 'dine,', 'drank', 'three', 'kinds', 'of', 'wine,', 'and', 'got', 'into', 'a', 'heated', 'argument']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"He ordered a porterhouse steak, sauerkraut, mince pie and fruit cake. Then sat down to dine, drank three kinds of wine,\", ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN'], False, 10)\n",
    "print(poem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['he', 'ordered', 'a', 'porterhouse', 'steak,', 'sauerkraut,', 'mince', 'pie', 'and', 'fruit', 'cake.', 'then', 'sat', 'down', 'to', 'dine,', 'drank', 'three', 'kinds', 'of', 'wine,', 'and', 'got', 'into', 'a', 'heated', 'argument']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"He ordered a porterhouse steak, sauerkraut, mince pie and fruit cake. Then sat down to dine, drank three kinds of wine,\", ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN'], False, 100)\n",
    "print(poem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "(['there', 'was', 'a', 'young', 'woman', 'named', 'kite,', 'whose', 'speed', 'was', 'much', 'faster', 'than', 'light,', 'she', 'set', 'out', 'one', 'day,', 'in', 'a', 'relative', 'way,', 'and', 'come', 'from', 'the', 'other', 'world'], [8117, 9776, 64, 35465, 8580, 13190, 74, 38159, 12287, 9776, 29482, 69, 14813, 2971, 7091, 2617, 448, 505, 820, 259, 64, 43762, 1014, 392, 2958, 6738, 1169, 847, 6894], -19.603738605976105)\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"There was a young woman named Kite, whose speed was much faster than light, she set out one day, in a relative way,\", \n",
    "                ['CC', 'VBN', 'IN', 'DT', 'JJ', 'NN'], False, 10)\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['a', 'man', 'and', 'his', 'lady-love,', 'min,', 'skated', 'out', 'where', 'the', 'ice', 'was', 'quite', 'thin,', 'had', 'a', 'quarrel,', 'no', 'doubt,', 'for', 'i', 'hear', 'they', 'fell', 'out', 'what', 'the', 'hell', 'he', 'going']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"A man and his lady-love, Min, Skated out where the ice was quite thin, Had a quarrel, no doubt, For I hear they fell out\", \n",
    "                ['WP', 'DT', 'NN', 'PRP', 'VBG'] ,False, 10)\n",
    "print(poem[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhyme Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['why', 'do', 'we', 'have', 'homework', 'after', 'school?', 'this', 'is', 'so', 'uncool.', 'i', 'so', 'want', 'to', 'cry.', 'you', 'need', 'to', 'do', 'this', 'in', 'the', 'middle', 'of', 'school']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"Why do we have homework after school? This is so uncool. I so want to cry.\", \n",
    "               ['PRP', 'VBP', 'TO', 'VB', 'DT', 'IN', 'DT', 'NN', 'IN', 'NN'], 'school', 100)\n",
    "print(poem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['he', 'ordered', 'a', 'porterhouse', 'steak,', 'sauerkraut,', 'mince', 'pie', 'and', 'fruit', 'cake.', 'then', 'sat', 'down', 'to', 'dine,', 'drank', 'three', 'kinds', 'of', 'wine,', 'and', 'got', 'into', 'a', 'little', 'break']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"He ordered a porterhouse steak, sauerkraut, mince pie and fruit cake. Then sat down to dine, drank three kinds of wine,\", ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN'], 'cake', 10)\n",
    "print(poem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['there', 'was', 'a', 'young', 'woman', 'named', 'kite,', 'whose', 'speed', 'was', 'much', 'faster', 'than', 'light,', 'she', 'set', 'out', 'one', 'day,', 'in', 'a', 'relative', 'way,', 'and', 'come', 'from', 'the', 'first', 'night']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"There was a young woman named Kite, whose speed was much faster than light, she set out one day, in a relative way,\", \n",
    "                ['CC', 'VBN', 'IN', 'DT', 'JJ', 'NN'], 'light', 10)\n",
    "print(poem[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Approach (generate only one setentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "[' and', ' smoked', ' in', ' the', ' same', ' room']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"He ordered a porterhouse steak, sauerkraut, mince pie and fruit cake. Then sat down to dine, drank three kinds of wine,\", \n",
    "                (['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN'], \n",
    "                 ['and', 'retired', 'with', 'a', 'bad', 'stomachache']),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "[' and', ' sat', ' near', ' the', ' main', ' kitchen']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"He ordered a porterhouse steak, sauerkraut, mince pie and fruit cake. Then sat down to dine, drank three kinds of wine,\", \n",
    "                (['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN'], \n",
    "                 ['and', 'retired', 'with', 'a', 'bad', 'stomachache']),)\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "[' Who', ' all', ' fall', ' he', ' heard', ' in']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"A man and his lady-love, Min, Skated out where the ice was quite thin, Had a quarrel, no doubt, For I hear they fell out\", \n",
    "                (['WP', 'DT', 'NN', 'PRP', 'VBP', 'IN'], ['what', 'a', 'blessing', 'they', 'didnt', 'fall', 'in']) ,rhyme=\"thin\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\score.py:54: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "[' and', ' found', ' that', ' the', ' young', 'Knight']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"There was a young woman named Kite, whose speed was much faster than light, she set out one day, in a relative way,\", \n",
    "               (['CC', 'VBN', 'IN', 'DT', 'JJ', 'NN'], \n",
    "                ['and', 'returned', 'on', 'the', 'previous', 'night']),rhyme=\"light\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "[' but', ' found', ' at', ' all', ' horrible', ' plight']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"There was a young woman named Kite, whose speed was much faster than light, she set out one day, in a relative way,\", \n",
    "               (['CC', 'VBN', 'IN', 'DT', 'JJ', 'NN'], \n",
    "                ['and', 'returned', 'on', 'the', 'previous', 'night']),rhyme=\"light\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "[' and', ' stayed', ' with', ' the', ' other', ' night']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"There was a young woman named Kite, whose speed was much faster than light, she set out one day, in a relative way,\", \n",
    "               (['CC', 'VBN', 'IN', 'DT', 'JJ', 'NN'], \n",
    "                ['and', 'returned', 'on', 'the', 'previous', 'night']),rhyme=\"light\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Template Constraint\n",
    "There was a young lady named Perkins, Who just simply doted on gherkins. In spite of advice, she ate so much spice, which favour the youngsters, and greatly mortified the obstinate young girl, who turned out to be a pauper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "[' and', ' the', ' lady', ' from', ' the', ' festival', ' of', ' the', ' Tiger']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"There was a young lady from Niger, Who smiled as she rode on a tiger. They came back from the ride with the lady inside,\", \n",
    "               (['CC', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN'], \n",
    "                ['and', 'the', 'smile', 'on', 'the', 'face', 'of', 'the', 'tiger'], 3), rhyme=\"tiger\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate with prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('prompt2.txt','r')\n",
    "template = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'template' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-20a006ab59e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m lg.gen_line_with_template(template, (['PRP', 'VBD', 'CD', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'NN'], \n\u001b[0m\u001b[1;32m      2\u001b[0m                                      ['he', 'was', 'one', 'funny', 'guy', 'with', 'a', 'nice', 'car'], 4))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'template' is not defined"
     ]
    }
   ],
   "source": [
    "lg.gen_line_with_template(template, (['PRP', 'VBD', 'CD', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'NN'], \n",
    "                                     ['he', 'was', 'one', 'funny', 'guy', 'with', 'a', 'nice', 'car'], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "[('he was one funny brit with a nice head of hair on his pate', -176.0026502609253)]\n"
     ]
    }
   ],
   "source": [
    "lg.gen_line_with_template(template, (['PRP', 'VBD', 'CD', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'NN', 'IN', 'NN', 'IN', 'PRP$', 'NN'], \n",
    "                                     ['he', 'was', 'one', 'funny', 'brit', 'with', 'a', 'nice', 'head', 'of', 'hair', 'on', 'his', 'pate'], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:06<00:25,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:11<00:18,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:17<00:11,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:23<00:05,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 5/5 [00:29<00:00,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-33.64236831665039:['it', 'could', 'read', 'to', 'the', 'universe']\n",
      "-37.41541051864624:['he', 'would', 'go', 'to', 'a', 'party']\n",
      "-37.79438257217407:['she', 'could', 'make', 'to', 'this', 're']\n",
      "-38.859190940856934:['me', 'shall', 'do', 'to', 'the', 'world']\n",
      "-38.904462575912476:['you', 'would', 'have', 'to', 'every', 'part']\n",
      "-39.291123390197754:['they', 'must', 'create', 'to', 'the', 'head']\n",
      "-39.50753688812256:['us', 'would', 'have', 'to', 'either', 'key']\n",
      "-39.595194816589355:['oftener', 'could', 'change', 'to', 'either', 'look']\n",
      "-40.514989376068115:['themselves', 'shouldnt', 'want', 'to', 'both', 'perspective']\n",
      "-40.55293893814087:['i', 'can', 'stare', 'at', 'the', 'sky']\n",
      "-40.98474740982056:['them', 'could', 'get', 'to', 'each', 'create']\n",
      "-40.98748826980591:['it', 'will', 'answer', 'to', 'that', 'joy']\n",
      "-41.257362842559814:['themselves', 'will', 'make', 'to', 'all', 'someone']\n",
      "-41.304943323135376:['itself', 'ought', 'read', 'to', 'the', 'something']\n",
      "-41.317829608917236:['self', 'shall', 'get', 'to', 'that', 'joy']\n",
      "-41.840683460235596:['self', 'will', 'read', 'to', 'any', 'part']\n",
      "-41.86216688156128:['itself', 'ought', 'look', 'to', 'this', 'object']\n",
      "-42.13162326812744:['i', 'couldnt', 'have', 'to', 'all', 'answer']\n",
      "-42.2010064125061:['she', 'shouldnt', 'read', 'to', 'no', 'right']\n",
      "-42.223740100860596:['meltst', 'shouldnt', 'read', 'to', 'any', 'key']\n",
      "-42.31282567977905:['himself', 'dare', 'answer', 'to', 'both', 'world']\n",
      "-42.403303146362305:['herself', 'could', 'do', 'to', 'each', 'understood']\n",
      "-42.44603967666626:['me', 'couldnt', 'see', 'to', 'every', 'love']\n",
      "-42.65145015716553:['yourself', 'shouldnt', 'see', 'to', 'any', 'mind']\n",
      "-42.68892478942871:['massacred', 'shouldnt', 'read', 'to', 'all', 'nature']\n",
      "-43.08396530151367:['themselves', 'dare', 'get', 'to', 'those', 'someone']\n",
      "-43.51232147216797:['yourself', 'shall', 'look', 'to', 'such', 'object']\n",
      "-43.79765319824219:['thyself', 'might', 'look', 'to', 'that', 'nothing']\n",
      "-43.93553352355957:['onesself', 'would', 'do', 'to', 'these', 'luck']\n",
      "-44.05070638656616:['handfuls', 'cannot', 'realize', 'to', 'this', 'object']\n",
      "-44.1845645904541:['itself', 'ought', 'be', 'to', 'a', 'place']\n",
      "-44.35441732406616:['she', 'need', 'have', 'to', 'those', 'world']\n",
      "-44.52108573913574:['overthrow', 'may', 'feel', 'to', 'that', 'kindness']\n",
      "-44.54827404022217:['they', 'dare', 'know', 'to', 'that', 'someone']\n",
      "-44.77217674255371:['me', 'shouldnt', 'make', 'to', 'either', 'head']\n",
      "-44.9534478187561:['they', 'may', 'have', 'to', 'no', 'everyone']\n",
      "-45.041504859924316:['yourself', 'could', 'create', 'to', 'an', 'friendship']\n",
      "-45.098647594451904:['handfuls', 'shall', 'know', 'to', 'both', 'kind']\n",
      "-45.13144874572754:['i', 'may', 'change', 'to', 'that', 'change']\n",
      "-45.14540910720825:['he', 'would', 'look', 'to', 'an', 'share']\n",
      "-45.271042823791504:['us', 'might', 'make', 'to', 'neither', 'joy']\n",
      "-45.50499963760376:['yelps', 'will', 'know', 'to', 'another', 'key']\n",
      "-45.84663486480713:['elf', 'shall', 're', 'to', 'the', 'look']\n",
      "-45.968549728393555:['him', 'dare', 'feel', 'to', 'a', 'kindness']\n",
      "-46.05663013458252:['ye', 'will', 'see', 'to', 'some', 'thought']\n",
      "-46.13122606277466:['yelps', 'can', 'be', 'to', 'all', 'head']\n",
      "-46.2157564163208:['ye', 'couldnt', 'feel', 'to', 'neither', 'meant']\n",
      "-46.24919605255127:['they', 'couldnt', 'realize', 'to', 'each', 'thought']\n",
      "-46.40546894073486:['it', 'cannot', 'see', 'to', 'that', 'object']\n",
      "-46.50616121292114:['you', 'cannot', 'look', 'to', 'each', 'answer']\n",
      "-46.782352447509766:['overthrow', 'shouldnt', 'look', 'to', 'either', 'question']\n",
      "-47.02110147476196:['meltst', 'must', 'get', 'to', 'this', 'luck']\n",
      "-47.06746768951416:['him', 'can', 'have', 'to', 'those', 'object']\n",
      "-47.08656597137451:['meltst', 'would', 'create', 'to', 'another', 'nothing']\n",
      "-47.32706594467163:['massacred', 'need', 're', 'to', 'either', 'friendship']\n",
      "-47.383381366729736:['handfuls', 'cannot', 'create', 'to', 'both', 'friendship']\n",
      "-47.40849232673645:['i', 'shall', 'want', 'to', 'either', 'someone']\n",
      "-47.463990211486816:['you', 'can', 'object', 'to', 'those', 'kindness']\n",
      "-47.72133445739746:['ont', 'ought', 'see', 'to', 'an', 'friendship']\n",
      "-47.87050533294678:['himself', 'dare', 'know', 'to', 'half', 'mind']\n",
      "-47.93333196640015:['thyself', 'will', 'read', 'to', 'no', 'part']\n",
      "-48.37499809265137:['them', 'ought', 'create', 'to', 'every', 'object']\n",
      "-48.43808650970459:['me', 'will', 'object', 'to', 'any', 'question']\n",
      "-48.50966787338257:['you', 'need', 'have', 'to', 'these', 'everyone']\n",
      "-48.697081565856934:['meltst', 'might', 'change', 'to', 'both', 'something']\n",
      "-48.89209771156311:['onesself', 'need', 'want', 'to', 'these', 'nothing']\n",
      "-48.89372682571411:['we', 'dare', 'be', 'to', 'either', 'mind']\n",
      "-48.90936231613159:['me', 'may', 're', 'to', 'these', 'meaning']\n",
      "-48.98923301696777:['it', 'can', 'object', 'to', 'both', 'create']\n",
      "-49.0537314414978:['itself', 'ought', 'object', 'to', 'another', 'answer']\n",
      "-49.080400466918945:['elf', 'shall', 're', 'to', 'any', 'key']\n",
      "-49.16201734542847:['yourself', 'ought', 'create', 'to', 'both', 'head']\n",
      "-49.20561408996582:['myself', 'could', 'perspective', 'to', 'an', 'kind']\n",
      "-49.309041023254395:['wither', 'will', 'do', 'to', 'some', 'create']\n",
      "-49.42597198486328:['theirs', 'ought', 'look', 'to', 'neither', 'compassion']\n",
      "-49.512078285217285:['we', 'cannot', 'perspective', 'to', 'another', 'compassion']\n",
      "-49.572465896606445:['mantelshelf', 'may', 're', 'to', 'each', 'look']\n",
      "-49.969780921936035:['theirs', 'may', 'perspective', 'to', 'the', 'thought']\n",
      "-50.05227088928223:['himself', 'may', 'feel', 'to', 'half', 'something']\n",
      "-50.07360601425171:['he', 'may', 'object', 'to', 'this', 'sense']\n",
      "-50.110952377319336:['herself', 'cannot', 'perspective', 'to', 'this', 'perspective']\n",
      "-50.390286445617676:['mantelshelf', 'shall', 'do', 'to', 'either', 'meant']\n",
      "-50.51639938354492:['overthrow', 'shall', 'object', 'to', 'those', 'thought']\n",
      "-50.551188468933105:['herself', 'shouldnt', 'create', 'to', 'no', 'right']\n",
      "-50.56462478637695:['ye', 'shall', 'know', 'to', 'this', 'everyone']\n",
      "-50.61376953125:['onesself', 'shall', 'do', 'to', 'no', 'meaning']\n",
      "-50.62317132949829:['himself', 'must', 'realize', 'to', 'each', 'create']\n",
      "-51.0150032043457:['ye', 'will', 'create', 'to', 'such', 'thought']\n",
      "-51.46578598022461:['themselves', 'shall', 'object', 'to', 'some', 'acceptance']\n",
      "-51.476492404937744:['oftener', 'ought', 're', 'to', 'both', 'thought']\n",
      "-51.75570297241211:['mantelshelf', 'may', 'make', 'to', 'either', 'spirit']\n",
      "-51.868536949157715:['us', 'ought', 'object', 'to', 'every', 'someone']\n",
      "-52.84356117248535:['ont', 'shall', 'read', 'to', 'no', 'spirit']\n",
      "-53.09879684448242:['himself', 'will', 'perspective', 'to', 'every', 'look']\n",
      "-54.41274547576904:['ont', 'ought', 're', 'to', 'those', 'change']\n",
      "-54.6750431060791:['massacred', 'must', 'realize', 'to', 'each', 'luck']\n",
      "-54.75090456008911:['i', 'ought', 'create', 'to', 'each', 'joy']\n",
      "-55.006789207458496:['us', 'ought', 'perspective', 'to', 'any', 'create']\n",
      "-56.020450592041016:['ye', 'may', 'realize', 'to', 'no', 'place']\n",
      "-56.20230579376221:['overthrow', 'shall', 'perspective', 'to', 'those', 'power']\n",
      "-56.75651454925537:['yelps', 'might', 'perspective', 'to', 'this', 'friendship']\n",
      "-58.6817512512207:['theirs', 'shall', 'perspective', 'to', 'every', 'share']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lg.gen_line_with_template(template,['PRP', 'MD', 'VB', 'TO','DT', 'NN'],100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate First Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from py_files.Limericks_new2 import Limerick_Generate_new\n",
    "lg = Limerick_Generate_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test WEMA\n",
    "print(self.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ira\n",
      "kaw\n",
      "hor\n",
      "ll\n",
      "ven\n",
      "del\n",
      "td\n",
      "au\n",
      "est\n",
      "td\n",
      "hun\n",
      "ke\n",
      "mer\n",
      "del\n",
      "im\n",
      "ve\n",
      "ter\n",
      "hed\n",
      "hm\n",
      "les\n",
      "au\n",
      "les\n",
      "pm\n",
      "le\n",
      "xx\n",
      "dg\n",
      "ir\n",
      "ir\n",
      "iii\n",
      "fas\n",
      "mm\n",
      "ven\n",
      "que\n",
      "xxx\n",
      "hes\n",
      "xxx\n",
      "usk\n",
      "ew\n",
      "ii\n",
      "et\n",
      "ir\n",
      "iv\n",
      "hun\n",
      "ii\n",
      "del\n",
      "cv\n",
      "feb\n",
      "td\n",
      "ive\n",
      "ci\n",
      "que\n",
      "del\n",
      "nox\n",
      "je\n",
      "tm\n",
      "pos\n",
      "du\n",
      "iii\n",
      "ix\n",
      "pos\n",
      "mer\n",
      "iii\n",
      "hun\n",
      "fo\n",
      "del\n",
      "vou\n",
      "iv\n",
      "lv\n",
      "mr\n",
      "com\n",
      "ven\n",
      "du\n",
      "mer\n",
      "xxx\n",
      "usd\n",
      "pos\n",
      "liv\n",
      "ven\n",
      "ter\n",
      "len\n",
      "xx\n",
      "du\n",
      "que\n",
      "ful\n",
      "ke\n",
      "ov\n",
      "ida\n",
      "iv\n",
      "ot\n",
      "xiv\n",
      "cv\n",
      "ci\n",
      "mer\n",
      "des\n",
      "ahs\n",
      "ix\n",
      "ov\n",
      "des\n",
      "hed\n",
      "ke\n",
      "ov\n",
      "iv\n",
      "hed\n",
      "xl\n",
      "des\n",
      "xx\n",
      "ven\n",
      "au\n",
      "et\n",
      "cx\n",
      "ira\n",
      "sos\n",
      "hor\n",
      "xc\n",
      "les\n",
      "au\n",
      "le\n",
      "com\n",
      "fm\n",
      "xv\n",
      "ter\n",
      "hes\n",
      "mr\n",
      "vii\n",
      "des\n",
      "pm\n",
      "zap\n",
      "iv\n",
      "tm\n",
      "fo\n",
      "ew\n",
      "suc\n",
      "mia\n",
      "wel\n",
      "ot\n",
      "im\n",
      "lv\n",
      "ned\n",
      "com\n",
      "cv\n",
      "mm\n",
      "fm\n",
      "est\n",
      "htm\n",
      "je\n",
      "hun\n",
      "ir\n",
      "com\n",
      "liv\n",
      "ot\n",
      "mr\n",
      "ke\n",
      "le\n",
      "civ\n",
      "ll\n",
      "feb\n",
      "mer\n",
      "ve\n",
      "len\n",
      "hm\n",
      "fd\n",
      "eid\n",
      "ter\n",
      "liv\n",
      "im\n",
      "ci\n",
      "ot\n",
      "ii\n",
      "tm\n",
      "et\n",
      "les\n",
      "ino\n",
      "im\n",
      "est\n",
      "que\n",
      "ter\n",
      "lv\n",
      "lv\n",
      "mm\n",
      "des\n",
      "pm\n",
      "ix\n",
      "du\n",
      "est\n",
      "ve\n",
      "ir\n",
      "hor\n",
      "ot\n",
      "mr\n",
      "est\n",
      "ov\n",
      "ter\n",
      "ve\n",
      "nd\n",
      "mia\n",
      "iii\n",
      "ke\n",
      "fo\n",
      "im\n",
      "xx\n",
      "ke\n",
      "hun\n",
      "des\n",
      "et\n",
      "xii\n",
      "suc\n",
      "nd\n",
      "du\n",
      "hm\n",
      "mr\n",
      "ful\n",
      "pos\n",
      "est\n",
      "ii\n",
      "una\n",
      "ll\n",
      "ful\n",
      "usd\n",
      "com\n",
      "ful\n",
      "pos\n",
      "xl\n",
      "mm\n",
      "lv\n",
      "ll\n",
      "fd\n",
      "pm\n",
      "au\n",
      "ew\n",
      "del\n",
      "wel\n",
      "pos\n",
      "ive\n",
      "ned\n",
      "mer\n",
      "nd\n",
      "le\n",
      "com\n",
      "hes\n",
      "hor\n",
      "mia\n",
      "fo\n",
      "lx\n",
      "ino\n",
      "len\n",
      "iv\n",
      "xvi\n",
      "ve\n",
      "mm\n",
      "len\n",
      "fm\n",
      "ci\n",
      "les\n",
      "je\n",
      "fd\n",
      "vii\n",
      "im\n",
      "civ\n",
      "td\n",
      "je\n",
      "ida\n",
      "le\n",
      "ir\n",
      "le\n",
      "hor\n",
      "fo\n",
      "et\n",
      "ll\n"
     ]
    }
   ],
   "source": [
    "for index in lg.blacklist_index:\n",
    "    print(lg.enc.decode([index]).lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "\"\n",
      "#\n",
      "$\n",
      "%\n",
      "&\n",
      "'\n",
      "(\n",
      ")\n",
      "*\n",
      "+\n",
      "-\n",
      "/\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      ":\n",
      ";\n",
      "<\n",
      "=\n",
      ">\n",
      "?\n",
      "@\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "j\n",
      "k\n",
      "p\n",
      "r\n",
      "s\n",
      "t\n",
      "v\n",
      "w\n",
      "x\n",
      "[\n",
      "\\\n",
      "]\n",
      "^\n",
      "_\n",
      "`\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "j\n",
      "k\n",
      "p\n",
      "r\n",
      "s\n",
      "t\n",
      "v\n",
      "w\n",
      "x\n",
      "{\n",
      "|\n",
      "}\n",
      "~\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "\u0000\n",
      "\u0001\n",
      "\u0002\n",
      "\u0003\n",
      "\u0004\n",
      "\u0005\n",
      "\u0006\n",
      "\u0007\n",
      "\b\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u000e\n",
      "\u000f\n",
      "\u0010\n",
      "\u0011\n",
      "\u0012\n",
      "\u0013\n",
      "\u0014\n",
      "\u0015\n",
      "\u0016\n",
      "\u0017\n",
      "\u0018\n",
      "\u0019\n",
      "\u001a\n",
      "\u001b\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "�\n",
      "t\n",
      "er\n",
      "s\n",
      "w\n",
      "en\n",
      "f\n",
      "ing\n",
      "p\n",
      "ou\n",
      "al\n",
      "ar\n",
      "h\n",
      "ic\n",
      "th\n",
      "om\n",
      "ll\n",
      "st\n",
      "e\n",
      "ro\n",
      "ly\n",
      "g\n",
      "t\n",
      "ct\n",
      "s\n",
      "ut\n",
      "ow\n",
      "ad\n",
      "se\n",
      "ig\n",
      "ver\n",
      "ur\n",
      "ld\n",
      "st\n",
      "ation\n",
      "ith\n",
      "ir\n",
      "ce\n",
      "il\n",
      "wh\n",
      "ol\n",
      "p\n",
      "1\n",
      "ch\n",
      "(\n",
      "nd\n",
      "2\n",
      "ag\n",
      "ers\n",
      "\"\n",
      "h\n",
      "w\n",
      "r\n",
      "r\n",
      "od\n",
      "f\n",
      "ul\n",
      "ri\n",
      "pp\n",
      "se\n",
      "ain\n",
      "igh\n",
      "ist\n",
      "ab\n",
      "rom\n",
      "th\n",
      "g\n",
      "op\n",
      "00\n",
      "ess\n",
      "ex\n",
      "v\n",
      "res\n",
      "e\n",
      "ew\n",
      "ity\n",
      "el\n",
      "os\n",
      "ort\n",
      "oc\n",
      "qu\n",
      "su\n",
      "ive\n",
      "ould\n",
      "sh\n",
      "nt\n",
      "ra\n",
      "pe\n",
      "ight\n",
      "ment\n",
      "al\n",
      "ust\n",
      "--\n",
      "ack\n",
      "ch\n",
      "ies\n",
      "ard\n",
      "�\n",
      "j\n",
      "ab\n",
      "iv\n",
      "ost\n",
      "gh\n",
      "pt\n",
      "pl\n",
      "ast\n",
      "ak\n",
      "ome\n",
      "ud\n",
      "ge\n",
      "'t\n",
      "rou\n",
      "j\n",
      "wor\n",
      "ect\n",
      "k\n",
      "ame\n",
      "ok\n",
      "whe\n",
      "ide\n",
      "01\n",
      "ff\n",
      "ich\n",
      "pl\n",
      "ther\n",
      "tr\n",
      "..\n",
      "int\n",
      "ie\n",
      "ure\n",
      "ial\n",
      "ap\n",
      "ine\n",
      "ans\n",
      "ong\n",
      "ions\n",
      "k\n",
      "ad\n",
      "3\n",
      "ated\n",
      "ous\n",
      "ue\n",
      "og\n",
      "st\n",
      "ind\n",
      "ike\n",
      "ime\n",
      ".\"\n",
      "ber\n",
      "iz\n",
      "-\n",
      "cc\n",
      "th\n",
      "cl\n",
      "ep\n",
      "ake\n",
      "ip\n",
      "cont\n",
      "ia\n",
      "ub\n",
      "en\n",
      "comp\n",
      ",\"\n",
      "ag\n",
      "ire\n",
      "ary\n",
      "ry\n",
      "�\n",
      "cl\n",
      "ook\n",
      "v\n",
      "ign\n",
      "ven\n",
      "ile\n",
      "ose\n",
      "ite\n",
      "orm\n",
      "201\n",
      "res\n",
      "ord\n",
      "ult\n",
      "ase\n",
      "ance\n",
      "ks\n",
      "ays\n",
      "ence\n",
      "dis\n",
      "ction\n",
      "app\n",
      "sp\n",
      "int\n",
      "ress\n",
      "ations\n",
      "4\n",
      "ical\n",
      "ount\n",
      "ch\n",
      "ar\n",
      "pe\n",
      "av\n",
      "ough\n",
      "ach\n",
      "ru\n",
      "ond\n",
      "ick\n",
      "vel\n",
      "qu\n",
      "\n",
      "sc\n",
      "reat\n",
      "ree\n",
      "ound\n",
      "fter\n",
      "kn\n",
      "bec\n",
      "ens\n",
      "5\n",
      "ople\n",
      "ang\n",
      "----\n",
      "ory\n",
      "ition\n",
      "ings\n",
      "0\n",
      "ents\n",
      "ove\n",
      "rec\n",
      "tw\n",
      "ian\n",
      "irst\n",
      "ark\n",
      "ors\n",
      "ade\n",
      "ob\n",
      "wn\n",
      "lic\n",
      "19\n",
      "ish\n",
      "nder\n",
      "ause\n",
      "ons\n",
      "[\n",
      "ro\n",
      "ild\n",
      "ates\n",
      "vers\n",
      "oll\n",
      "spe\n",
      "ck\n",
      "amp\n",
      "acc\n",
      "bl\n",
      "ious\n",
      "ft\n",
      "ood\n",
      "hed\n",
      "'\n",
      "aw\n",
      "att\n",
      "ov\n",
      "erv\n",
      "ict\n",
      "itt\n",
      "6\n",
      "$\n",
      "ec\n",
      "hing\n",
      "ual\n",
      "ull\n",
      "comm\n",
      "oy\n",
      "ces\n",
      "ater\n",
      "fe\n",
      "iff\n",
      "ock\n",
      ").\n",
      "ident\n",
      "sel\n",
      "xt\n",
      "ph\n",
      "iss\n",
      "ject\n",
      "inc\n",
      "pol\n",
      "ont\n",
      "clud\n",
      "tern\n",
      "co\n",
      "7\n",
      "ning\n",
      "iew\n",
      "ced\n",
      "ind\n",
      "ty\n",
      "ath\n",
      "pr\n",
      "fl\n",
      "ng\n",
      "–\n",
      "ise\n",
      "ower\n",
      "oss\n",
      "uch\n",
      "=\n",
      "ied\n",
      "rit\n",
      "inv\n",
      "lect\n",
      "supp\n",
      "ating\n",
      "pect\n",
      "8\n",
      "bu\n",
      "ific\n",
      "ily\n",
      "diff\n",
      "rem\n",
      "th\n",
      "ev\n",
      "'re\n",
      "rel\n",
      "ss\n",
      "def\n",
      "sy\n",
      "),\n",
      "000\n",
      "tr\n",
      "__\n",
      "10\n",
      "ased\n",
      "ublic\n",
      "reg\n",
      "ix\n",
      "includ\n",
      "imp\n",
      "oth\n",
      "sub\n",
      "—\n",
      "arg\n",
      "wh\n",
      "==\n",
      "ible\n",
      "ange\n",
      "9\n",
      "ert\n",
      "ps\n",
      "ited\n",
      "ational\n",
      "br\n",
      "aking\n",
      "uring\n",
      "ities\n",
      "ph\n",
      "ics\n",
      "als\n",
      "dec\n",
      "ative\n",
      "ener\n",
      "ility\n",
      "erson\n",
      "ason\n",
      "ting\n",
      "ef\n",
      "ys\n",
      "bel\n",
      "sm\n",
      "prov\n",
      "ife\n",
      "ments\n",
      "ble\n",
      "pres\n",
      "ms\n",
      "omet\n",
      "ob\n",
      "sh\n",
      "ts\n",
      "ful\n",
      "eff\n",
      "gu\n",
      "inst\n",
      "und\n",
      "ren\n",
      "cess\n",
      "ince\n",
      "tt\n",
      "olog\n",
      "|\n",
      "ump\n",
      "hel\n",
      "vern\n",
      "ular\n",
      "ually\n",
      "mon\n",
      "200\n",
      "10\n",
      "ures\n",
      "ar\n",
      "ars\n",
      "meric\n",
      "ues\n",
      "cy\n",
      "min\n",
      "ollow\n",
      "col\n",
      "hes\n",
      "ier\n",
      "—\n",
      "ank\n",
      "atch\n",
      "str\n",
      "ork\n",
      "ool\n",
      "alk\n",
      "ement\n",
      "ract\n",
      "ween\n",
      "oun\n",
      "al\n",
      "ci\n",
      "differe\n",
      "--------\n",
      "cept\n",
      "sim\n",
      "...\n",
      "ek\n",
      "produ\n",
      "num\n",
      "imes\n",
      "se\n",
      "//\n",
      "ret\n",
      "ref\n",
      "trans\n",
      "ner\n",
      "ution\n",
      "ters\n",
      "cl\n",
      "conf\n",
      "sl\n",
      "ug\n",
      "americ\n",
      "spec\n",
      "ists\n",
      "oot\n",
      "az\n",
      "ather\n",
      "exp\n",
      "op\n",
      "ins\n",
      "gr\n",
      "requ\n",
      "ets\n",
      "ins\n",
      "ism\n",
      "ata\n",
      "ames\n",
      "pr\n",
      "'ve\n",
      "somet\n",
      "ser\n",
      ":\n",
      "irect\n",
      "det\n",
      "ices\n",
      "12\n",
      "mem\n",
      "cr\n",
      "ered\n",
      "ex\n",
      "ext\n",
      "uth\n",
      "ense\n",
      "co\n",
      "ving\n",
      "ouse\n",
      "att\n",
      "ved\n",
      "der\n",
      "ives\n",
      "min\n",
      "bl\n",
      "cur\n",
      "velop\n",
      "cour\n",
      "alth\n",
      "ize\n",
      "ode\n",
      "'m\n",
      "12\n",
      "....\n",
      "ness\n",
      "ying\n",
      "serv\n",
      "wom\n",
      "med\n",
      "ody\n",
      "50\n",
      "exper\n",
      "akes\n",
      "che\n",
      "cre\n",
      "ines\n",
      "rep\n",
      "19\n",
      "gg\n",
      "illion\n",
      "grou\n",
      "ute\n",
      "ik\n",
      "er\n",
      "ern\n",
      "ized\n",
      "ared\n",
      "fam\n",
      "ically\n",
      "happ\n",
      "char\n",
      "med\n",
      "gener\n",
      "ient\n",
      "ple\n",
      "iet\n",
      "11\n",
      "ves\n",
      "ption\n",
      "20\n",
      "cor\n",
      "offic\n",
      "ield\n",
      "ision\n",
      "inf\n",
      "oad\n",
      "prog\n",
      "ric\n",
      "**\n",
      "loc\n",
      "'ll\n",
      "poss\n",
      "stat\n",
      "ret\n",
      "val\n",
      "iss\n",
      "cle\n",
      "ivers\n",
      "anc\n",
      "expl\n",
      "av\n",
      "nce\n",
      "wh\n",
      "ired\n",
      "ittle\n",
      "dep\n",
      "�\n",
      "orn\n",
      "bers\n",
      "ross\n",
      "ad\n",
      "fr\n",
      "resp\n",
      "/\n",
      "&\n",
      "comple\n",
      "fil\n",
      "aj\n",
      "uc\n",
      "dist\n",
      "prot\n",
      "20\n",
      "ience\n",
      "contro\n",
      "18\n",
      "chool\n",
      "ott\n",
      "incre\n",
      "ote\n",
      "ty\n",
      "erest\n",
      "contin\n",
      "201\n",
      ")\n",
      "opp\n",
      "30\n",
      "iness\n",
      "st\n",
      "gl\n",
      "<\n",
      "ording\n",
      "ately\n",
      "ital\n",
      "el\n",
      "riend\n",
      "tra\n",
      "inal\n",
      "pri\n",
      "\":\n",
      "ains\n",
      "ature\n",
      "#\n",
      "ider\n",
      "fr\n",
      "soc\n",
      "pur\n",
      "ron\n",
      "15\n",
      "15\n",
      "commun\n",
      "wr\n",
      "app\n",
      "ained\n",
      "ead\n",
      "appro\n",
      "tri\n",
      "osed\n",
      "sp\n",
      "sk\n",
      "+\n",
      "partic\n",
      "pl\n",
      "ably\n",
      "uck\n",
      "ished\n",
      "chn\n",
      "ator\n",
      "adv\n",
      "ruct\n",
      "dem\n",
      "ling\n",
      "gy\n",
      "reen\n",
      "ger\n",
      "data\n",
      "11\n",
      "proble\n",
      "ards\n",
      "beh\n",
      "ral\n",
      "arge\n",
      "--\n",
      "://\n",
      "bro\n",
      "ph\n",
      "ats\n",
      "ww\n",
      "ided\n",
      "ases\n",
      "ency\n",
      "ined\n",
      "{\n",
      "x\n",
      "eas\n",
      "aining\n",
      "…\n",
      "var\n",
      "ide\n",
      "rece\n",
      "polit\n",
      "mov\n",
      "iving\n",
      "14\n",
      "sc\n",
      "ised\n",
      "unt\n",
      "oney\n",
      "ploy\n",
      "====\n",
      "didn\n",
      "ind\n",
      "els\n",
      "ertain\n",
      "____\n",
      "iver\n",
      "ified\n",
      "rep\n",
      "16\n",
      "uro\n",
      "ology\n",
      "atter\n",
      "ina\n",
      "vious\n",
      "bs\n",
      "sc\n",
      "ird\n",
      "bre\n",
      "ee\n",
      "dri\n",
      "uthor\n",
      "ides\n",
      "ention\n",
      "mil\n",
      "16\n",
      "iven\n",
      "raph\n",
      "ror\n",
      "ently\n",
      "ex\n",
      "ream\n",
      "sh\n",
      "14\n",
      "ission\n",
      "ality\n",
      "13\n",
      "chang\n",
      "bo\n",
      "vis\n",
      "ember\n",
      "25\n",
      "pped\n",
      "const\n",
      "arn\n",
      "ar\n",
      "ior\n",
      "ium\n",
      "orth\n",
      "18\n",
      "ailable\n",
      "sw\n",
      "13\n",
      "atic\n",
      "ted\n",
      "oper\n",
      "eng\n",
      "ajor\n",
      "conom\n",
      "comm\n",
      "ured\n",
      "ural\n",
      "aff\n",
      "ush\n",
      "ane\n",
      "eg\n",
      "prof\n",
      "outh\n",
      "ional\n",
      ".,\n",
      "30\n",
      "charact\n",
      "ians\n",
      "icle\n",
      "'d\n",
      "prom\n",
      "hist\n",
      "ither\n",
      "iqu\n",
      "17\n",
      "ohn\n",
      "oint\n",
      "lection\n",
      "augh\n",
      "ived\n",
      "techn\n",
      "par\n",
      "2016\n",
      "rist\n",
      "ering\n",
      "�\n",
      "acy\n",
      "ccess\n",
      "199\n",
      "doesn\n",
      "17\n",
      "rese\n",
      "\",\n",
      "ury\n",
      "equ\n",
      "alf\n",
      "nect\n",
      "iversity\n",
      "occ\n",
      "fl\n",
      "dev\n",
      "bas\n",
      "col\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for index in range(50257):\n",
    "    word = lg.enc.decode([index]).lower().strip()\n",
    "    if word not in lg.words_to_pos or word not in lg.dict_meters:\n",
    "        print(word)\n",
    "        count += 1\n",
    "        if count == 1000:\n",
    "            break\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NNS']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "({'anne': {'madman', 'ran', 'can', 'van', 'japan', 'tan', 'man', 'fisherman', 'klan', 'san', 'chan', 'than', 'pan', 'suntan', 'caveman', 'milan', 'gan', 'anchorman', 'fan', 'ban', 'divan', 'kan', 'helmsman', 'began', 'dan', 'businessman', 'journeyman', 'afghan', 'sedan', 'ann', 'clan', 'an', 'caravan', 'clergyman', 'plan', 'scan', 'span'}, 'flor': {'hoar', 'lore', 'score', 'corps', 'ashore', 'nor', 'sore', 'folklore', 'decor', 'fore', 'seashore', 'snore', 'tore', 'before', 'boar', 'chore', 'evermore', 'soar', 'swore', 'therefor', 'four', 'gore', 'sophomore', 'adore', 'shore', 'outdoor', 'oar', 'salvador', 'door', 'mentor', 'pore', 'roar', 'pour', 'dinosaur', 'store', 'rapport', 'drawer', 'therefore', 'indoor', 'sycamore', 'core', 'bore', 'anymore', 'floor', 'yore', 'troubadour', 'labrador', 'ore', 'furthermore', 'ignore', 'matador', 'abhor', 'for', 'war', 'or', 'wore', 'more', 'uproar', 'your', 'whore', 'tor', 'centaur', 'explore', 'encore', 'restore'}}, {'collection': {'selection', 'perfection', 'section', 'connection', 'midsection', 'reflection', 'affection', 'objection', 'direction', 'dissection', 'infection', 'injection', 'rejection', 'inflection', 'inspection', 'complexion', 'correction', 'projection', 'defection', 'protection', 'election', 'detection'}, 'hall': {'forestall', 'sol', 'fall', 'thrall', 'small', 'pall', 'cabal', 'doll', 'fireball', 'basketball', 'haul', 'loll', 'gall', 'protocol', 'natal', 'baseball', 'brawl', 'senegal', 'banal', 'waterfall', 'sprawl', 'ball', 'football', 'scrawl', 'all', 'overall', 'mall', 'eyeball', 'nightfall', 'paul', 'tall', 'maul', 'alcohol', 'call', 'gaul', 'wall', 'shawl', 'stall', 'recall', 'downfall', 'wherewithal', 'crawl', 'hardball', 'ethanol', 'footfall', 'appall'}})\n"
     ]
    }
   ],
   "source": [
    "print(lg.poetic_vectors.similarity('library', 'library'))\n",
    "print(lg.get_two_sets_henry('library', 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "['there', 'was', 'a', 'humble', 'man', 'named', 'beau']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "['who', 'spent', 'decades', 'in', 'the', 'shadow']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"hurricane\", \"hurricane\",\n",
    "                       prompt_length=100, search_space=150, story_line=True,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'DT', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ],enforce_syllables = True, enforce_stress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['there', 'was', 'a', 'kind', 'lady', 'named', 'mary']\n",
    ",['who', 'was', 'friends', 'with', 'a', 'loan']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "possible_syllables = ['01','00']\n",
    "stress_syllable_pos = 0\n",
    "print(all(s[stress_syllable_pos] != '1' for s in possible_syllables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from py_files.Limericks_new2 import Limerick_Generate_new\n",
    "lg = Limerick_Generate_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Madlib Verbs ------\n",
      "{'VBD': ['lived', 'put', 'changed', 'learned', 'spent', 'thought', 'wrote', 'imagined', 'inspired', 'loved', 'wanted', 'saved', 'devoted', 'brought', 'worked', 'did', 'happened', 'transformed', 'meant', 'got'], 'VBN': ['lived', 'come', 'put', 'changed', 'given', 'learned', 'gone', 'spent', 'thought', 'imagined', 'done', 'loved', 'taken', 'seen', 'become', 'saved', 'devoted', 'brought', 'worked', 'been'], 'VB': ['work', 'come', 'look', 'care', 'live', 'understand', 'help', 'get', 'go', 'make', 'be', 'put', 'do', 'imagine', 'stay', 'take', 'survive', 'tell', 'learn', 'know'], 'VBZ': ['lives', 'does', 'works', 'seems', 'has', 'loves', 'tells', 'takes', 'goes', 'needs', 'makes', 'knows', 'looks', 'happens', 'means', 'finds', 'explains', 'comes', 'values', 'brings'], 'VBP': ['work', 'come', 'look', 'live', 'understand', 'help', 'get', 'go', 'make', 'hope', 'do', 'imagine', 'stay', 'take', 'survive', 'tell', 'know', 'see', 'find', 'have'], 'VBG': ['living', 'having', 'being', 'working', 'seeing', 'dying', 'doing', 'going', 'writing', 'saving', 'learning', 'thinking', 'knowing', 'finding', 'understanding', 'looking', 'loving', 'telling', 'caring', 'watching']}\n",
      "============= w1s_rhyme_dict=====================\n",
      "{'sol': ['haul', 'shawl', 'appall', 'fall', 'ball', 'football', 'forestall', 'small', 'baseball', 'all', 'crawl', 'banal', 'call', 'loll', 'recall', 'wall'], 'rea': ['dismay', 'day', 'way', 'halfway', 'okay', 'convey', 're', 'pay', 'birthday', 'friday', 'display', 'today', 'lay', 'sway', 'spray', 'hey', 'survey', 'betray', 'array', 'say', 'prey', 'may', 'relay', 'repay', 'pray', 'away', 'sunday', 'obey', 'stay', 'delay', 'they', 'weigh', 'play'], 'scott': ['cannot', 'caught', 'forgot', 'lot', 'got', 'bought', 'ought', 'shot', 'fraught', 'hot', 'thought', 'spot', 'scott', 'taught', 'naught', 'fought', 'squat', 'not', 'pot', 'sought', 'brought'], 'noe': ['sew', 'go', 'know', 'borrow', 'slow', 'forgo', 'whoa', 'dough', 'toe', 'row', 'owe', 'blow', 'although', 'photo', 'hello', 'so', 'grow', 'though', 'below', 'mow', 'solo', 'throw', 'low', 'no', 'bestow', 'show', 'flow', 'glow'], 'mack': ['lack', 'crack', 'setback', 'pack', 'rack', 'attack', 'back', 'comeback', 'smack', 'track', 'snack', 'feedback', 'soundtrack', 'black'], 'ed': ['red', 'dread', 'bloodshed', 'dead', 'fled', 'lead', 'head', 'fed', 'led', 'sped', 'said', 'bread', 'ahead', 'instead', 'widespread', 'bed', 'spread', 'read', 'thread'], 'elayne': ['pain', 'contain', 'regain', 'maintain', 'retain', 'grain', 'vain', 'explain', 'refrain', 'disdain', 'gain', 'train', 'rein', 'brain', 'wane', 'ordain', 'attain', 'detain', 'main', 'terrain', 'obtain', 'rain', 'stain', 'remain', 'arcane', 'restrain', 'deign', 'campaign', 'drain', 'plane', 'inane', 'complain', 'again', 'sustain', 'abstain'], 'noreen': ['keen', 'demean', 'scene', 'caffeine', 'green', 'careen', 'foreseen', 'mean', 'cuisine', 'seen', 'between', 'glean', 'screen', 'routine', 'lean', 'clean'], 'rod': ['awed', 'flawed', 'broad', 'nod', 'fraud', 'plod', 'odd', 'facade', 'squad', 'applaud', 'god', 'abroad'], 'gale': ['bail', 'scale', 'prevail', 'entail', 'wholesale', 'rail', 'tail', 'tale', 'jail', 'sale', 'trail', 'fail', 'wail', 'flail', 'blackmail', 'detail', 'mail', 'inhale', 'unveil', 'sail'], 'manuel': ['expel', 'dispel', 'fell', 'dwell', 'hell', 'propel', 'swell', 'hotel', 'smell', 'sell', 'quell', 'compel', 'tell', 'farewell', 'yell', 'gel', 'rebel', 'spell', 'well', 'repel', 'cell'], 'aimee': ['we', 'he', 'key', 'be', 'fee', 't', 'thee', 'ski', 'pre', 'free', 'tv', 'knee', 'agree', 'three', 'plea', 'debris', 'sea', 'she', 'foresee', 'see', 've', 'sunday', 'me', 'decree', 'flee'], 'kyle': ['file', 'trial', 'worthwhile', 'style', 'exile', 'smile', 'compile', 'awhile', 'while', 'meanwhile', 'spile', 'tile', 'profile', 'beguile', 'mile', 'guile', 'pile'], 'flor': ['gore', 'score', 'yore', 'explore', 'shore', 'snore', 'adore', 'uproar', 'ignore', 'or', 'pour', 'door', 'soar', 'store', 'abhor', 'more', 'four', 'restore', 'therefore', 'swore', 'therefor', 'before', 'decor', 'war', 'wore', 'roar', 'ashore', 'your', 'for', 'core', 'nor'], 'gil': ['will', 'still', 'uphill', 'downhill', 'until', 'spill', 'chill', 'thrill', 'dill', 'till', 'bill', 'kill', 'fill', 'shrill', 'refill', 'grill', 'fulfill', 'skill'], 'leann': ['pan', 'an', 'ban', 'plan', 'than', 'began', 'can', 'man', 'japan', 'ran'], 'heide': ['wide', 'side', 'upside', 'subside', 'ride', 'defied', 'confide', 'slide', 'divide', 'guide', 'reside', 'provide', 'implied', 'decide', 'outside', 'bide', 'beside', 'worldwide', 'complied', 'hide', 'lied', 'tied', 'applied', 'aside', 'chide', 'pride', 'abide', 'inside', 'eyed', 'preside', 'dried', 'denied', 'tried', 'deride'], 'nick': ['thick', 'trick', 'picnic', 'sick', 'quick', 'stick', 'pick', 'click', 'kick', 'lick'], 'brent': ['frequent', 'percent', 'meant', 'tent', 'spent', 'invent', 'ascent', 'prevent', 'content', 'rent', 'sent', 'scent', 'consent', 'lament', 'torment', 'resent', 'repent', 'event', 'present', 'went', 'intent', 'extent', 'shent', 'relent', 'blent'], 'tyrone': ['shown', 'bone', 'condone', 'grown', 'unknown', 'phone', 'flown', 'groan', 'known', 'alone', 'sewn', 'thrown', 'atone', 'blown', 'postpone', 'tone', 'hone', 'loan', 'own'], 'lavette': ['whet', 'forget', 'debt', 'bet', 'jet', 'net', 'mindset', 'regret', 'let', 'threat', 'get', 'met', 'set', 'fret', 'upset', 'offset', 'beset', 'yet', 'sweat'], 'raul': ['haul', 'shawl', 'growl', 'prowl', 'appall', 'fall', 'ball', 'football', 'foul', 'forestall', 'small', 'baseball', 'fool', 'fuel', 'howl', 'all', 'school', 'crawl', 'banal', 'call', 'cruel', 'cool', 'loll', 'tool', 'pool', 'towel', 'scowl', 'recall', 'rule', 'wall'], 'clair': ['spare', 'compare', 'err', 'declare', 'where', 'blare', 'pear', 'impair', 'nowhere', 'welfare', 'aware', 'wear', 'prayer', 'fare', 'glare', 'software', 'there', 'scare', 'repair', 'despair', 'pair', 'stare', 'dare', 'nightmare', 'hardware', 'rare', 'bear', 'hair', 'swear', 'share', 'elsewhere', 'their', 'prepare', 'beware', 'air', 'fair', 'care', 'tear', 'unfair'], 'kurt': ['divert', 'avert', 'dessert', 'blurt', 'subvert', 'exert', 'concert', 'assert', 'dirt', 'skirt', 'alert', 'shirt', 'convert', 'insert', 'hurt', 'flirt'], 'chi': ['eye', 'hereby', 'supply', 'whereby', 'defy', 'thereby', 'reply', 'wry', 'by', 'tie', 'buy', 'rely', 'imply', 'dry', 'fly', 'ply', 'nearby', 'decry', 'cry', 'deny', 'i', 'lie', 'try', 'high', 'my', 'comply', 'guy', 'pie', 'pry', 'sigh', 'goodbye', 'die', 'apply', 'fry', 'why'], 'yu': ['blue', 'review', 'renew', 'stew', 'coup', 'due', 'chew', 'spew', 'crew', 'two', 'breakthrough', 'new', 'too', 'you', 'view', 'imbue', 'q', 'anew', 'pursue', 'sue', 'through', 'eschew', 'who', 'true', 'tissue', 'screw', 'undue', 'few', 'do', 'to', 'clue', 'subdue', 'into', 'debut', 'undo'], 'max': ['slacks', 'facts', 'snacks', 'relax', 'acts', 'knickknacks', 'backs', 'attacks', 'contacts', 'tracks', 'lacks', 'tax'], 'dwight': ['midnight', 'bright', 'incite', 'despite', 'quite', 'write', 'sight', 'slight', 'site', 'outright', 'tight', 'fight', 'delight', 'bite', 'smite', 'highlight', 'height', 'right', 'unite', 'website', 'light', 'invite', 'recite', 'might', 'downright', 'contrite', 'ignite', 'night', 'flight', 'white', 'finite', 'spite', 'trite', 'polite', 'spotlight', 'rewrite'], 'adelaide': ['parade', 'located', 'betrayed', 'degrade', 'frayed', 'fade', 'delayed', 'trade', 'played', 'raid', 'evade', 'decade', 'invade', 'afraid', 'displayed', 'portrayed', 'made', 'stayed', 'forbade', 'conveyed', 'paid', 'pervade', 'aid', 'splayed', 'dissuade', 'persuade'], 'lin': ['thin', 'when', 'grin', 'spin', 'begin', 'skin', 'within', 'in', 'been', 'win'], 'rex': ['projects', 'expects', 'sex', 'checks', 'necks', 'respects', 'reflects', 'complex', 'suspects', 'next', 'objects', 'subjects', 'effects'], 'blake': ['forsake', 'take', 'betake', 'stake', 'slake', 'wake', 'cake', 'ache', 'steak', 'shake', 'mistake', 'awake', 'make', 'partake', 'break', 'sake', 'brake', 'bake'], 'pete': ['street', 'heat', 'treat', 'deplete', 'unseat', 'eat', 'beat', 'neat', 'compete', 'meet', 'sweet', 'complete', 'feet', 'repeat', 'upbeat', 'athlete', 'retreat', 'sheet', 'digit', 'greet', 'concrete', 'meat', 'fleet', 'defeat'], 'salvatore': ['gore', 'score', 'restore', 'yore', 'explore', 'shore', 'adore', 'therefore', 'therefor', 'before', 'uproar', 'ignore', 'decor', 'war', 'glory', 'wore', 'roar', 'or', 'your', 'for', 'pour', 'door', 'soar', 'store', 'abhor', 'more', 'four', 'core', 'story', 'nor'], 'will': ['still', 'uphill', 'downhill', 'until', 'spill', 'chill', 'thrill', 'dill', 'till', 'bill', 'kill', 'fill', 'dull', 'shrill', 'refill', 'grill', 'fulfill', 'skill'], 'bess': ['press', 'success', 'depress', 'redress', 'bless', 'unless', 'excess', 'guess', 'assess', 'progress', 'suppress', 'mess', 'profess', 'oppress', 'requests', 'possess', 'caress', 'repress', 'confess', 'yes', 'address', 'stress', 'impress', 'express', 'protests', 'access', 'dress', 'less', 'process'], 'grace': ['apace', 'disgrace', 'case', 'erase', 'someplace', 'chase', 'replace', 'race', 'trace', 'displace', 'face', 'space', 'deface', 'lace', 'base', 'staircase', 'pace', 'place', 'embrace'], 'un': ['spun', 'run', 'someone', 'won', 'than', 'fun', 'gun', 'outrun', 'begun', 'none', 'one', 'done', 'been', 'shun'], 'michel': ['expel', 'smell', 'sell', 'quell', 'compel', 'tell', 'cycle', 'farewell', 'dispel', 'yell', 'fell', 'dwell', 'gel', 'hell', 'rebel', 'spell', 'propel', 'well', 'swell', 'repel', 'cell', 'hotel'], 'dede': ['freed', 'plead', 'agreed', 'lead', 'speed', 'exceed', 'proceed', 'greed', 'indeed', 'fried', 'heed', 'need', 'succeed', 'pitied', 'feed', 'concede', 'recede', 'read', 'bleed', 'mislead'], 'nicole': ['whole', 'extol', 'bowl', 'poll', 'dole', 'stroll', 'roll', 'hole', 'charcoal', 'control', 'soul', 'role', 'goal'], 'gaylord': ['accord', 'reward', 'record', 'ignored', 'roared', 'poured', 'board', 'toward', 'aboard', 'adored', 'afford', 'cardboard', 'scored', 'stored', 'bored', 'soared'], 'bok': ['gawk', 'block', 'rock', 'balk', 'flock', 'dock', 'walk', 'shock', 'knock', 'talk', 'sidewalk', 'stock', 'clock'], 'cruz': ['thews', 'statues', 'defuse', 'whose', 'clues', 'suffuse', 'abuse', 'accuse', 'infuse', 'crews', 'jews', 'cruise', 'lose', 'misuse', 'choose', 'ooze', 'refuse', 'excuse', 'diffuse', 'news', 'views', 'shoes', 'peruse', 'tissues', 'amuse', 'confuse'], 'jacques': ['gawk', 'block', 'lack', 'rock', 'balk', 'flock', 'crack', 'dock', 'setback', 'pack', 'rack', 'attack', 'back', 'walk', 'shock', 'knock', 'smack', 'talk', 'track', 'snack', 'stock', 'clock', 'feedback', 'black'], 'veronique': ['technique', 'leak', 'peek', 'seek', 'sleek', 'squeak', 'peak', 'sneak', 'week', 'unique', 'streak', 'speak', 'shriek', 'critique', 'creak', 'weak'], 'ferdinand': ['firsthand', 'expand', 'command', 'band', 'stand', 'pan', 'an', 'ban', 'plan', 'than', 'banned', 'demand', 'brand', 'began', 'withstand', 'planned', 'can', 'man', 'japan', 'land', 'ran', 'hand'], 'kit': ['bit', 'permit', 'hit', 'spit', 'fit', 'admit', 'split', 'flit', 'knit', 'transmit', 'submit', 'omit', 'wit', 'commit', 'it', 'emit', 'sit', 'quit'], 'darline': ['resign', 'outline', 'design', 'line', 'airline', 'brine', 'combine', 'decline', 'enshrine', 'whine', 'online', 'define', 'sign', 'refine', 'shine', 'fine', 'confine', 'nine', 'deadline', 'dine', 'wine'], 'mose': ['pose', 'woes', 'hose', 'rows', 'throws', 'expose', 'shadows', 'chose', 'arose', 'prose', 'goes', 'toes', 'suppose', 'clothes', 'elbows', 'knows', 'blows', 'rose', 'those', 'propose', 'dispose', 'shows', 'doze', 'compose', 'depose', 'foes', 'enclose', 'flows', 'close', 'nose', 'photos', 'disclose', 'impose'], 'milan': ['dawn', 'gone', 'on', 'pan', 'upon', 'an', 'ban', 'plan', 'drawn', 'than', 'began', 'can', 'man', 'japan', 'non', 'ran'], 'jude': ['food', 'allude', 'viewed', 'exclude', 'cooed', 'imbued', 'seafood', 'exude', 'crude', 'intrude', 'spewed', 'construed', 'elude', 'include', 'protrude', 'renewed', 'pursued', 'chewed', 'mood', 'conclude', 'glued', 'endued'], 'jerrell': ['bail', 'trail', 'fail', 'wail', 'flail', 'scale', 'blackmail', 'prevail', 'entail', 'wholesale', 'detail', 'mail', 'rail', 'inhale', 'tail', 'tale', 'unveil', 'jail', 'sale', 'sail'], 'sharon': ['thrown', 'atone', 'shown', 'bone', 'blown', 'condone', 'grown', 'postpone', 'tone', 'unknown', 'hone', 'phone', 'flown', 'groan', 'known', 'alone', 'loan', 'sewn', 'own'], 'elouise': ['wheeze', 'seas', 'knees', 'ease', 'agrees', 'appease', 'sneeze', 'squeeze', 'chinese', 'disease', 'please', 'freeze', 'peas', 'tease', 'jeez', 'cheese', 'these', 'seize', 'sees', 'unease'], 'kate': ['state', 'create', 'rate', 'innate', 'late', 'weight', 'fate', 'relate', 'mandate', 'straight', 'freight', 'negate', 'great', 'spate', 'debate', 'date', 'wait'], 'celeste': ['confessed', 'depressed', 'guessed', 'contest', 'unrest', 'addressed', 'west', 'best', 'expressed', 'wrest', 'dressed', 'protest', 'stressed', 'oppressed', 'infest', 'lest', 'rest', 'guest', 'quest', 'pressed', 'obsessed', 'attest', 'arrest', 'impressed', 'blessed', 'molest', 'suggest', 'request', 'test', 'detest'], 'clementine': ['refine', 'shine', 'keen', 'demean', 'scene', 'sign', 'resign', 'green', 'careen', 'fine', 'confine', 'mean', 'cuisine', 'outline', 'nine', 'between', 'design', 'line', 'glean', 'deadline', 'screen', 'brine', 'combine', 'decline', 'enshrine', 'wine', 'whine', 'online', 'routine', 'lean', 'clean', 'define'], 'lise': ['fries', 'despise', 'size', 'rise', 'devise', 'disguise', 'allies', 'supplies', 'surprise', 'guys', 'eyes', 'wise', 'advise', 'ties', 'likewise', 'arise', 'surmise'], 'hyun': ['spun', 'run', 'someone', 'won', 'than', 'fun', 'gun', 'outrun', 'begun', 'none', 'one', 'done', 'been', 'shun'], 'francoise': ['laws', 'because', 'cause', 'pause', 'withdraw', 'saw', 'cars', 'draw', 'awe', 'applause', 'raw', 'law', 'was', 'guffaw', 'gnaw', 'claw'], 'chere': ['severe', 'jeer', 'unclear', 'steer', 'career', 'sear', 'cheer', 'sincere', 'gear', 'clear', 'rear', 'near', 'adhere', 'dear', 'fear', 'tear', 'appear', 'year', 'sneer'], 'sunday': ['dismay', 'day', 'we', 'three', 'way', 'plea', 'flee', 'key', 'array', 'say', 'prey', 'be', 'may', 'fee', 'convey', 're', 'pay', 'debris', 't', 'relay', 'sea', 'ski', 'foresee', 'see', 'free', 'away', 'tv', 'display', 'survey', 'stay', 'delay', 'lay', 'sway', 'agree', 'me', 'decree', 'betray', 'play'], 'yer': ['confer', 'spur', 'defer', 'purr', 'her', 'transfer', 'stir', 'were', 'concur', 'prefer', 'occur', 'refer', 'per'], 'brande': ['firsthand', 'expand', 'command', 'band', 'stand', 'banned', 'demand', 'brand', 'planned', 'land', 'withstand', 'hand']}\n",
      "=============== w3s_rhyme_dict ====================\n",
      "{'years': {'appears', 'cheers', 'occurs', 'fears', 'prefers'}, 'time': {'sometime', 'climb', 'meantime', 'lime', 'thyme'}, 'everything': {'sing', 'spring', 'cling', 'pling', 'thing', 'bring', 'wring'}, 'way': {'stay', 'obey', 'away', 'say', 're', 'hey', 'sunday', 'okay', 'weigh', 'play', 'convey', 'may', 'pray', 'friday', 'birthday', 'pay', 'they', 'lay', 'dismay', 'betray', 'day', 'repay', 'prey', 'today', 'delay'}, 'man': {'pan', 'ban', 'can', 'than', 'ran', 'began', 'plan', 'an'}, 'work': {'artwork', 'smirk', 'framework', 'network', 'lurk'}, 'mind': {'kind', 'defined', 'combined', 'behind', 'remind', 'inclined', 'find', 'declined', 'designed'}, 'childhood': {'stood', 'should', 'would', 'could', 'good'}, 'lifetime': {'sometime', 'climb', 'meantime', 'lime', 'time', 'thyme'}, 'kind': {'mind', 'defined', 'combined', 'behind', 'remind', 'inclined', 'find', 'declined', 'designed'}, 'fact': {'act', 'distract', 'impact', 'attract', 'intact', 'react', 'exact', 'contract', 'lacked', 'detract', 'pact', 'extract', 'contact'}, 'everyone': {'someone', 'won', 'than', 'begun', 'been', 'fun', 'done', 'one', 'none', 'run'}, 'days': {'phase', 'gaze', 'glaze', 'raise', 'always', 'phrase', 'graze', 'amaze', 'praise', 'ways'}, 'friends': {'tends', 'tens', 'trends', 'cleanse', 'pretends', 'depends', 'intends', 'ends'}, 'anything': {'sing', 'spring', 'cling', 'pling', 'thing', 'bring', 'wring'}, 'thing': {'sing', 'spring', 'cling', 'pling', 'bring', 'wring'}, 'sense': {'expense', 'condense', 'hence', 'commence'}, 'come': {'become', 'income', 'outcome', 'from', 'them', 'glum', 'some'}, 'decades': {'aides', 'fades'}, 'god': {'fraud', 'applaud', 'abroad', 'nod'}}\n",
      "=========================== Creating Wema =======================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************** multiprocessing starts with 4 processes *************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-10:\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-7:\n",
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks_new2.py\", line 567, in get_wema_dict\n",
      "    distances = [self.get_word_similarity(word, rhyme) for rhyme in rhyme_set]\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks_new2.py\", line 567, in <listcomp>\n",
      "    distances = [self.get_word_similarity(word, rhyme) for rhyme in rhyme_set]\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks.py\", line 179, in get_word_similarity\n",
      "    distances = [self.poetic_vectors.similarity(word, rhyme) for rhyme in rhyme_set if rhyme in self.words_to_pos]\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks.py\", line 179, in <listcomp>\n",
      "    distances = [self.poetic_vectors.similarity(word, rhyme) for rhyme in rhyme_set if rhyme in self.words_to_pos]\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\", line 955, in similarity\n",
      "    return dot(matutils.unitvec(self[w1]), matutils.unitvec(self[w2]))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b1e3159b53b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_poem_andre_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"life\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Poetix/poetix/py_files/Limericks_new2.py\u001b[0m in \u001b[0;36mgen_poem_andre_new\u001b[0;34m(self, prompt, search_space, retain_space, stress, prob_threshold)\u001b[0m\n\u001b[1;32m    180\u001b[0m                                 \u001b[0;32mdel\u001b[0m \u001b[0mw1s_rhyme_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=========================== Creating Wema =======================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_wema_dict_mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=========================== Finished Wema =======================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Poetix/poetix/py_files/Limericks_new2.py\u001b[0m in \u001b[0;36mget_wema_dict_mp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    535\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m                         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput_wema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwema_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\", line 347, in __getitem__\n",
      "    return self.get_vector(entities)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\", line 465, in get_vector\n",
      "    return self.word_vec(word)\n",
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks_new2.py\", line 567, in get_wema_dict\n",
      "    distances = [self.get_word_similarity(word, rhyme) for rhyme in rhyme_set]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks_new2.py\", line 567, in <listcomp>\n",
      "    distances = [self.get_word_similarity(word, rhyme) for rhyme in rhyme_set]\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks.py\", line 179, in get_word_similarity\n",
      "    distances = [self.poetic_vectors.similarity(word, rhyme) for rhyme in rhyme_set if rhyme in self.words_to_pos]\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks.py\", line 179, in <listcomp>\n",
      "    distances = [self.poetic_vectors.similarity(word, rhyme) for rhyme in rhyme_set if rhyme in self.words_to_pos]\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\", line 955, in similarity\n",
      "    return dot(matutils.unitvec(self[w1]), matutils.unitvec(self[w2]))\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks_new2.py\", line 567, in get_wema_dict\n",
      "    distances = [self.get_word_similarity(word, rhyme) for rhyme in rhyme_set]\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks_new2.py\", line 567, in <listcomp>\n",
      "    distances = [self.get_word_similarity(word, rhyme) for rhyme in rhyme_set]\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/gensim/matutils.py\", line 743, in unitvec\n",
      "    return blas_scal(1.0 / veclen, vec).astype(vec.dtype)\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks.py\", line 179, in get_word_similarity\n",
      "    distances = [self.poetic_vectors.similarity(word, rhyme) for rhyme in rhyme_set if rhyme in self.words_to_pos]\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks.py\", line 179, in <listcomp>\n",
      "    distances = [self.poetic_vectors.similarity(word, rhyme) for rhyme in rhyme_set if rhyme in self.words_to_pos]\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\", line 955, in similarity\n",
      "    return dot(matutils.unitvec(self[w1]), matutils.unitvec(self[w2]))\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/gensim/matutils.py\", line 738, in unitvec\n",
      "    if np.issubdtype(vec.dtype, np.integer):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/numpy/core/numerictypes.py\", line 394, in issubdtype\n",
      "    if not issubclass_(arg2, generic):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\", line 432, in word_vec\n",
      "    def word_vec(self, word, use_norm=False):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks_new2.py\", line 588, in get_wema_dict\n",
      "    distances = [self.get_word_similarity(word, rhyme) for rhyme in rhyme_set]\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks_new2.py\", line 588, in <listcomp>\n",
      "    distances = [self.get_word_similarity(word, rhyme) for rhyme in rhyme_set]\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks.py\", line 179, in get_word_similarity\n",
      "    distances = [self.poetic_vectors.similarity(word, rhyme) for rhyme in rhyme_set if rhyme in self.words_to_pos]\n",
      "  File \"/Users/isaac/Desktop/Poetix/poetix/py_files/Limericks.py\", line 179, in <listcomp>\n",
      "    distances = [self.poetic_vectors.similarity(word, rhyme) for rhyme in rhyme_set if rhyme in self.words_to_pos]\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\", line 955, in similarity\n",
      "    return dot(matutils.unitvec(self[w1]), matutils.unitvec(self[w2]))\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/gensim/matutils.py\", line 712, in unitvec\n",
      "    if scipy.sparse.issparse(vec):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/numpy/core/numerictypes.py\", line 328, in issubclass_\n",
      "    return issubclass(arg1, arg2)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\", line 1214, in isspmatrix\n",
      "    return isinstance(x, spmatrix)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "lg.gen_poem_andre_new(search_space=50, retain_space=5, prob_threshold=-10,prompt=\"life\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-fe6890a147be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50257\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_word_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m     \u001b[0;32mand\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwhitelist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mblacklist_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "import pickle\n",
    "\n",
    "word_list = words.words()\n",
    "word_list = set(word_list)\n",
    "\n",
    "whitelist = [\"'s\", 'has', 'jew', 'etc', 'tom', 'kid', 'jim', 'tv', 'uh', 'jr', 'dr', 'mrs', 'hid', 'tv',]\n",
    "blacklist_index = set()\n",
    "for index in range(50257):\n",
    "    word = lg.enc.decode([index]).lower().strip()\n",
    "    if word not in word_list and len(lg.get_word_pos(word)) > 0 \\\n",
    "    and 1 < len(word) < 4 and word not in whitelist:\n",
    "        blacklist_index.add(index)\n",
    "        print(word)\n",
    "pickle.dump(blacklist_index, open(\"py_files/saved_objects/blacklist_index.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from py_files.Limericks_new2 import Limerick_Generate_new\n",
    "lg = Limerick_Generate_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{8704, 23043, 3076, 27140, 8710, 28163, 13320, 35851, 1556, 21016, 25117, 47134, 4638, 13856, 545, 1569, 1059, 16418, 36905, 35882, 559, 10287, 3122, 3123, 21044, 46133, 5686, 4663, 6711, 38971, 47676, 574, 4670, 27713, 10818, 31811, 17990, 6217, 21065, 2123, 4173, 16975, 41041, 4178, 1619, 26196, 3158, 41560, 9306, 25690, 4188, 12381, 35420, 18015, 15972, 21604, 10343, 10855, 22631, 37997, 29296, 15479, 20088, 11895, 4216, 25211, 21628, 6780, 5246, 9858, 28290, 646, 647, 43145, 11403, 18574, 16017, 37522, 5781, 11925, 31383, 35480, 8358, 46246, 7336, 8874, 3755, 8363, 21676, 42667, 33967, 14514, 34482, 22196, 39095, 10426, 19643, 30910, 704, 8896, 709, 45766, 30920, 32457, 8906, 5324, 9932, 26830, 2767, 43213, 27859, 42707, 48345, 25306, 28378, 40666, 12509, 9440, 23264, 29922, 3813, 44773, 1770, 19691, 748, 5868, 36079, 3824, 21232, 11511, 43255, 47352, 20730, 22268, 30972, 8959, 30976, 2817, 5377, 33538, 12038, 18695, 17160, 19211, 3852, 5900, 23820, 785, 32020, 19740, 13599, 3873, 293, 47909, 297, 15146, 13102, 303, 12592, 25904, 30002, 31022, 15156, 17717, 1846, 37685, 313, 2873, 17209, 316, 829, 2879, 320, 6465, 15681, 28994, 24388, 29507, 20806, 5960, 4426, 844, 35660, 10062, 8016, 343, 27991, 2394, 17242, 22362, 46941, 353, 26979, 358, 44903, 46955, 365, 6513, 3955, 8051, 885, 5494, 2935, 12152, 39284, 6522, 8575, 7043, 23940, 43395, 28040, 1930, 395, 3978, 9613, 18315, 46476, 29072, 401, 913, 1426, 16276, 8085, 24981, 32660, 26009, 9114, 27548, 413, 49571, 5029, 28069, 425, 35754, 4017, 25524, 443, 955, 956, 6075, 32189, 6080, 44988, 46016, 30659, 452, 49090, 6089, 3020, 18896, 38353, 979, 11732, 11223, 16344, 45529, 3546, 36317, 8671, 40932, 41957, 2538, 14826, 1004, 17899, 19434, 17906, 3069}\n"
     ]
    }
   ],
   "source": [
    "print(lg.blacklist_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'PRP': [(('OF', 'THE', 'NN', 'VBN', 'IN', 'VBG', 'PRP'), ('of', 'the', 'bishop', 'engaged', 'in', 'confirming', \"'em\"), (7, 11)), (('AND', 'RB', 'THERE', 'VBD', 'JJ', 'JJ', 'IN', 'PRP'), ('and', 'right', 'there', 'became', 'awful', 'sick', 'in', \"'em\"), (8, 10)), (('WOULD', 'VB', 'VBD', 'THE', 'NN', 'VBN', 'FROM', 'PRP'), ('would', 'arise', 'were', 'the', 'kid', 'taken', 'from', 'us'), (8, 10)), (('BUT', 'A', 'NN', 'MD', 'RB', 'CAN', 'A', 'CAN', ',', 'CAN', 'PRP'), ('but', 'a', 'canner', 'ca', \"n't\", 'can', 'a', 'can', ',', 'can', 'he'), (10, 11))], 'POS': [(('THAT', 'THE', 'NN', 'VBD', 'RB', 'PRP$', 'NN', 'POS'), ('that', 'the', 'outfit', 'was', 'really', 'his', 'mama', \"'s\"), (8, 11)), (('NN', '.', 'NN', 'AT', 'THE', 'NN', 'ON', 'THE', 'NN', 'POS'), ('`oh', '!', 'look', 'at', 'the', 'legs', 'on', 'the', 'table', \"'\"), (9, 10)), (('PRP', 'CAN', 'RB', 'VB', 'NNS', 'IN', 'CD', 'NNS', 'POS'), ('you', 'can', \"n't\", 'put', 'toucans', 'in', 'two', 'cans', \"'\"), (9, 9)), (('AND', 'PRP', 'VBP', 'VBN', 'OUT', 'OF', 'NNS', 'BY', 'THE', 'NN', 'POS'), ('and', 'I', 'am', 'made', 'out', 'of', 'curds', 'by', 'the', 'whey', \"'\"), (11, 11)), (('VBZ', 'MORE', 'THAN', 'PRP$', 'JJ', 'NNS', 'POS'), ('is', 'more', 'than', 'your', 'scholarship', 'warrants', \"'\"), (7, 10))], 'NN': [(('RB', 'PRP', 'VBP', 'VBG', 'THE', 'NN', 'FOR', 'NN'), ('now', 'they', 'are', 'fishing', 'the', 'fissure', 'for', 'fisher'), (8, 11)), (('AND', 'VBD', 'THE', 'NN', 'WITH', 'NN'), ('and', 'finished', 'the', 'solo', 'with', 'honour'), (6, 9)), (('VBD', 'A', 'NN', 'DT', 'JJR', 'THAN', 'NN'), ('was', 'a', 'tipple', 'no', 'stronger', 'than', 'toui'), (7, 9)), (('VBZ', 'AND', 'VBZ', 'DT', 'NN'), ('perspires', 'and', 'pushes', 'no', 'mower'), (5, 7)), (('TO', 'VB', 'JJ', 'NNS', 'ON', 'PRP', 'NN'), ('to', 'balance', 'green', 'peas', 'on', 'her', 'fork'), (7, 8)), (('VBZ', 'A', 'NN', 'A', 'NN', 'NN', '.'), ('is', 'a', 'buttress', 'a', 'feminine', 'butter', '?'), (6, 11)), (('PRP', 'RB', 'VBD', 'PRP$', 'NN'), ('he', 'never', 'completed', 'his', 'task'), (5, 8)), (('OF', 'THE', 'NN', 'AND', 'NN', 'AND', 'NN'), ('of', 'the', 'gravy', 'and', 'chicken', 'and', 'ham'), (7, 9)), (('VBP', 'ALL', 'VBN', 'PRP$', 'NNS', 'IN', 'PRP$', 'NN', '.'), ('have', 'all', 'built', 'their', 'nests', 'in', 'my', 'beard', '!'), (8, 9)), (('VBP', 'JJ', 'TO', 'VB', 'ON', 'PRP$', 'NN', '.'), ('are', 'welcome', 'to', 'sit', 'on', 'my', 'bonnet', '!'), (7, 10)), (('WHEN', 'THE', 'NN', 'VBD', 'CD', 'RB', 'VB', 'A', 'NN', '.'), ('when', 'the', 'moon', 'said', \"'do\", \"n't\", 'be', 'a', 'buffoon', '!'), (9, 11)), (('RB', 'PRP', 'VBD', 'PRP', 'NN', 'IN', 'THE', 'NN'), ('then', 'he', 'walloped', 'me', 'square', 'in', 'the', 'face'), (8, 8)), ((',', 'SO', 'PRP', 'VBP', 'ON', 'THE', 'NN'), (',', 'so', 'they', 'played', 'on', 'the', 'lynx'), (6, 6)), (('BY', 'THAT', 'NN', 'OF', 'NN'), ('by', 'that', 'lady', 'of', 'russia'), (5, 7)), (('WHICH', 'VBD', 'THAT', 'NN', 'OF', 'NN'), ('which', 'refreshed', 'that', 'person', 'of', 'ewell'), (6, 9)), (('OR', 'THE', 'NN', 'OF', 'A', 'JJ', 'NN'), ('or', 'the', 'joy', 'of', 'a', 'pleasant', 'surprise'), (7, 9)), (('AND', 'PRP', 'VBP', 'THAT', 'PRP$', 'NN', 'VBZ', 'A', 'NN'), ('and', 'I', 'hope', 'that', 'your', 'day', 'is', 'a', 'blast'), (9, 9)), (('PRP$', 'NN', 'POS', 'JJ', 'NN'), ('my', 'neighbor', \"'s\", 'fat', 'wife'), (5, 6)), (('LIKE', 'THE', 'NNS', 'OF', 'NN'), ('like', 'the', 'movies', 'of', 'tandy'), (5, 7)), (('WITH', 'A', 'JJ', 'NN', 'OF', 'NN', 'ON', 'PRP$', 'NN'), ('with', 'a', 'nice', 'head', 'of', 'hair', 'on', 'his', 'pate'), (9, 9)), (('AND', 'VBD', 'WITH', 'A', 'JJ', 'NN'), ('and', 'retired', 'with', 'a', 'bad', 'stomach ache'), (6, 7)), (('AND', 'THAT', 'VBZ', 'THE', 'NN', 'OF', 'THIS', 'NN'), ('and', 'that', 'is', 'the', 'cause', 'of', 'this', 'sonnet'), (8, 9)), (('IN', 'NN', ',', 'PRP', 'COULD', 'RB', 'VB', 'NN'), ('in', 'fact', ',', 'they', 'could', 'hardly', 'get', 'ynne'), (7, 8)), (('PRP', 'RB', 'VBD', 'A', 'NN'), ('he', 'carelessly', 'stuck', 'a', 'verbena'), (5, 9)), (('IN', 'PRP$', 'JJ', 'NN'), ('because of', 'his', 'scanty', 'regalia'), (4, 7)), (('WHICH', 'VBZ', 'PRP', 'IN', 'RB', 'JJ', 'NN'), ('which', 'leaves', 'him', 'in', 'very', 'bad', 'shape'), (7, 8)), (('FOR', 'CD', 'NNS', 'VBD', 'JJ', 'AT', 'NN'), ('for', 'six', 'sikhs', 'were', 'seasick', 'at', 'eos'), (7, 9)), (('VBD', 'RB', 'A', 'JJ', 'NN'), ('found', 'only', 'a', 'sleeveless', 'tuxedo'), (5, 9)), (('AND', 'THE', 'NN', 'RB', 'VBD', 'A', 'WHOLE', 'NN'), ('and', 'the', 'captain', 'then', 'swore', 'a', 'whole', 'lacht'), (8, 9)), (('FOR', 'RB', 'VBG', 'PRP', 'JJ', 'NN'), ('for', 'not', 'selling', 'her', 'waterproof', 'paint'), (6, 9)), (('WHEN', 'THE', 'JJ', 'NN', 'VBD', 'VBN', 'BY', 'NN'), ('when', 'the', 'wrong', 'tooth', 'was', 'pulled', 'by', 'mistake'), (8, 9)), (('AND', 'VBD', 'PRP', 'MANY', 'NN'), ('and', 'showed', 'him', 'many', 'cstar'), (5, 6)), (('WHEN', 'PRP', 'VBP', 'PRP', ',', 'PRP', 'VBP', 'VBN', 'A', 'NN'), ('when', 'I', 'wear', 'it', ',', 'I', 'am', 'called', 'a', 'vermine'), (9, 9)), (('VBP', 'VBG', 'A', 'NN', 'IN', 'PRP$', 'NN'), ('are', 'making', 'a', 'nest', 'in', 'my', 'beard'), (7, 8)), (('AND', 'VBD', 'ON', 'THE', 'JJ', 'NN'), ('and', 'returned', 'on', 'the', 'previous', 'night'), (6, 9)), (('THE', 'NN', 'VBZ', 'VBN', 'NN'), ('the', 'confusion', 'is', 'called', 'harem-scarem'), (5, 7)), (('AND', 'AS', 'RB', 'AS', 'THE', 'NN'), ('and', 'as', 'far', 'as', 'the', 'bucket'), (6, 7)), (('THAT', 'PRP', 'VBD', 'PRP', 'JJ', 'NN'), ('that', 'she', 'pickled', 'her', 'internal', \"workins'\"), (6, 9)), (('OF', 'THE', 'NN', 'FROM', 'NN', 'TO', 'NN'), ('of', 'the', 'distance', 'from', 'object', 'to', 'source'), (7, 9)), (('VBD', 'VBG', 'PRP$', 'DURING', 'THE', 'NN'), ('kept', 'insuring', 'her', 'during', 'the', 'service'), (6, 10)), (('SO', 'PRP', 'VBP', 'THROUGH', 'A', 'NN', 'IN', 'THE', 'NN'), ('so', 'they', 'flew', 'through', 'a', 'flaw', 'in', 'the', 'flue'), (9, 9)), (('AND', 'PRP', 'VBP', 'VBN', 'TO', 'THE', 'NN', 'WITH', 'NN'), ('and', 'I', 'am', 'stuck', 'to', 'the', 'toilet', 'with', 'glue'), (9, 10)), (('NNS', 'OUT', 'OF', 'PRP$', 'NNS', 'LIKE', 'NN'), ('seeps', 'out', 'of', 'my', 'pockets', 'like', 'honey'), (7, 9)), (('WHEN', 'PRP', 'VBP', 'PRP', ',', 'PRP', 'VBP', 'VBN', 'RB', 'NN'), ('when', 'I', 'wear', 'it', ',', 'I', 'am', 'called', 'only', 'vermin'), (9, 11)), (('SO', 'PRP', 'VBD', 'UP', 'AND', 'VB', 'ON', 'THE', 'NN'), ('so', 'he', 'jumped', 'up', 'and', 'spat', 'on', 'the', 'ceiling'), (9, 10)), (('AS', 'PRP', 'VBD', 'TO', 'VB', ',', 'PRP', 'VBP', 'A', 'NN'), ('as', 'it', 'tried', 'to', 'explain', ',', 'I', 'am', 'a', 'spi'), (9, 10)), (('WITH', 'PRP$', 'NN', 'AND', 'NN', 'IN', 'THE', 'NN'), ('with', 'his', 'spanner', 'and', 'jack', 'in', 'the', 'box'), (8, 9)), (('AND', 'TO', 'VB', 'PRP', 'JJ', 'NNS', 'OF', 'NN'), ('and', 'to', 'write', 'it', 'used', 'acres', 'of', 'time'), (8, 9)), (('POS', 'VB', 'ALL', 'THE', 'NN', 'NN'), (\"'twill\", 'take', 'all', 'the', 'afternoon', 'cleaning'), (6, 10)), (('THE', 'NN', 'JJ', 'NN', 'POS', 'NN', 'A', 'NN'), ('the', \"bloomin'\", 'old', 'tub', \"'s\", 'sprung', 'a', 'leak'), (8, 9)), (('PRP', 'VBD', 'PRP$', 'JJ', 'NNS', 'AND', 'CD', 'NN'), ('they', 'found', 'his', 'front', 'teeth', 'and', 'one', 'cuff'), (8, 8)), (('PRP', 'RB', 'VBP', 'IN', 'A', 'NN', '.'), ('I', 'invariably', 'get', 'in', 'a', 'stew', '!'), (6, 11)), (('NN', 'VBD', ',', 'PRP', 'VBZ', 'A', 'JJ', 'NN', 'IN', 'NN'), ('bo', 'said', ',', 'it', 'is', 'a', 'polar', 'bear', 'in', 'snow'), (9, 10)), (('WHICH', 'VBD', 'THAT', 'NN'), ('which', 'distracted', 'that', 'bull'), (4, 6)), (('PRP', 'MD', 'VB', 'UP', 'A', 'NN'), ('they', \"'d\", 'kick', 'up', 'a', 'hullabaloo'), (6, 9)), (('AND', 'VBD', 'PRP$', 'NN', 'A', 'NN'), ('and', 'gave', 'his', 'proboscis', 'a', 'tweak'), (6, 8)), (('THAT', 'PRP$', 'NN', 'VBD', 'NN'), ('that', 'her', 'head', 'was', 'bare'), (5, 5)), (('AND', 'VBD', 'PRP$', 'BECAUSE', 'PRP', 'VBD', 'NN'), ('and', 'kissed', 'her', 'because', 'he', 'was', 'wuise'), (7, 8)), (('AND', 'QUITE', 'JJ', 'OF', 'NN'), ('and', 'quite', 'independent', 'of', 'girth'), (5, 8)), (('BUT', 'PRP', 'VBZ', 'RB', 'VB', 'IN', 'PRP$', 'NN'), ('but', 'it', 'does', \"n't\", 'come', 'out of', 'my', 'purse'), (8, 8)), (('WHAT', 'VBD', 'VBN', 'ON', 'THE', 'NN', 'NN'), ('what', 'was', 'shown', 'on', 'the', 'cinema', 'screen'), (7, 9)), (('RB', ',', 'PRP', 'VBD', 'JJ', 'NN'), ('alas', ',', 'he', 'proved', 'treaulieu', 'unreaulieu'), (5, 6)), (('RB', ',', 'PRP', 'VBD', 'JJ', 'NN'), ('alas', ',', 'he', 'proved', 'treaulieu', 'unreaulieu'), (5, 6)), (('RB', 'BOTH', 'VBN', 'FROM', 'NN'), ('then', 'both', 'skedaddled', 'from', 'eden'), (5, 6)), (('BY', 'ANOTHER', 'WITH', 'NNS', 'FROM', 'NEAR', 'NN'), ('by', 'another', 'with', 'beans', 'from', 'near', 'fargo'), (7, 10)), (('SO', 'PRP', 'JUST', 'VB', ',', 'OF', 'NN'), ('so', 'he', 'just', 'rhododendron', ',', 'of', 'course'), (6, 9)), (('PRP', 'VBD', 'RB', 'VB', 'NN', 'VBD', 'THIS', 'NN'), ('I', 'did', \"n't\", 'think', 'life', 'was', 'this', 'way'), (8, 8)), (('BUT', 'PRP', 'VBD', 'AND', 'PRP', 'VBD', ',', 'NN'), ('but', 'she', 'sighed', 'and', 'she', 'said', ',', 'canteloupe'), (7, 7)), (('VBG', 'TO', 'VB', 'NN'), ('pretending', 'to', 'represent', 'chile'), (4, 9)), (('AND', 'RB', 'PRP', 'VBZ', 'A', 'NN', 'NN'), ('and', 'now', 'he', \"'s\", 'a', 'college', 'professor'), (7, 10)), (('ALL', 'OF', 'THIS', 'NN', 'AFTER', 'NN'), ('all', 'of', 'this', 'homework', 'after', 'school'), (6, 8)), (('THAT', 'NN', 'IN', 'A', 'NN'), ('that', 'man', 'in', 'a', 'boat'), (5, 5)), (('THAT', 'NN', 'OF', 'NN'), ('that', 'man', 'of', 'peru'), (4, 5)), (('AND', 'VB', 'NN', 'TO', 'PRP$', 'NN', 'IN', 'NN'), ('and', 'give', 'vent', 'to', 'their', 'terror', 'in', 'scremyss'), (8, 9)), (('VBP', 'ALL', 'JJ', 'NNS', 'FOR', 'A', 'NN'), ('are', 'all', 'easy', 'marks', 'for', 'a', 'jolly'), (7, 9)), (('THE', 'NN', 'OF', 'NN'), ('the', 'theory', 'of', 'witten'), (4, 6)), (('AS', 'THE', 'JJ', 'NN'), ('as', 'the', 'unique', 'motivation'), (4, 8)), (('THAT', 'PRP', 'VBP', 'RB', 'VBN', 'VBN', 'WITH', 'A', 'NN'), ('that', 'I', 'have', \"n't\", 'been', 'born', 'with', 'a', 'breign'), (9, 10)), (('AND', 'PRP', 'VBD', 'DOWN', 'AND', 'VBD', 'PRP$', 'NN'), ('and', 'it', 'dropped', 'down', 'and', 'ruined', 'her', 'gown'), (8, 9)), (('AND', 'RB', 'VB', 'QUITE', 'NN'), ('and', 'sometimes', 'get', 'quite', 'cranky'), (5, 7)), (('THAT', 'VBD', 'JJ', ',', 'JUST', 'LIKE', 'NN'), ('that', 'were', 'funny', ',', 'just', 'like', 'fudd'), (6, 7)), (('THAT', 'NN', 'OF', 'NN'), ('that', 'person', 'of', 'ischia'), (4, 5)), (('ON', 'THE', 'NN', 'WITH', 'PRP$', 'NN', 'OR', 'NN'), ('on', 'the', 'phone', 'with', 'your', 'brother', 'or', 'seester'), (8, 9)), (('RB', 'VBD', 'INTO', 'A', 'NN', 'OF', 'NN'), ('then', 'fell', 'into', 'a', 'vat', 'of', 'grease'), (7, 8)), (('AND', 'RB', 'COULD', 'VB', 'A', 'NN'), ('and', 'soon', 'could', 'afford', 'a', 'rolls-royce'), (6, 7)), (('FOR', 'A', 'NN', 'VBZ', 'VBN', 'OFF', 'PRP$', 'NN'), ('for', 'a', 'surgeon', 'has', 'cut', 'off', 'his', 'fuite'), (8, 9)), (('MAY', 'VB', 'A', 'NN', 'AT', 'NN'), ('may', 'evolve', 'a', 'professor', 'at', 'yale'), (6, 9)), (('UPON', 'THE', 'NN', ',', 'VBG', 'NN', '.'), ('upon', 'the', 'fence', ',', 'crying', 'hooray', '!'), (5, 8)), (('THAN', 'VB', 'TO', 'THE', 'JJ', 'NN'), ('than', 'belong', 'to', 'the', 'star-spangled', 'banner'), (6, 8)), (('AND', 'PRP', 'VBD', 'RB', 'LIKE', 'NN', 'OF', 'NN'), ('and', 'he', 'did', \"n't\", 'like', 'mother', 'of', 'pearl'), (8, 9)), (('VBD', 'QUITE', 'THE', 'NN', 'OF', 'NN'), ('was', 'quite', 'the', 'reverse', 'of', \"'hosanna'\"), (6, 7)), (('RB', 'PRP$', 'NN', 'VBD', 'A', 'NN', 'IN', 'PRP$', 'NN'), ('then', 'his', 'wife', 'tied', 'a', 'knot', 'in', 'his', 'trunk'), (9, 9)), (('PRP', 'VBP', 'RB', 'VB', ',', 'PRP', 'JUST', 'VBD', 'FOR', 'THE', 'NN'), ('I', 'do', \"n't\", 'know', ',', 'I', 'just', 'came', 'for', 'the', 'ride'), (10, 10)), (('THAN', 'THERE', 'VBP', 'IN', 'THE', 'JJ', 'NN'), ('than', 'there', 'are', 'in', 'the', 'star-spangled', 'banner'), (7, 8)), (('AS', 'PRP', 'VBD', 'OUT', 'CD', 'NNS', 'IN', 'PRP$', 'NN'), ('as', 'she', 'let', 'out', 'three', 'tucks', 'in', 'her', 'tunic'), (9, 10)), (('VBD', 'OUT', 'TO', 'VB', 'NN', 'OF', 'NN'), ('turned', 'out', 'to', 'be', 'plaster', 'of', 'paris'), (7, 9)), (('FOR', 'PRP', 'VBP', 'THAT', 'PRP', 'VBP', 'PRP', 'VBZ', 'JJ', ',', 'NN'), ('for', 'I', 'fear', 'that', 'I', 'am', 'handel', \"'s\", 'miss', ',', 'sire'), (10, 12)), (('IN', 'A', 'JJ', 'NN', 'NN'), ('in', 'a', 'sugary', 'takeover', 'bid'), (5, 9)), (('AND', 'THE', 'NN', 'ON', 'THE', 'NN', 'OF', 'THE', 'NN'), ('and', 'the', 'smile', 'on', 'the', 'face', 'of', 'the', 'tiger'), (9, 10)), (('PRP', 'VBD', 'WHEN', 'PRP', 'VBP', 'ACROSS', 'NN'), ('I', 'relaxed', 'when', 'I', 'eos', 'across', 'aunt'), (7, 11)), (('TO', 'A', 'NN', 'WHO', 'VBD', 'VBN', 'LIKE', 'A', 'NN'), ('to', 'a', 'man', 'who', 'was', 'shaped', 'like', 'a', 'cello'), (9, 10))], 'INSIDE': [(('AND', 'VBD', 'NN', 'INSIDE', 'PRP$', 'INSIDE'), ('and', 'made', 'cider', 'inside', 'her', 'inside'), (6, 9))], 'BENEATH': [(('VBD', 'DOWN', ',', 'AND', 'VBD', 'VBN', 'BENEATH'), ('sat', 'down', ',', 'and', 'was', 'bitten', 'beneath'), (6, 8))], 'VB': [(('TO', 'VB', 'CD', 'NNS', 'TO', 'VB'), ('to', 'tutor', 'two', 'tutors', 'to', 'toot'), (6, 8)), (('JUST', 'AS', 'EVERY', 'JJ', 'NN', 'SHOULD', 'VB'), ('just', 'as', 'every', 'sweet', 'maiden', 'should', 'dioux'), (7, 10)), (('PRP', 'VBD', 'JJ', 'TO', 'VB', 'AND', 'TO', 'VB'), ('she', 'was', 'ready', 'to', 'give', 'and', 'to', 'take'), (8, 9)), (('BECAUSE', 'THE', 'NN', 'VBD', 'AND', 'VB'), ('because', 'the', 'man', 'bullied', 'and', 'boucestcr'), (6, 8)), (('BUT', 'THE', 'NN', 'NN', 'VBD', 'PRP', 'VB'), ('but', 'the', 'telephone', 'book', 'caused', 'him', 'pain'), (7, 9)), (('WHICH', 'PRP$', 'NN', 'COULD', 'RB', 'VB', ',', 'JJ', 'TO', 'VB'), ('which', 'his', 'faith', 'could', \"n't\", 'heal', ',', 'strange', 'to', 'say'), (9, 9)), (('JJ', 'NNS', 'VBZ', 'THE', 'NN', 'PRP', 'WILL', 'VB'), ('thirty', 'days', 'is', 'the', 'time', 'he', 'will', 'do'), (8, 9)), (('BUT', 'PRP', 'VBP', 'THAT', 'PRP', 'RB', 'VB'), ('but', 'I', 'guess', 'that', 'you', 'probably', 'gnu'), (7, 9)), (('AND', 'NN', ',', 'NN', 'THERE', ',', 'OR', 'RB', 'PRP', 'WILL', 'VB'), ('and', 'shout', ',', 'freeze', 'there', ',', 'or', 'else', 'I', 'will', 'cheroot'), (9, 9)), (('SO', 'PRP', 'RB', 'RB', 'VBD', 'BACK', 'TO', 'VB'), ('so', 'he', 'very', 'soon', 'went', 'back', 'to', 'dover'), (8, 10)), (('BUT', 'VBD', 'RB', 'BECAUSE', 'PRP$', 'NNS', 'VB'), ('but', 'slept', 'poorly', 'because', 'her', 'toes', 'froze'), (7, 9)), (('VBD', 'PRP$', 'NN', 'NN', 'PRP$', 'NNS', 'AND', 'VB'), ('put', 'his', 'arm', 'round', 'her', 'shoulders', 'and', 'kr'), (8, 9)), (('VBP', 'HOW', 'JJ', '.', 'THE', 'NNS', 'WILL', 'VB'), ('oh', 'how', 'modern', '!', 'the', 'critics', 'will', 'say'), (7, 9)), (('AND', 'WOULD', ',', 'IF', 'PRP', 'VBD', 'RB', 'VB'), ('and', 'would', ',', 'if', 'I', 'did', \"n't\", 'forgezzo'), (7, 8)), (('RB', 'PRP', 'VBP', 'JJ', 'WITH', 'DT', 'NN', 'TO', 'VB'), ('now', 'I', 'am', 'homeless', 'with', 'no', 'place', 'to', 'stay'), (9, 10)), (('THE', 'JJ', 'NN', 'VBD', 'DT', 'NN', 'TO', 'VB'), ('the', 'old', 'dame', 'said', 'no', 'word', 'to', 'rebuchre'), (8, 8)), (('FROM', 'THE', 'NN', 'NNS', 'PRP', 'COULD', 'VB'), ('from', 'the', 'comedy', 'roles', 'he', 'could', 'play'), (7, 9))], 'PRP$': [(('NNP', 'JJ', 'EVER', 'TO', 'VB', 'PRP$'), ('`twas', 'impossible', 'ever', 'to', 'fill', 'her'), (6, 10)), (('ALL', 'OF', 'WHICH', ',', 'THE', 'NN', 'VBD', ',', 'VBD', 'PRP$'), ('all', 'of', 'which', ',', 'the', 'lady', 'said', ',', 'shocked', 'her'), (8, 9))], 'NNS': [(('AND', 'VBN', 'VBG', 'ON', 'NNS', 'AND', 'JJ', 'NNS'), ('and', 'been', 'feasting', 'on', 'peas', 'and', 'green', 'beans'), (8, 9)), (('BECAUSE', 'PRP', 'VBD', 'VBG', 'PRP$', 'NNS'), ('because', 'I', 'was', 'sniffing', 'my', 'toes'), (6, 8)), (('THAT', 'JJ', 'JJ', 'NN', 'OF', 'NNS'), ('that', 'unlucky', 'old', 'person', 'of', 'ems'), (6, 9)), (('THAT', 'JJ', 'JJ', 'NN', 'OF', 'NNS'), ('that', 'unlucky', 'old', 'person', 'of', 'ems'), (6, 9)), (('BUT', 'PRP$', 'NNS', 'VBD', 'DOWN', 'TO', 'PRP$', 'NNS'), ('but', 'her', 'glasses', 'slipped', 'down', 'to', 'her', 'toes'), (8, 9)), (('OF', 'PRP$', 'NN', 'AND', 'NN', 'NNS'), ('of', 'their', 'city', 'and', 'town', 'promenades'), (6, 9)), (('THIS', 'VBD', 'RB', 'VB', 'TO', 'PRP$', 'NNS'), ('this', 'did', \"n't\", 'apply', 'to', 'her', 'feet'), (7, 8)), (('AND', 'PRP', 'VBD', 'RB', 'JJ', 'NN', 'NNS'), ('and', 'she', 'baked', 'really', 'great', 'apple', 'pies'), (7, 9)), (('AND', 'PRP', 'CAN', 'RB', 'VB', 'PRP$', 'NN', 'FROM', 'PRP$', 'NNS'), ('and', 'he', 'can', \"n't\", 'tell', 'his', 'head', 'from', 'his', 'feet'), (10, 10)), (('PRP', 'VBP', 'VBG', 'PRP', ',', 'BY', 'NNS'), ('you', 'are', 'killing', 'yourself', ',', 'by', 'degrees'), (6, 9)), (('WHEN', 'PRP', 'VBD', 'THERE', 'VBD', 'CD', 'JJ', 'NNS'), ('when', 'he', 'saw', 'there', 'were', 'six', 'little', 'chips'), (8, 9)), (('BUT', 'THE', 'JJ', 'VBD', 'JJ', 'NNS'), ('but', 'the', 'other', 'won', 'several', 'prizes'), (6, 10))], 'VBD': [(('SO', 'FOR', 'NN', 'PRP', 'VBD'), ('so', 'for', 'over-achievement', 'he', 'strived'), (5, 5)), (('PRP', 'VBD', 'RB', 'THE', 'NN', 'PRP', 'VBD'), ('he', 'was', \"n't\", 'the', 'wizard', 'he', 'woz'), (7, 8)), (('AS', 'PRP$', 'NN', 'AND', 'NN', 'VBD'), ('as', 'his', 'talent', 'and', 'confidence', 'swelled'), (6, 9)), (('RB', 'PRP', 'VBP', 'ON', 'PRP$', 'NN', 'AND', 'VBD'), ('then', 'I', 'sat', 'on', 'my', 'moped', 'and', 'moped'), (8, 8)), (('AND', 'DT', 'NN', 'VBZ', 'WHICH', 'NN', 'PRP', 'VBD'), ('and', 'no', 'one', 'knows', 'which', 'way', 'she', 'went'), (8, 8)), (('BUT', 'PRP', 'VBD', 'PRP$', 'NNS', 'AND', 'VBD'), ('but', 'he', 'thanked', 'his', 'detractors', 'and', 'bowed'), (7, 9)), (('PRP', 'VBD', 'UP', 'IN', 'NN', 'AND', 'VBD'), ('she', 'sat', 'up', 'in', 'bed', 'and', 'meowed'), (7, 7))], 'VBN': [(('OR', 'A', 'NN', 'THAT', 'VBZ', 'VBN', 'RB', 'VBN'), ('or', 'a', 'lamb', 'that', \"'s\", 'been', 'recently', 'fleeced'), (8, 10)), (('AND', 'SINCE', 'RB', 'VBZ', 'RB', 'VBN'), ('and', 'since', 'then', 'has', 'never', 'benzene'), (6, 8)), (('AND', 'VBZ', 'PRP', 'COULD', 'RB', 'VB', 'VBN'), ('and', 'sideways', 'he', 'could', \"n't\", 'be', 'seen'), (7, 8)), (('PRP', 'VBP', 'RB', 'VBN', 'SINCE', 'THE', 'NN', 'PRP', 'VBD', 'VBN'), ('I', 'have', 'not', 'used', 'since', 'the', 'year', 'I', 'was', 'born'), (10, 10)), (('IF', 'VBN', ',', 'FOR', 'PRP$', 'JJS', 'NN', 'VBZ', 'VBN'), ('if', 'dressed', ',', 'for', 'my', 'best', 'frock', 'is', 'frayed'), (8, 9))], 'VBP': [(('RB', ',', 'PRP', 'WILL', 'VB', 'PRP', 'NN', ',', 'PRP', 'VBP'), ('well', ',', 'I', 'will', 'do', 'it', 'tomorrow', ',', 'I', 'mean'), (8, 10)), (('AND', 'PRP', 'VBD', 'NN', 'RB', 'VBP'), ('and', 'she', 'reached', 'home', 'exceedingly', 'plain'), (6, 9)), (('AND', 'RB', 'A', 'JJ', 'NN', 'PRP', 'VBP'), ('and', 'now', 'a', 'new', 'teacher', 'they', 'seek'), (7, 8)), (('PRP', 'VBZ', 'THE', 'NNS', 'IN', 'NN', 'THAT', 'PRP', 'VBP'), ('it', \"'s\", 'the', 'people', 'in', 'front', 'that', 'I', 'jar'), (9, 10)), (('OF', 'THE', 'JJ', 'NN', 'PRP', 'VBP'), ('of', 'the', 'classical', 'music', 'I', 'play'), (6, 9)), (('JJ', 'NN', 'VBZ', 'JJ', ',', 'PRP', 'VBP'), (\"'to\", 'drink', 'is', 'forbidden', ',', 'you', 'loon'), (6, 9)), (('DT', ',', 'VB', 'PRP', 'RB', 'VB', 'PRP', ',', 'PRP', 'VBP'), ('no', ',', 'igloo', 'them', 'not', 'sew', 'them', ',', 'you', 'know'), (8, 9))], 'RB': [(('JJ', 'OUGHT', 'TO', 'VB', 'OUT', 'THERE', 'RB', '.'), ('`you', 'ought', 'to', 'go', 'out', 'there', 'again', '!'), (7, 9)), (('AND', 'COULD', 'RB', 'VB', 'BACK', 'RB'), ('and', 'could', \"n't\", 'bend', 'back', 'again'), (6, 7)), (('VBZ', 'TO', 'VB', 'PRP$', 'NN', 'NN', 'RB'), ('hopes', 'to', 'draw', 'his', 'insurance', 'cheque', 'soon'), (7, 9)), (('OR', 'THE', 'NN', 'WILL', 'VB', 'VBG', 'CD', ',', 'RB'), ('or', 'the', 'rest', 'will', 'be', 'wanting', 'one', ',', 'too'), (8, 9))], 'DOWN': [(('VBD', 'THE', 'NN', 'IN', 'A', 'NN', 'RB', 'DOWN'), ('dumped', 'the', 'boy', 'in', 'a', 'bin', 'upside', 'down'), (8, 9))], 'JJ': [(('FOR', 'THE', 'NN', 'VBZ', 'VBN', ',', 'SO', 'VBZ', 'PRP$', 'JJ'), ('for', 'the', 'corn', 'is', 'gone', ',', 'so', 'is', 'her', 'teaux'), (9, 9)), (('AND', 'RB', 'THE', 'JJ', 'NN', 'VBZ', 'RB', 'JJ'), ('and', 'now', 'the', 'dumb', 'thing', 'is', 'too', 'small'), (8, 8)), (('AND', 'VBD', 'THE', 'JJ'), ('and', 'shocked', 'the', 'ultra-fastidious'), (4, 4)), (('VB', 'BEFORE', 'JJ', 'VB', 'JJ', 'JJ'), ('be', 'before', 'phoebe', 'be', 'phoebe', 'bee-bee'), (6, 9)), (('AS', 'IF', 'PRP', 'MD', 'VBN', 'JJ'), ('as', 'if', 'he', \"'d\", 'been', 'invited'), (6, 8)), (('THAT', 'NN', 'VBD', 'RB', 'JJ', ',', 'PRP', 'VBD', 'JJ'), ('that', 'bird', 'was', \"n't\", 'black', ',', 'he', 'was', 'yellow'), (8, 9)), (('TO', 'VB', 'PRP$', 'JJ', 'NN', 'JJ'), ('to', 'call', 'my', 'last', 'novel', 'impure'), (6, 9)), (('AND', 'VBG', 'VBP', 'PRP', 'VBZ', 'BUT', 'JJ', '.'), ('and', 'awakening', 'find', 'it', \"'s\", 'but', 'dreymss', '!'), (7, 11)), (('AND', 'VBG', 'VBP', 'PRP', 'VBZ', 'BUT', 'JJ', '.'), ('and', 'awakening', 'find', 'it', \"'s\", 'but', 'dreyrnss', '!'), (7, 11)), (('BUT', 'THE', 'NNS', 'ALL', 'VBD', 'NNP', 'RB', 'JJ'), ('but', 'the', 'others', 'all', 'thought', \"'twas\", 'too', 'breezy'), (8, 10)), (('THAT', 'DT', 'NN', 'VBD', 'JJ', 'BUT', 'JJ'), ('that', 'no', 'one', 'was', 'present', 'but', 'smarty'), (7, 9)), (('OR', 'VBZ', 'NN', 'VB', 'NNS', 'SO', 'JJ'), ('or', 'does', 'gravity', 'miss', 'things', 'so', 'small'), (7, 9)), (('RB', 'VB', 'UP', 'ALL', 'JJ', 'AND', 'JJ'), ('then', 'wake', 'up', 'all', 'snappy', 'and', 'snarly'), (7, 8))], 'IN': [(('BUT', 'CD', 'NN', 'PRP', 'JUST', 'COULD', 'RB', 'VB', 'IN'), ('but', 'one', 'god', 'he', 'just', 'could', \"n't\", 'believe', 'in'), (9, 10)), (('PRP', 'VBD', 'THROUGH', 'THE', 'NN', 'AND', 'VBD', 'IN'), ('she', 'slipped', 'through', 'the', 'straw', 'and', 'fell', 'in'), (8, 8)), (('PRP', 'VBD', 'THROUGH', 'THE', 'NN', 'AND', 'VBD', 'IN'), ('he', 'slipped', 'through', 'the', 'straw', 'and', 'fell', 'in'), (8, 8)), (('WHAT', 'A', 'NN', 'PRP', 'VBD', 'RB', 'VB', 'IN'), ('what', 'a', 'blessing', 'they', 'did', \"n't\", 'fall', 'in'), (8, 9))], 'ACROSS': [(('PRP', 'VBP', 'RB', 'DOWN', 'TO', 'VB', 'RP', 'ACROSS'), ('I', 'am', 'eos', 'down', 'to', 'put', 'eos', 'across'), (8, 11))], 'ON': [(('PRP', 'WILL', 'VB', 'THAT', 'PRP', 'VBZ', 'RB', 'VBN', 'VBN', 'ON'), ('I', 'will', 'know', 'that', 'it', 'has', \"n't\", 'been', 'sat', 'on'), (10, 10))], 'ANY': [(('THE', 'NNS', ',', 'RB', ',', 'VBD', 'RB', 'VB', 'ANY'), ('the', 'drivers', ',', 'therefore', ',', 'did', \"n't\", 'dump', 'any'), (7, 10)), (('RB', 'IN', 'CD', 'NNS', ',', 'THERE', 'VBP', 'RB', 'ANY'), ('now', 'instead of', 'two', 'cats', ',', 'there', 'are', \"n't\", 'any'), (8, 9))], 'FW': [(('THAN', 'JJ', 'NN', 'NN', 'FW', 'FW', 'FW', 'FW'), ('than', 'eos', 'point', 'eos', 'eos', 'eos', 'eos', 'eos'), (8, 14)), (('VBG', 'RB', 'A', 'NN', 'OF', 'FW', 'FW'), ('leaving', 'only', 'a', 'pile', 'of', 'de', 'brie'), (7, 9))], 'VBG': [(('BECAUSE', 'ON', 'PRP$', 'NNS', 'PRP', 'VBD', 'VBG'), ('because', 'on', 'her', 'toes', 'he', 'kept', 'prancing'), (7, 9)), (('JUST', 'VBD', 'PRP', ',', 'RB', 'WHERE', 'PRP', 'VBP', 'VBG'), ('just', 'painted', 'it', ',', 'right', 'where', 'you', 'are', 'sitting'), (8, 11))], 'TO': [(('PRP', 'VBD', 'PRP', 'AND', 'VBD', 'NNS', 'AND', 'TO'), ('he', 'reversed', 'it', 'and', 'walked', 'fro', 'and', 'to'), (8, 9))], 'CAN': [(('BUT', 'PRP', 'RB', 'VBP', 'TO', 'VB', 'AS', 'MANY', 'NNS', 'INTO', 'THE', 'JJ', 'NN', 'AS', 'PRP', 'RB', 'CAN'), ('but', 'I', 'always', 'try', 'to', 'get', 'as', 'many', 'syllables', 'into', 'the', 'last', 'line', 'as', 'I', 'possibly', 'can'), (17, 24))], 'CD': [(('RB', 'VB', 'OUT', 'A', 'NN', 'OR', 'CD'), ('then', 'grind', 'out', 'a', 'limerick', 'or', 'two'), (7, 9))], 'UP': [(('THAT', 'PRP', 'COULD', 'RB', 'VB', 'UP'), ('that', 'he', 'could', \"n't\", 'reach', 'up'), (6, 6))], 'JJR': [(('JJ', 'NN', ',', 'PRP', 'VBD', ',', 'COULD', 'VB', 'JJR'), ('`no', 'mixture', ',', 'she', 'said', ',', 'could', 'be', 'finer'), (7, 11)), (('AND', 'PRP$', 'NNS', 'VBD', 'JJR', 'AND', 'JJR'), ('and', 'her', 'freckles', 'grew', 'rarer', 'and', 'rarer'), (7, 10))], 'MORE': [(('PRP', 'VBD', 'ALL', 'PRP$', 'NNS', 'VBG', 'MORE'), ('he', 'left', 'all', 'his', 'fans', 'wanting', 'more'), (7, 8))], 'VBZ': [(('PRP', 'WILL', 'VB', 'RB', 'VBD', ',', 'WHEN', 'PRP', 'VBZ'), ('I', 'will', 'be', 'awfully', 'said', ',', 'when', 'it', 'goes'), (8, 10))]})\n"
     ]
    }
   ],
   "source": [
    "print(lg.templates['fifth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
