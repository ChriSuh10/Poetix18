{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_files.Limericks import Limerick_Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = Limerick_Generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fall', 'year', 'start', 'june', 'days', 'july', 'day', 'week', 'come', 'mid', 'begin', 'springtime', 'january', 'holiday', 'snow', 'end', 'sometime', 'began', 'expected', 'night'])\n"
     ]
    }
   ],
   "source": [
    "output = lg.get_two_sets_henry(\"planet\")\n",
    "print(output[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'shirleen' bfs iteration 0: 54 new words.\n",
      "Getting rhyming words of word 1 'shirleen' ...... 1 / 20 done.\n",
      "'kenneth' bfs iteration 0: 0 new words.\n",
      "Unable to find rhyming words of word 1 'kenneth'\n",
      "'georgeann' bfs iteration 0: 0 new words.\n",
      "Unable to find rhyming words of word 1 'georgeann'\n",
      "'evan' bfs iteration 0: 4 new words.\n",
      "Getting rhyming words of word 1 'evan' ...... 2 / 20 done.\n",
      "'cody' bfs iteration 0: 0 new words.\n",
      "Unable to find rhyming words of word 1 'cody'\n",
      "'michael' bfs iteration 0: 2 new words.\n",
      "Getting rhyming words of word 1 'michael' ...... 3 / 20 done.\n",
      "'mohamed' bfs iteration 0: 0 new words.\n",
      "Unable to find rhyming words of word 1 'mohamed'\n",
      "'lowell' bfs iteration 0: 1 new words.\n",
      "Getting rhyming words of word 1 'lowell' ...... 4 / 20 done.\n",
      "'january' bfs iteration 0: 27 new words.\n",
      "Getting rhyming words of word 1 'january' ...... 5 / 20 done.\n",
      "'halley' bfs iteration 0: 13 new words.\n",
      "Getting rhyming words of word 1 'halley' ...... 6 / 20 done.\n",
      "'brady' bfs iteration 0: 3 new words.\n",
      "Getting rhyming words of word 1 'brady' ...... 7 / 20 done.\n",
      "'fawn' bfs iteration 0: 41 new words.\n",
      "Getting rhyming words of word 1 'fawn' ...... 8 / 20 done.\n",
      "'lan' bfs iteration 0: 38 new words.\n",
      "Getting rhyming words of word 1 'lan' ...... 9 / 20 done.\n",
      "'jerold' bfs iteration 0: 0 new words.\n",
      "Unable to find rhyming words of word 1 'jerold'\n",
      "'joaquin' bfs iteration 0: 54 new words.\n",
      "Getting rhyming words of word 1 'joaquin' ...... 10 / 20 done.\n",
      "'mitch' bfs iteration 0: 16 new words.\n",
      "Getting rhyming words of word 1 'mitch' ...... 11 / 20 done.\n",
      "'melvin' bfs iteration 0: 0 new words.\n",
      "Unable to find rhyming words of word 1 'melvin'\n",
      "'dick' bfs iteration 0: 30 new words.\n",
      "Getting rhyming words of word 1 'dick' ...... 12 / 20 done.\n",
      "'crissy' bfs iteration 0: 0 new words.\n",
      "Unable to find rhyming words of word 1 'crissy'\n",
      "'herb' bfs iteration 0: 5 new words.\n",
      "Getting rhyming words of word 1 'herb' ...... 13 / 20 done.\n",
      "'preston' bfs iteration 0: 2 new words.\n",
      "Getting rhyming words of word 1 'preston' ...... 14 / 20 done.\n",
      "'eleanor' bfs iteration 0: 0 new words.\n",
      "Unable to find rhyming words of word 1 'eleanor'\n",
      "'jody' bfs iteration 0: 0 new words.\n",
      "Unable to find rhyming words of word 1 'jody'\n",
      "'sally' bfs iteration 0: 8 new words.\n",
      "Getting rhyming words of word 1 'sally' ...... 15 / 20 done.\n",
      "'trent' bfs iteration 0: 50 new words.\n",
      "Getting rhyming words of word 1 'trent' ...... 16 / 20 done.\n",
      "'willy' bfs iteration 0: 8 new words.\n",
      "Getting rhyming words of word 1 'willy' ...... 17 / 20 done.\n",
      "'allen' bfs iteration 0: 2 new words.\n",
      "Getting rhyming words of word 1 'allen' ...... 18 / 20 done.\n",
      "'yen' bfs iteration 0: 22 new words.\n",
      "Getting rhyming words of word 1 'yen' ...... 19 / 20 done.\n",
      "'elizabet' bfs iteration 0: 0 new words.\n",
      "Unable to find rhyming words of word 1 'elizabet'\n",
      "'stacey' bfs iteration 0: 1 new words.\n",
      "Getting rhyming words of word 1 'stacey' ...... 20 / 20 done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'shirleen': {'amin',\n",
       "  'augustine',\n",
       "  'baleen',\n",
       "  'bean',\n",
       "  'between',\n",
       "  'byzantine',\n",
       "  'caffeine',\n",
       "  'canteen',\n",
       "  'careen',\n",
       "  'clean',\n",
       "  'cuisine',\n",
       "  'dean',\n",
       "  'demean',\n",
       "  'evergreen',\n",
       "  'fifteen',\n",
       "  'figurine',\n",
       "  'florentine',\n",
       "  'foreseen',\n",
       "  'gene',\n",
       "  'glean',\n",
       "  'green',\n",
       "  'guillotine',\n",
       "  'intervene',\n",
       "  'jean',\n",
       "  'keen',\n",
       "  'latrine',\n",
       "  'lean',\n",
       "  'limousine',\n",
       "  'machine',\n",
       "  'magazine',\n",
       "  'marine',\n",
       "  'mean',\n",
       "  'mien',\n",
       "  'obscene',\n",
       "  'philistine',\n",
       "  'protein',\n",
       "  'quarantine',\n",
       "  'queen',\n",
       "  'ravine',\n",
       "  'routine',\n",
       "  'sabine',\n",
       "  'saline',\n",
       "  'scene',\n",
       "  'screen',\n",
       "  'seen',\n",
       "  'serene',\n",
       "  'sheen',\n",
       "  'sistine',\n",
       "  'spleen',\n",
       "  'submarine',\n",
       "  'teen',\n",
       "  'thirteen',\n",
       "  'unforeseen',\n",
       "  'wolverine'},\n",
       " 'evan': {'eleven', 'heaven', 'leaven', 'seven'},\n",
       " 'michael': {'cycle', 'tical'},\n",
       " 'lowell': {'joel'},\n",
       " 'january': {'aerie',\n",
       "  'airy',\n",
       "  'berry',\n",
       "  'bury',\n",
       "  'canary',\n",
       "  'carry',\n",
       "  'cherry',\n",
       "  'contrary',\n",
       "  'dairy',\n",
       "  'fairy',\n",
       "  'ferry',\n",
       "  'hairy',\n",
       "  'harry',\n",
       "  'library',\n",
       "  'marry',\n",
       "  'mary',\n",
       "  'merry',\n",
       "  'parry',\n",
       "  'prairie',\n",
       "  'primary',\n",
       "  'raspberry',\n",
       "  'scary',\n",
       "  'strawberry',\n",
       "  'tarry',\n",
       "  'vary',\n",
       "  'very',\n",
       "  'wary'},\n",
       " 'halley': {'alley',\n",
       "  'daily',\n",
       "  'dally',\n",
       "  'finale',\n",
       "  'gaily',\n",
       "  'galley',\n",
       "  'gayly',\n",
       "  'greyly',\n",
       "  'rally',\n",
       "  'scaly',\n",
       "  'tally',\n",
       "  'valley',\n",
       "  'verbally'},\n",
       " 'brady': {'arkady', 'lady', 'shady'},\n",
       " 'fawn': {'amazon',\n",
       "  'aragon',\n",
       "  'avalon',\n",
       "  'babylon',\n",
       "  'baton',\n",
       "  'bon',\n",
       "  'brawn',\n",
       "  'bygone',\n",
       "  'carillon',\n",
       "  'con',\n",
       "  'dawn',\n",
       "  'denouement',\n",
       "  'don',\n",
       "  'drawn',\n",
       "  'echelon',\n",
       "  'foregone',\n",
       "  'gone',\n",
       "  'john',\n",
       "  'juan',\n",
       "  'khan',\n",
       "  'lawn',\n",
       "  'liaison',\n",
       "  'marathon',\n",
       "  'mastodon',\n",
       "  'non',\n",
       "  'nylon',\n",
       "  'octagon',\n",
       "  'on',\n",
       "  'oregon',\n",
       "  'pantheon',\n",
       "  'paragon',\n",
       "  'pawn',\n",
       "  'pentagon',\n",
       "  'photon',\n",
       "  'salon',\n",
       "  'spawn',\n",
       "  'swan',\n",
       "  'upon',\n",
       "  'wan',\n",
       "  'withdrawn',\n",
       "  'yon'},\n",
       " 'lan': {'afghan',\n",
       "  'an',\n",
       "  'anchorman',\n",
       "  'ann',\n",
       "  'anne',\n",
       "  'ban',\n",
       "  'began',\n",
       "  'businessman',\n",
       "  'can',\n",
       "  'caravan',\n",
       "  'caveman',\n",
       "  'chan',\n",
       "  'clan',\n",
       "  'clergyman',\n",
       "  'dan',\n",
       "  'divan',\n",
       "  'fan',\n",
       "  'fisherman',\n",
       "  'gan',\n",
       "  'helmsman',\n",
       "  'japan',\n",
       "  'journeyman',\n",
       "  'kan',\n",
       "  'klan',\n",
       "  'madman',\n",
       "  'man',\n",
       "  'milan',\n",
       "  'pan',\n",
       "  'plan',\n",
       "  'ran',\n",
       "  'san',\n",
       "  'scan',\n",
       "  'sedan',\n",
       "  'span',\n",
       "  'suntan',\n",
       "  'tan',\n",
       "  'than',\n",
       "  'van'},\n",
       " 'joaquin': {'amin',\n",
       "  'augustine',\n",
       "  'baleen',\n",
       "  'bean',\n",
       "  'between',\n",
       "  'byzantine',\n",
       "  'caffeine',\n",
       "  'canteen',\n",
       "  'careen',\n",
       "  'clean',\n",
       "  'cuisine',\n",
       "  'dean',\n",
       "  'demean',\n",
       "  'evergreen',\n",
       "  'fifteen',\n",
       "  'figurine',\n",
       "  'florentine',\n",
       "  'foreseen',\n",
       "  'gene',\n",
       "  'glean',\n",
       "  'green',\n",
       "  'guillotine',\n",
       "  'intervene',\n",
       "  'jean',\n",
       "  'keen',\n",
       "  'latrine',\n",
       "  'lean',\n",
       "  'limousine',\n",
       "  'machine',\n",
       "  'magazine',\n",
       "  'marine',\n",
       "  'mean',\n",
       "  'mien',\n",
       "  'obscene',\n",
       "  'philistine',\n",
       "  'protein',\n",
       "  'quarantine',\n",
       "  'queen',\n",
       "  'ravine',\n",
       "  'routine',\n",
       "  'sabine',\n",
       "  'saline',\n",
       "  'scene',\n",
       "  'screen',\n",
       "  'seen',\n",
       "  'serene',\n",
       "  'sheen',\n",
       "  'sistine',\n",
       "  'spleen',\n",
       "  'submarine',\n",
       "  'teen',\n",
       "  'thirteen',\n",
       "  'unforeseen',\n",
       "  'wolverine'},\n",
       " 'mitch': {'bitch',\n",
       "  'chich',\n",
       "  'ditch',\n",
       "  'enrich',\n",
       "  'greenwich',\n",
       "  'hitch',\n",
       "  'itch',\n",
       "  'niche',\n",
       "  'pitch',\n",
       "  'rich',\n",
       "  'stitch',\n",
       "  'switch',\n",
       "  'twitch',\n",
       "  'unhitch',\n",
       "  'which',\n",
       "  'witch'},\n",
       " 'dick': {'bric',\n",
       "  'brick',\n",
       "  'chick',\n",
       "  'click',\n",
       "  'flick',\n",
       "  'glick',\n",
       "  'homesick',\n",
       "  'joystick',\n",
       "  'kick',\n",
       "  'lick',\n",
       "  'lipstick',\n",
       "  'lunatic',\n",
       "  'nick',\n",
       "  'pick',\n",
       "  'picnic',\n",
       "  'politic',\n",
       "  'prick',\n",
       "  'quick',\n",
       "  'quik',\n",
       "  'rick',\n",
       "  'sic',\n",
       "  'sick',\n",
       "  'slick',\n",
       "  'spick',\n",
       "  'stick',\n",
       "  'thick',\n",
       "  'tick',\n",
       "  'trick',\n",
       "  'vick',\n",
       "  'wick'},\n",
       " 'herb': {'blurb', 'curb', 'disturb', 'superb', 'verb'},\n",
       " 'preston': {'clandestine', 'destine'},\n",
       " 'sally': {'alley',\n",
       "  'dally',\n",
       "  'finale',\n",
       "  'galley',\n",
       "  'rally',\n",
       "  'tally',\n",
       "  'valley',\n",
       "  'verbally'},\n",
       " 'trent': {'accent',\n",
       "  'advent',\n",
       "  'ascent',\n",
       "  'assent',\n",
       "  'bent',\n",
       "  'blent',\n",
       "  'cement',\n",
       "  'cent',\n",
       "  'circumvent',\n",
       "  'consent',\n",
       "  'content',\n",
       "  'convent',\n",
       "  'dent',\n",
       "  'descent',\n",
       "  'discontent',\n",
       "  'dissent',\n",
       "  'ent',\n",
       "  'event',\n",
       "  'extent',\n",
       "  'ferment',\n",
       "  'frequent',\n",
       "  'intent',\n",
       "  'invent',\n",
       "  'kent',\n",
       "  'lament',\n",
       "  'lent',\n",
       "  'meant',\n",
       "  'mente',\n",
       "  'orient',\n",
       "  'pent',\n",
       "  'percent',\n",
       "  'present',\n",
       "  'president',\n",
       "  'prevent',\n",
       "  'reinvent',\n",
       "  'relent',\n",
       "  'rent',\n",
       "  'repent',\n",
       "  'represent',\n",
       "  'resent',\n",
       "  'scent',\n",
       "  'segment',\n",
       "  'sent',\n",
       "  'shent',\n",
       "  'spent',\n",
       "  'tent',\n",
       "  'torment',\n",
       "  'underwent',\n",
       "  'vent',\n",
       "  'went'},\n",
       " 'willy': {'chile',\n",
       "  'chilly',\n",
       "  'frilly',\n",
       "  'lilly',\n",
       "  'lily',\n",
       "  'nilly',\n",
       "  'really',\n",
       "  'silly'},\n",
       " 'allen': {'alan', 'gallon'},\n",
       " 'yen': {'again',\n",
       "  'amen',\n",
       "  'ben',\n",
       "  'businessmen',\n",
       "  'cnn',\n",
       "  'den',\n",
       "  'en',\n",
       "  'fen',\n",
       "  'glen',\n",
       "  'hen',\n",
       "  'ken',\n",
       "  'len',\n",
       "  'men',\n",
       "  'n',\n",
       "  'pen',\n",
       "  'penn',\n",
       "  'sen',\n",
       "  'ten',\n",
       "  'then',\n",
       "  'when',\n",
       "  'wren',\n",
       "  'zen'},\n",
       " 'stacey': {'lacy'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.get_two_sets_henry(\"love\", progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting rhyming words of word 1 'ginny' ...... 1 / 20 done.\n",
      "Getting rhyming words of word 1 'sunni' ...... 2 / 20 done.\n",
      "Getting rhyming words of word 1 'royal' ...... 3 / 20 done.\n",
      "Unable to find rhyming words of word 1 'jorge'\n",
      "Getting rhyming words of word 1 'nathaniel' ...... 4 / 20 done.\n",
      "Unable to find rhyming words of word 1 'onie'\n",
      "Unable to find rhyming words of word 1 'janean'\n",
      "Getting rhyming words of word 1 'patience' ...... 5 / 20 done.\n",
      "Unable to find rhyming words of word 1 'carlyn'\n",
      "Getting rhyming words of word 1 'adam' ...... 6 / 20 done.\n",
      "Unable to find rhyming words of word 1 'calvin'\n",
      "Getting rhyming words of word 1 'walker' ...... 7 / 20 done.\n",
      "Unable to find rhyming words of word 1 'whitley'\n",
      "Getting rhyming words of word 1 'loren' ...... 8 / 20 done.\n",
      "Unable to find rhyming words of word 1 'kourtney'\n",
      "Getting rhyming words of word 1 'roland' ...... 9 / 20 done.\n",
      "Getting rhyming words of word 1 'thomasine' ...... 10 / 20 done.\n",
      "Unable to find rhyming words of word 1 'mario'\n",
      "Unable to find rhyming words of word 1 'libby'\n",
      "Unable to find rhyming words of word 1 'avril'\n",
      "Unable to find rhyming words of word 1 'asley'\n",
      "Getting rhyming words of word 1 'adele' ...... 11 / 20 done.\n",
      "Getting rhyming words of word 1 'katie' ...... 12 / 20 done.\n",
      "Getting rhyming words of word 1 'hollie' ...... 13 / 20 done.\n",
      "Getting rhyming words of word 1 'hellen' ...... 14 / 20 done.\n",
      "Getting rhyming words of word 1 'chu' ...... 15 / 20 done.\n",
      "Unable to find rhyming words of word 1 'yael'\n",
      "Unable to find rhyming words of word 1 'mertie'\n",
      "Getting rhyming words of word 1 'suzy' ...... 16 / 20 done.\n",
      "Getting rhyming words of word 1 'maris' ...... 17 / 20 done.\n",
      "Unable to find rhyming words of word 1 'marylyn'\n",
      "Unable to find rhyming words of word 1 'kristan'\n",
      "Getting rhyming words of word 1 'grady' ...... 18 / 20 done.\n",
      "Getting rhyming words of word 1 'layne' ...... 19 / 20 done.\n",
      "Unable to find rhyming words of word 1 'genesis'\n",
      "Unable to find rhyming words of word 1 'vennie'\n",
      "Unable to find rhyming words of word 1 'ivory'\n",
      "Unable to find rhyming words of word 1 'margret'\n",
      "Getting rhyming words of word 1 'mitch' ...... 20 / 20 done.\n",
      "Getting rhyming words of word 3 'affection' ...... 1 / 20 done.\n",
      "Getting rhyming words of word 3 'desire' ...... 2 / 20 done.\n",
      "Getting rhyming words of word 3 'devotion' ...... 3 / 20 done.\n",
      "Getting rhyming words of word 3 'great' ...... 4 / 20 done.\n",
      "Getting rhyming words of word 3 'pleasure' ...... 5 / 20 done.\n",
      "Getting rhyming words of word 3 'beloved' ...... 6 / 20 done.\n",
      "Getting rhyming words of word 3 'feeling' ...... 7 / 20 done.\n",
      "Getting rhyming words of word 3 'people' ...... 8 / 20 done.\n",
      "Getting rhyming words of word 3 'emotion' ...... 9 / 20 done.\n",
      "Unable to find rhyming words of word 3 'person'\n",
      "Getting rhyming words of word 3 'passion' ...... 11 / 20 done.\n",
      "Getting rhyming words of word 3 'lovers' ...... 12 / 20 done.\n",
      "Getting rhyming words of word 3 'lover' ...... 13 / 20 done.\n",
      "Getting rhyming words of word 3 'affection' ...... 14 / 20 done.\n",
      "Getting rhyming words of word 3 'everyone' ...... 15 / 20 done.\n",
      "Unable to find rhyming words of word 3 'something'\n",
      "Getting rhyming words of word 3 'romance' ...... 17 / 20 done.\n",
      "Getting rhyming words of word 3 'fun' ...... 18 / 20 done.\n",
      "Getting rhyming words of word 3 'life' ...... 19 / 20 done.\n",
      "Getting rhyming words of word 3 'friends' ...... 20 / 20 done.\n",
      "'royal' and 'affection' are unable to generate storyline\n",
      "'royal' and 'desire' are unable to generate storyline\n",
      "'royal' and 'devotion' are unable to generate storyline\n",
      "'royal' and 'great' are unable to generate storyline\n",
      "'royal' and 'pleasure' are unable to generate storyline\n",
      "'royal' and 'beloved' are unable to generate storyline\n",
      "'royal' and 'feeling' are unable to generate storyline\n",
      "'royal' and 'people' are unable to generate storyline\n",
      "'royal' and 'emotion' are unable to generate storyline\n",
      "'royal' and 'passion' are unable to generate storyline\n",
      "'royal' and 'lovers' are unable to generate storyline\n",
      "'royal' and 'lover' are unable to generate storyline\n",
      "'royal' and 'everyone' are unable to generate storyline\n",
      "'royal' and 'romance' are unable to generate storyline\n",
      "'royal' and 'fun' are unable to generate storyline\n",
      "'royal' and 'life' are unable to generate storyline\n",
      "'royal' and 'friends' are unable to generate storyline\n",
      "'nathaniel' and 'affection' are unable to generate storyline\n",
      "'nathaniel' and 'desire' are unable to generate storyline\n",
      "'nathaniel' and 'devotion' are unable to generate storyline\n",
      "'nathaniel' and 'great' are unable to generate storyline\n",
      "'nathaniel' and 'pleasure' are unable to generate storyline\n",
      "'nathaniel' and 'beloved' are unable to generate storyline\n",
      "'nathaniel' and 'feeling' are unable to generate storyline\n",
      "'nathaniel' and 'people' are unable to generate storyline\n",
      "'nathaniel' and 'emotion' are unable to generate storyline\n",
      "'nathaniel' and 'passion' are unable to generate storyline\n",
      "'nathaniel' and 'lovers' are unable to generate storyline\n",
      "'nathaniel' and 'lover' are unable to generate storyline\n",
      "'nathaniel' and 'everyone' are unable to generate storyline\n",
      "'nathaniel' and 'romance' are unable to generate storyline\n",
      "'nathaniel' and 'fun' are unable to generate storyline\n",
      "'nathaniel' and 'life' are unable to generate storyline\n",
      "'nathaniel' and 'friends' are unable to generate storyline\n",
      "'roland' and 'affection' are unable to generate storyline\n",
      "'roland' and 'desire' are unable to generate storyline\n",
      "'roland' and 'devotion' are unable to generate storyline\n",
      "'roland' and 'great' are unable to generate storyline\n",
      "'roland' and 'pleasure' are unable to generate storyline\n",
      "'roland' and 'beloved' are unable to generate storyline\n",
      "'roland' and 'feeling' are unable to generate storyline\n",
      "'roland' and 'people' are unable to generate storyline\n",
      "'roland' and 'emotion' are unable to generate storyline\n",
      "'roland' and 'passion' are unable to generate storyline\n",
      "'roland' and 'lovers' are unable to generate storyline\n",
      "'roland' and 'lover' are unable to generate storyline\n",
      "'roland' and 'everyone' are unable to generate storyline\n",
      "'roland' and 'romance' are unable to generate storyline\n",
      "'roland' and 'fun' are unable to generate storyline\n",
      "'roland' and 'life' are unable to generate storyline\n",
      "'roland' and 'friends' are unable to generate storyline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Ginny', 'guinea', 'affection', 'reflection', 'skinny'],\n",
       " ['Ginny', 'tinny', 'desire', 'inspire', 'skinny'],\n",
       " ['Ginny', 'skinny', 'devotion', 'emotion', 'mini'],\n",
       " ['Ginny', 'guinea', 'great', 'late', 'mini'],\n",
       " ['Ginny', 'tinny', 'pleasure', 'leisure', 'mini'],\n",
       " ['Ginny', 'mini', 'beloved', 'unloved', 'skinny'],\n",
       " ['Ginny', 'tinny', 'feeling', 'appealing', 'skinny'],\n",
       " ['Ginny', 'tinny', 'people', 'townspeople', 'skinny'],\n",
       " ['Ginny', 'guinea', 'emotion', 'devotion', 'skinny'],\n",
       " ['Ginny', 'tinny', 'passion', 'dedication', 'shinny'],\n",
       " ['Ginny', 'skinny', 'lovers', 'discovers', 'mini'],\n",
       " ['Ginny', 'shinny', 'lover', 'discover', 'tinny'],\n",
       " ['Ginny', 'skinny', 'everyone', 'fun', 'mini'],\n",
       " ['Ginny', 'skinny', 'romance', 'dance', 'mini'],\n",
       " ['Ginny', 'shinny', 'fun', 'everyone', 'mini'],\n",
       " ['Ginny', 'guinea', 'life', 'wife', 'mini'],\n",
       " ['Ginny', 'skinny', 'friends', 'befriends', 'mini'],\n",
       " ['Sunni', 'moony', 'affection', 'introspection', 'puny'],\n",
       " ['Sunni', 'moony', 'desire', 'inspire', 'puny'],\n",
       " ['Sunni', 'puny', 'devotion', 'emotion', 'moony'],\n",
       " ['Sunni', 'puny', 'great', 'appreciate', 'moony'],\n",
       " ['Sunni', 'puny', 'pleasure', 'treasure', 'moony'],\n",
       " ['Sunni', 'puny', 'beloved', 'unloved', 'moony'],\n",
       " ['Sunni', 'moony', 'feeling', 'healing', 'puny'],\n",
       " ['Sunni', 'puny', 'people', 'townspeople', 'moony'],\n",
       " ['Sunni', 'moony', 'emotion', 'devotion', 'puny'],\n",
       " ['Sunni', 'puny', 'passion', 'compassion', 'moony'],\n",
       " ['Sunni', 'puny', 'lovers', 'discovers', 'moony'],\n",
       " ['Sunni', 'moony', 'lover', 'discover', 'puny'],\n",
       " ['Sunni', 'moony', 'everyone', 'anyone', 'puny'],\n",
       " ['Sunni', 'puny', 'romance', 'dance', 'moony'],\n",
       " ['Sunni', 'puny', 'fun', 'everyone', 'moony'],\n",
       " ['Sunni', 'puny', 'life', 'afterlife', 'moony'],\n",
       " ['Sunni', 'puny', 'friends', 'spends', 'moony'],\n",
       " ['Patience', 'patience', 'affection', 'reflection', 'impatience'],\n",
       " ['Patience', 'patience', 'desire', 'inspire', 'impatience'],\n",
       " ['Patience', 'patience', 'devotion', 'emotion', 'impatience'],\n",
       " ['Patience', 'impatience', 'great', 'appreciate', 'patience'],\n",
       " ['Patience', 'impatience', 'pleasure', 'leisure', 'patience'],\n",
       " ['Patience', 'impatience', 'beloved', 'unloved', 'patience'],\n",
       " ['Patience', 'patience', 'feeling', 'healing', 'impatience'],\n",
       " ['Patience', 'impatience', 'people', 'townspeople', 'patience'],\n",
       " ['Patience', 'patience', 'emotion', 'devotion', 'impatience'],\n",
       " ['Patience', 'patience', 'passion', 'compassion', 'impatience'],\n",
       " ['Patience', 'impatience', 'lovers', 'discovers', 'patience'],\n",
       " ['Patience', 'patience', 'lover', 'discover', 'impatience'],\n",
       " ['Patience', 'impatience', 'everyone', 'someone', 'patience'],\n",
       " ['Patience', 'impatience', 'romance', 'dance', 'patience'],\n",
       " ['Patience', 'impatience', 'fun', 'everyone', 'patience'],\n",
       " ['Patience', 'patience', 'life', 'wife', 'impatience'],\n",
       " ['Patience', 'impatience', 'friends', 'sends', 'patience'],\n",
       " ['Adam', 'am', 'affection', 'reflection', 'damn'],\n",
       " ['Adam', 'damn', 'desire', 'admire', 'am'],\n",
       " ['Adam', 'program', 'devotion', 'promotion', 'programme'],\n",
       " ['Adam', 'jam', 'great', 'late', 'am'],\n",
       " ['Adam', 'damn', 'pleasure', 'leisure', 'am'],\n",
       " ['Adam', 'pam', 'beloved', 'unloved', 'madame'],\n",
       " ['Adam', 'jam', 'feeling', 'appealing', 'am'],\n",
       " ['Adam', 'jam', 'people', 'townspeople', 'am'],\n",
       " ['Adam', 'damn', 'emotion', 'devotion', 'am'],\n",
       " ['Adam', 'damn', 'passion', 'compassion', 'am'],\n",
       " ['Adam', 'madame', 'lovers', 'discovers', 'pam'],\n",
       " ['Adam', 'am', 'lover', 'discover', 'damn'],\n",
       " ['Adam', 'damn', 'everyone', 'anyone', 'am'],\n",
       " ['Adam', 'pam', 'romance', 'dance', 'slam'],\n",
       " ['Adam', 'slam', 'fun', 'everyone', 'am'],\n",
       " ['Adam', 'madame', 'life', 'wife', 'pam'],\n",
       " ['Adam', 'program', 'friends', 'weekends', 'programme'],\n",
       " ['Walker', 'knocker', 'affection', 'introspection', 'talker'],\n",
       " ['Walker', 'soccer', 'desire', 'inspire', 'rocker'],\n",
       " ['Walker', 'laugher', 'devotion', 'emotion', 'talker'],\n",
       " ['Walker', 'hawker', 'great', 'appreciate', 'soccer'],\n",
       " ['Walker', 'soccer', 'pleasure', 'leisure', 'rocker'],\n",
       " ['Walker', 'soccer', 'beloved', 'unloved', 'rocker'],\n",
       " ['Walker', 'hawker', 'feeling', 'dealing', 'soccer'],\n",
       " ['Walker', 'hawker', 'people', 'townspeople', 'laugher'],\n",
       " ['Walker', 'soccer', 'emotion', 'devotion', 'rocker'],\n",
       " ['Walker', 'talker', 'passion', 'compassion', 'rocker'],\n",
       " ['Walker', 'laugher', 'lovers', 'discovers', 'talker'],\n",
       " ['Walker', 'hawker', 'lover', 'discover', 'soccer'],\n",
       " ['Walker', 'rocker', 'everyone', 'someone', 'soccer'],\n",
       " ['Walker', 'knocker', 'romance', 'dance', 'rocker'],\n",
       " ['Walker', 'laugher', 'fun', 'everyone', 'talker'],\n",
       " ['Walker', 'rocker', 'life', 'wife', 'soccer'],\n",
       " ['Walker', 'talker', 'friends', 'weekends', 'soccer'],\n",
       " ['Loren', 'aren', 'affection', 'predilection', 'horan'],\n",
       " ['Loren', 'aren', 'desire', 'inspire', 'foreign'],\n",
       " ['Loren', 'aren', 'devotion', 'emotion', 'foreign'],\n",
       " ['Loren', 'foreign', 'great', 'appreciate', 'warren'],\n",
       " ['Loren', 'foreign', 'pleasure', 'leisure', 'warren'],\n",
       " ['Loren', 'warren', 'beloved', 'unloved', 'foreign'],\n",
       " ['Loren', 'aren', 'feeling', 'healing', 'horan'],\n",
       " ['Loren', 'warren', 'people', 'townspeople', 'foreign'],\n",
       " ['Loren', 'aren', 'emotion', 'devotion', 'horan'],\n",
       " ['Loren', 'warren', 'passion', 'inspiration', 'foreign'],\n",
       " ['Loren', 'foreign', 'lovers', 'discovers', 'warren'],\n",
       " ['Loren', 'warren', 'lover', 'discover', 'foreign'],\n",
       " ['Loren', 'horan', 'everyone', 'anyone', 'warren'],\n",
       " ['Loren', 'aren', 'romance', 'dance', 'warren'],\n",
       " ['Loren', 'aren', 'fun', 'everyone', 'foreign'],\n",
       " ['Loren', 'aren', 'life', 'afterlife', 'horan'],\n",
       " ['Loren', 'warren', 'friends', 'ends', 'foreign'],\n",
       " ['Thomasine', 'genuine', 'affection', 'reflection', 'mean'],\n",
       " ['Thomasine', 'sign', 'desire', 'inspire', 'genuine'],\n",
       " ['Thomasine', 'divine', 'devotion', 'emotion', 'genuine'],\n",
       " ['Thomasine', 'seen', 'great', 'appreciate', 'mean'],\n",
       " ['Thomasine', 'genuine', 'pleasure', 'treasure', 'keen'],\n",
       " ['Thomasine', 'queen', 'beloved', 'unloved', 'teen'],\n",
       " ['Thomasine', 'sign', 'feeling', 'dealing', 'seen'],\n",
       " ['Thomasine', 'between', 'people', 'townspeople', 'seen'],\n",
       " ['Thomasine', 'teen', 'emotion', 'devotion', 'genuine'],\n",
       " ['Thomasine', 'teen', 'passion', 'inspiration', 'scene'],\n",
       " ['Thomasine', 'teen', 'lovers', 'discovers', 'scene'],\n",
       " ['Thomasine', 'divine', 'lover', 'discover', 'genuine'],\n",
       " ['Thomasine', 'sign', 'everyone', 'anyone', 'mean'],\n",
       " ['Thomasine', 'teen', 'romance', 'dance', 'scene'],\n",
       " ['Thomasine', 'genuine', 'fun', 'everyone', 'mean'],\n",
       " ['Thomasine', 'scene', 'life', 'wife', 'seen'],\n",
       " ['Thomasine', 'scene', 'friends', 'ends', 'seen'],\n",
       " ['Adele', 'smell', 'affection', 'reflection', 'tell'],\n",
       " ['Adele', 'tell', 'desire', 'inspire', 'well'],\n",
       " ['Adele', 'well', 'devotion', 'emotion', 'tell'],\n",
       " ['Adele', 'sell', 'great', 'create', 'well'],\n",
       " ['Adele', 'smell', 'pleasure', 'treasure', 'tell'],\n",
       " ['Adele', 'well', 'beloved', 'unloved', 'tell'],\n",
       " ['Adele', 'tell', 'feeling', 'dealing', 'well'],\n",
       " ['Adele', 'hell', 'people', 'townspeople', 'tell'],\n",
       " ['Adele', 'hell', 'emotion', 'devotion', 'tell'],\n",
       " ['Adele', 'well', 'passion', 'inspiration', 'tell'],\n",
       " ['Adele', 'smell', 'lovers', 'discovers', 'tell'],\n",
       " ['Adele', 'hell', 'lover', 'discover', 'tell'],\n",
       " ['Adele', 'well', 'everyone', 'anyone', 'tell'],\n",
       " ['Adele', 'smell', 'romance', 'dance', 'tell'],\n",
       " ['Adele', 'hell', 'fun', 'everyone', 'tell'],\n",
       " ['Adele', 'travel', 'life', 'wife', 'tell'],\n",
       " ['Adele', 'tell', 'friends', 'ends', 'well'],\n",
       " ['Katie', 'we', 'affection', 'reflection', 'way'],\n",
       " ['Katie', 'see', 'desire', 'inspire', 'me'],\n",
       " ['Katie', 'we', 'devotion', 'emotion', 'me'],\n",
       " ['Katie', 'way', 'great', 'appreciate', 'we'],\n",
       " ['Katie', 'me', 'pleasure', 'leisure', 'way'],\n",
       " ['Katie', 'see', 'beloved', 'unloved', 'me'],\n",
       " ['Katie', 'she', 'feeling', 'dealing', 'he'],\n",
       " ['Katie', 'she', 'people', 'townspeople', 'he'],\n",
       " ['Katie', 'she', 'emotion', 'devotion', 'me'],\n",
       " ['Katie', 'she', 'passion', 'inspiration', 'me'],\n",
       " ['Katie', 'she', 'lovers', 'discovers', 'me'],\n",
       " ['Katie', 'way', 'lover', 'discover', 'me'],\n",
       " ['Katie', 'see', 'everyone', 'anyone', 'me'],\n",
       " ['Katie', 'reality', 'romance', 'dance', 'way'],\n",
       " ['Katie', 'me', 'fun', 'everyone', 'we'],\n",
       " ['Katie', 'she', 'life', 'wife', 'he'],\n",
       " ['Katie', 'see', 'friends', 'weekends', 'we'],\n",
       " ['Hollie', 'folly', 'affection', 'reflection', 'melancholy'],\n",
       " ['Hollie', 'holly', 'desire', 'inspire', 'jolly'],\n",
       " ['Hollie', 'melancholy', 'devotion', 'emotion', 'folly'],\n",
       " ['Hollie', 'ali', 'great', 'late', 'dali'],\n",
       " ['Hollie', 'folly', 'pleasure', 'leisure', 'jolly'],\n",
       " ['Hollie', 'holly', 'beloved', 'unloved', 'jolly'],\n",
       " ['Hollie', 'melancholy', 'feeling', 'healing', 'folly'],\n",
       " ['Hollie', 'folly', 'people', 'townspeople', 'melancholy'],\n",
       " ['Hollie', 'dolly', 'emotion', 'devotion', 'melancholy'],\n",
       " ['Hollie', 'folly', 'passion', 'compassion', 'melancholy'],\n",
       " ['Hollie', 'folly', 'lovers', 'discovers', 'melancholy'],\n",
       " ['Hollie', 'folly', 'lover', 'discover', 'holly'],\n",
       " ['Hollie', 'jolly', 'everyone', 'fun', 'holly'],\n",
       " ['Hollie', 'folly', 'romance', 'dance', 'melancholy'],\n",
       " ['Hollie', 'dolly', 'fun', 'everyone', 'holly'],\n",
       " ['Hollie', 'holly', 'life', 'wife', 'jolly'],\n",
       " ['Hollie', 'jolly', 'friends', 'befriends', 'holly'],\n",
       " ['Hellen', 'helen', 'affection', 'perfection', 'ellen'],\n",
       " ['Hellen', 'ellen', 'desire', 'inspire', 'helen'],\n",
       " ['Hellen', 'melon', 'devotion', 'emotion', 'helen'],\n",
       " ['Hellen', 'melon', 'great', 'appreciate', 'helen'],\n",
       " ['Hellen', 'melon', 'pleasure', 'leisure', 'felon'],\n",
       " ['Hellen', 'ellen', 'beloved', 'unloved', 'helen'],\n",
       " ['Hellen', 'melon', 'feeling', 'healing', 'helen'],\n",
       " ['Hellen', 'felon', 'people', 'townspeople', 'melon'],\n",
       " ['Hellen', 'melon', 'emotion', 'devotion', 'helen'],\n",
       " ['Hellen', 'helen', 'passion', 'dedication', 'ellen'],\n",
       " ['Hellen', 'helen', 'lovers', 'discovers', 'ellen'],\n",
       " ['Hellen', 'melon', 'lover', 'discover', 'helen'],\n",
       " ['Hellen', 'ellen', 'everyone', 'someone', 'helen'],\n",
       " ['Hellen', 'helen', 'romance', 'dance', 'ellen'],\n",
       " ['Hellen', 'melon', 'fun', 'everyone', 'ellen'],\n",
       " ['Hellen', 'helen', 'life', 'wife', 'ellen'],\n",
       " ['Hellen', 'helen', 'friends', 'befriends', 'ellen'],\n",
       " ['Chu', 'too', 'affection', 'reflection', 'you'],\n",
       " ['Chu', 'true', 'desire', 'inspire', 'do'],\n",
       " ['Chu', 'you', 'devotion', 'emotion', 'do'],\n",
       " ['Chu', 'too', 'great', 'appreciate', 'you'],\n",
       " ['Chu', 'do', 'pleasure', 'leisure', 'you'],\n",
       " ['Chu', 'who', 'beloved', 'unloved', 'too'],\n",
       " ['Chu', 'true', 'feeling', 'healing', 'you'],\n",
       " ['Chu', 'too', 'people', 'townspeople', 'who'],\n",
       " ['Chu', 'too', 'emotion', 'notion', 'you'],\n",
       " ['Chu', 'you', 'passion', 'compassion', 'do'],\n",
       " ['Chu', 'who', 'lovers', 'discovers', 'true'],\n",
       " ['Chu', 'you', 'lover', 'discover', 'do'],\n",
       " ['Chu', 'too', 'everyone', 'anyone', 'you'],\n",
       " ['Chu', 'too', 'romance', 'dance', 'you'],\n",
       " ['Chu', 'do', 'fun', 'everyone', 'you'],\n",
       " ['Chu', 'true', 'life', 'wife', 'you'],\n",
       " ['Chu', 'true', 'friends', 'ends', 'you'],\n",
       " ['Suzy', 'woozy', 'affection', 'introspection', 'jacuzzi'],\n",
       " ['Suzy', 'woozy', 'desire', 'inspire', 'jacuzzi'],\n",
       " ['Suzy', 'jacuzzi', 'devotion', 'emotion', 'woozy'],\n",
       " ['Suzy', 'jacuzzi', 'great', 'appreciate', 'woozy'],\n",
       " ['Suzy', 'woozy', 'pleasure', 'leisure', 'jacuzzi'],\n",
       " ['Suzy', 'jacuzzi', 'beloved', 'unloved', 'woozy'],\n",
       " ['Suzy', 'jacuzzi', 'feeling', 'healing', 'woozy'],\n",
       " ['Suzy', 'jacuzzi', 'people', 'townspeople', 'woozy'],\n",
       " ['Suzy', 'woozy', 'emotion', 'commotion', 'jacuzzi'],\n",
       " ['Suzy', 'jacuzzi', 'passion', 'vocation', 'woozy'],\n",
       " ['Suzy', 'jacuzzi', 'lovers', 'discovers', 'woozy'],\n",
       " ['Suzy', 'jacuzzi', 'lover', 'discover', 'woozy'],\n",
       " ['Suzy', 'woozy', 'everyone', 'fun', 'jacuzzi'],\n",
       " ['Suzy', 'jacuzzi', 'romance', 'dance', 'woozy'],\n",
       " ['Suzy', 'woozy', 'fun', 'everyone', 'jacuzzi'],\n",
       " ['Suzy', 'woozy', 'life', 'wife', 'jacuzzi'],\n",
       " ['Suzy', 'woozy', 'friends', 'befriends', 'jacuzzi'],\n",
       " ['Maris', 'terrace', 'affection', 'reflection', 'paris'],\n",
       " ['Maris', 'embarrass', 'desire', 'inspire', 'paris'],\n",
       " ['Maris', 'harris', 'devotion', 'emotion', 'paris'],\n",
       " ['Maris', 'terrace', 'great', 'celebrate', 'paris'],\n",
       " ['Maris', 'embarrass', 'pleasure', 'leisure', 'paris'],\n",
       " ['Maris', 'paris', 'beloved', 'unloved', 'heiress'],\n",
       " ['Maris', 'paris', 'feeling', 'dealing', 'harris'],\n",
       " ['Maris', 'embarrass', 'people', 'townspeople', 'harris'],\n",
       " ['Maris', 'harris', 'emotion', 'devotion', 'paris'],\n",
       " ['Maris', 'embarrass', 'passion', 'motivation', 'harris'],\n",
       " ['Maris', 'paris', 'lovers', 'discovers', 'heiress'],\n",
       " ['Maris', 'harris', 'lover', 'discover', 'paris'],\n",
       " ['Maris', 'embarrass', 'everyone', 'anyone', 'harris'],\n",
       " ['Maris', 'harris', 'romance', 'dance', 'paris'],\n",
       " ['Maris', 'heiress', 'fun', 'someone', 'paris'],\n",
       " ['Maris', 'paris', 'life', 'wife', 'heiress'],\n",
       " ['Maris', 'embarrass', 'friends', 'pretends', 'heiress'],\n",
       " ['Grady', 'lady', 'affection', 'reflection', 'shady'],\n",
       " ['Grady', 'shady', 'desire', 'admire', 'lady'],\n",
       " ['Grady', 'shady', 'devotion', 'emotion', 'lady'],\n",
       " ['Grady', 'lady', 'great', 'appreciate', 'shady'],\n",
       " ['Grady', 'shady', 'pleasure', 'leisure', 'lady'],\n",
       " ['Grady', 'lady', 'beloved', 'unloved', 'shady'],\n",
       " ['Grady', 'shady', 'feeling', 'dealing', 'lady'],\n",
       " ['Grady', 'arkady', 'people', 'townspeople', 'shady'],\n",
       " ['Grady', 'lady', 'emotion', 'devotion', 'shady'],\n",
       " ['Grady', 'arkady', 'passion', 'motivation', 'shady'],\n",
       " ['Grady', 'lady', 'lovers', 'discovers', 'shady'],\n",
       " ['Grady', 'shady', 'lover', 'discover', 'lady'],\n",
       " ['Grady', 'arkady', 'everyone', 'anyone', 'lady'],\n",
       " ['Grady', 'lady', 'romance', 'dance', 'shady'],\n",
       " ['Grady', 'arkady', 'fun', 'everyone', 'lady'],\n",
       " ['Grady', 'shady', 'life', 'wife', 'lady'],\n",
       " ['Grady', 'shady', 'friends', 'weekends', 'lady'],\n",
       " ['Layne', 'again', 'affection', 'reflection', 'when'],\n",
       " ['Layne', 'explain', 'desire', 'inspire', 'sustain'],\n",
       " ['Layne', 'again', 'devotion', 'emotion', 'when'],\n",
       " ['Layne', 'when', 'great', 'late', 'again'],\n",
       " ['Layne', 'again', 'pleasure', 'leisure', 'when'],\n",
       " ['Layne', 'when', 'beloved', 'unloved', 'again'],\n",
       " ['Layne', 'explains', 'feeling', 'healing', 'pain'],\n",
       " ['Layne', 'again', 'people', 'townspeople', 'when'],\n",
       " ['Layne', 'explain', 'emotion', 'notion', 'when'],\n",
       " ['Layne', 'disdain', 'passion', 'compassion', 'pain'],\n",
       " ['Layne', 'vain', 'lovers', 'discovers', 'when'],\n",
       " ['Layne', 'explains', 'lover', 'discover', 'when'],\n",
       " ['Layne', 'then', 'everyone', 'when', 'again'],\n",
       " ['Layne', 'when', 'romance', 'dance', 'again'],\n",
       " ['Layne', 'win', 'fun', 'everyone', 'again'],\n",
       " ['Layne', 'men', 'life', 'wife', 'when'],\n",
       " ['Layne', 'explains', 'friends', 'spends', 'complains'],\n",
       " ['Mitch', 'rich', 'affection', 'reflection', 'which'],\n",
       " ['Mitch', 'witch', 'desire', 'inspire', 'which'],\n",
       " ['Mitch', 'pitch', 'devotion', 'emotion', 'which'],\n",
       " ['Mitch', 'which', 'great', 'create', 'rich'],\n",
       " ['Mitch', 'bitch', 'pleasure', 'leisure', 'rich'],\n",
       " ['Mitch', 'witch', 'beloved', 'unloved', 'bitch'],\n",
       " ['Mitch', 'pitch', 'feeling', 'dealing', 'which'],\n",
       " ['Mitch', 'which', 'people', 'townspeople', 'rich'],\n",
       " ['Mitch', 'niche', 'emotion', 'devotion', 'which'],\n",
       " ['Mitch', 'witch', 'passion', 'inspiration', 'which'],\n",
       " ['Mitch', 'bitch', 'lovers', 'discovers', 'witch'],\n",
       " ['Mitch', 'bitch', 'lover', 'discover', 'witch'],\n",
       " ['Mitch', 'pitch', 'everyone', 'anyone', 'which'],\n",
       " ['Mitch', 'bitch', 'romance', 'dance', 'witch'],\n",
       " ['Mitch', 'which', 'fun', 'everyone', 'pitch'],\n",
       " ['Mitch', 'bitch', 'life', 'wife', 'witch'],\n",
       " ['Mitch', 'bitch', 'friends', 'weekends', 'witch']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.get_five_words_henry('love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('gath', 'path', 'say', 'way', 'bath')\n",
      "('hath', 'path', 'say', 'way', 'footpath')\n"
     ]
    }
   ],
   "source": [
    "print(lg.get_five_words('path'))\n",
    "print(lg.get_five_words_henry('path'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('everything', 'spring', 'reason', 'season', 'ring')\n",
      "('pling', 'spring', 'reason', 'season', 'thing')\n"
     ]
    }
   ],
   "source": [
    "print(lg.get_five_words('spring'))\n",
    "print(lg.get_five_words_henry('spring'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dame', 'game', 'they', 'play', 'name')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\0\\Github\\Poetix18\\py_files\\Limericks.py:196: RuntimeWarning: invalid value encountered in power\n",
      "  sim += self.poetic_vectors.similarity(word, other_word) ** 0.5\n",
      "D:\\0\\Github\\Poetix18\\py_files\\Limericks.py:296: RuntimeWarning: invalid value encountered in power\n",
      "  sim = self.poetic_vectors.similarity(w2, r) ** 0.5\n",
      "D:\\0\\Github\\Poetix18\\py_files\\Limericks.py:297: RuntimeWarning: invalid value encountered in power\n",
      "  sim += self.poetic_vectors.similarity(w4, r) ** 0.5\n",
      "D:\\0\\Github\\Poetix18\\py_files\\Limericks.py:311: RuntimeWarning: invalid value encountered in power\n",
      "  sim = self.poetic_vectors.similarity(w2, r) ** 0.5 * 2\n",
      "D:\\0\\Github\\Poetix18\\py_files\\Limericks.py:312: RuntimeWarning: invalid value encountered in power\n",
      "  sim += self.poetic_vectors.similarity(w4, r) ** 0.5 * 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('maim', 'game', 'way', 'play', 'came')\n"
     ]
    }
   ],
   "source": [
    "print(lg.get_five_words('game'))\n",
    "print(lg.get_five_words_henry('game'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WHO', 'VBD', 'DT', 'JJ', 'NN', 'IN', 'PRP$', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WP$', 'NN', 'VBD', 'DT', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'DT', 'PRP$', 'NN', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'DT', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WP$', 'NN', 'VBD', 'RB', 'JJR', 'THAN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "[(['who', 'hesitated', 'the', 'first', 'part', 'of', 'her', 'game'], -4.20305871963501, ['WHO', 'VBD', 'DT', 'JJ', 'NN', 'IN', 'PRP$', 'NN'], ['who', 'had', 'a', 'large', 'wart', 'on', 'her', 'nose']), (['who', 'fascinated', 'all', 'his', 'look', 'at', 'some', 'game'], -4.708104133605957, ['WHO', 'VBD', 'DT', 'PRP$', 'NN', 'IN', 'DT', 'NN'], ['who', 'kept', 'all', 'his', 'cash', 'in', 'a', 'bucket']), (['whose', 'personality', 'was', 'not', 'more', 'than', 'game'], -4.719402313232422, ['WP$', 'NN', 'VBD', 'RB', 'JJR', 'THAN', 'NN'], ['whose', 'speed', 'was', 'much', 'faster', 'than', 'light']), (['who', 'deteriorated', 'the', 'way', 'out', 'game'], -4.988438606262207, ['WHO', 'VBD', 'DT', 'NN', 'IN', 'NN'], ['who', 'hadnt', 'an', 'atom', 'of', 'fear']), (['whose', 'life', 'eliminated', 'the', 'way', 'out', 'game'], -5.094135829380581, ['WP$', 'NN', 'VBD', 'DT', 'NN', 'IN', 'NN'], ['whose', 'pa', 'made', 'a', 'fortune', 'in', 'pork'])]\n",
      "['RB', 'DT', 'JJ', 'NN', 'VBD', 'PRP']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "[(['only', 'the', 'whole', 'thing', 'was', 'they'], -3.443039894104004, ['RB', 'DT', 'JJ', 'NN', 'VBD', 'PRP'], ['soon', 'a', 'happy', 'thought', 'hit', 'her'])]\n",
      "['DT', 'VBN', 'TO', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'VBD', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'POS', 'DT', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['CC', 'IN', 'PRP$', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['VBZ', 'DT', 'JJ', 'NN', 'POS', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "[(['that', 'come', 'to', 'another', 'play'], -4.002622985839844, ['DT', 'VBN', 'TO', 'DT', 'NN'], ['all', 'exposed', 'to', 'the', 'breeze']), (['i', 'hesitated', 'all', 'play'], -4.113086223602295, ['PRP', 'VBD', 'DT', 'NN'], ['he', 'inserted', 'some', 'mice']), (['and', 'addition', 'ours', 'play'], -5.885270118713379, ['CC', 'IN', 'PRP$', 'NN'], ['and', 'in', 'his', 'lapel'])]\n",
      "['WDT', 'VBZ', 'PRP', 'IN', 'RB', 'JJ', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WDT', 'VBD', 'JJ', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHEN', 'PRP', 'VBP', 'PRP', ',', 'PRP', 'VBP', 'VBN', 'RB', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'RB', 'VBD', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['CC', 'PRP', 'VBZ', 'DT', 'NN', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "[(['and', 'it', 'is', 'the', 'reality', 'of', 'all', 'name'], -3.0360076427459717, ['CC', 'PRP', 'VBZ', 'DT', 'NN', 'IN', 'DT', 'NN'], ['and', 'that', 'is', 'the', 'cause', 'of', 'this', 'sonnet']), (['when', 'you', 'understand', 'me', ',', 'i', 'am', 'come', 'close', 'name'], -3.1270063400268553, ['WHEN', 'PRP', 'VBP', 'PRP', ',', 'PRP', 'VBP', 'VBN', 'RB', 'NN'], ['when', 'I', 'wear', 'it', ',', 'I', 'am', 'called', 'only', 'vermin']), (['which', 'is', 'it', 'as', 'not', 'intolerable', 'name'], -4.17210578918457, ['WDT', 'VBZ', 'PRP', 'IN', 'RB', 'JJ', 'NN'], ['which', 'leaves', 'him', 'in', 'very', 'bad', 'shape']), (['i', 'conspiratorially', 'saw', 'that', 'name'], -5.430389022827148, ['PRP', 'RB', 'VBD', 'DT', 'NN'], ['he', 'carelessly', 'stuck', 'a', 'verbena']), (['which', 'deteriorated', 'first', 'look', 'on', 'name'], -6.1767832438151045, ['WDT', 'VBD', 'JJ', 'NN', 'IN', 'NN'], ['which', 'refreshed', 'that', 'person', 'of', 'ewell'])]\n",
      "************\n",
      "there once was a young woman whose name was ame\n",
      "who hesitated the first part of her game\n",
      "only the whole thing was they\n",
      "that come to another play\n",
      "and it is the reality of all name\n",
      "\n",
      "['WHO', 'VBD', 'DT', 'JJ', 'NN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'DT', 'JJ', 'NN', 'IN', 'PRP$', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'PRP', 'RB', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'IN', 'DT', 'NN', 'IN', 'NNS']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WP$', 'NN', 'VBD', 'DT', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "[(['who', 'came', 'to', 'the', 'conservatory', 'out', 'game'], -4.073335102626255, ['WHO', 'VBD', 'IN', 'DT', 'NN', 'IN', 'NNS'], ['who', 'slipped', 'on', 'a', 'peel', 'of', 'bananas']), (['who', 'hesitated', 'the', 'first', 'part', 'of', 'her', 'game'], -4.20305871963501, ['WHO', 'VBD', 'DT', 'JJ', 'NN', 'IN', 'PRP$', 'NN'], ['who', 'had', 'a', 'large', 'wart', 'on', 'her', 'nose']), (['who', 'had', 'a', 'psychological', 'place', 'all', 'game'], -4.339798791067941, ['WHO', 'VBD', 'DT', 'JJ', 'NN', 'DT', 'NN'], ['who', 'read', 'a', 'love', 'story', 'each', 'day']), (['who', 'gave', 'me', 'immediately', 'to', 'some', 'game'], -4.39716420854841, ['WHO', 'VBD', 'PRP', 'RB', 'IN', 'DT', 'NN'], ['who', 'found', 'himself', 'quite', 'at', 'a', 'loss']), (['whose', 'life', 'was', 'the', 'imagination', 'out', 'game'], -4.439111164637974, ['WP$', 'NN', 'VBD', 'DT', 'NN', 'IN', 'NN'], ['whose', 'pa', 'made', 'a', 'fortune', 'in', 'pork'])]\n",
      "['PRP', 'VBP', 'DT', 'NN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHEN', 'DT', 'NN', 'VBZ', 'PRP$', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'VBD', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['VBD', 'DT', 'CD', 'TO', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['EX', 'VBZ', 'NN', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "[(['i', 'have', 'no', 'expression', 'way'], -2.75305118560791, ['PRP', 'VBP', 'DT', 'NN', 'NN'], ['you', 'are', 'a', 'simpleton', 'loon']), (['there', 'is', 'something', 'of', 'all', 'way'], -3.175832748413086, ['EX', 'VBZ', 'NN', 'IN', 'DT', 'NN'], ['there', 'was', 'nothing', 'like', 'a', 'food']), (['when', 'the', 'word', 'reminds', 'her', 'way'], -4.118831952412923, ['WHEN', 'DT', 'NN', 'VBZ', 'PRP$', 'NN'], ['when', 'a', 'girl', 'wears', 'my', 'coat']), (['i', 'hesitated', 'all', 'way'], -4.159818649291992, ['PRP', 'VBD', 'DT', 'NN'], ['he', 'indulged', 'a', 'desire']), (['were', 'the', 'thousand', 'to', 'all', 'way'], -4.879453976949056, ['VBD', 'DT', 'CD', 'TO', 'DT', 'NN'], ['said', 'the', 'two', 'to', 'the', 'tutor'])]\n",
      "['CC', 'VB', 'RB', 'AS', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WP', 'DT', 'JJ', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IN', 'DT', 'NN', 'CC', 'VBD', 'IN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['SO', 'JJ', 'VBD', 'PRP$', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "[(['of', 'any', 'life', 'or', 'thought', 'play'], -3.58531920115153, ['IN', 'DT', 'NN', 'CC', 'VBD', 'IN'], ['with', 'a', 'yell', 'and', 'eloped', 'with']), (['and', 'come', 'together', 'as', 'play'], -3.7545085906982423, ['CC', 'VB', 'RB', 'AS', 'NN'], ['and', 'eat', 'just', 'as', 'hearty']), (['so', 'beautiful', 'was', 'mine', 'play'], -4.403765106201172, ['SO', 'JJ', 'VBD', 'PRP$', 'NN'], ['so', 'short', 'was', 'his', 'fin']), (['addition', 'another', 'play'], -6.840391159057617, ['IN', 'DT', 'NN'], ['without', 'any', 'nightie'])]\n",
      "['AS', 'IF', 'PRP', 'MD', 'VBN', 'JJ']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['CC', 'VBD', 'DT', 'JJ']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['VB', 'IN', 'JJ', 'VB', 'JJ', 'JJ']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['DT', 'JJ', 'NN']\n",
      "['IN', 'PRP', 'MD', 'RB', 'VB', 'RP']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "[(['if', 'i', 'can', 'instantaneously', 'look', 'same'], -4.455282847086589, ['IN', 'PRP', 'MD', 'RB', 'VB', 'RP'], ['that', 'he', 'could', \"n't\", 'reach', 'up']), (['as', 'if', 'himself', 'would', 'accumulated', 'same'], -5.268693606058757, ['AS', 'IF', 'PRP', 'MD', 'VBN', 'JJ'], ['as', 'if', 'he', \"'d\", 'been', 'invited']), (['think', 'of', 'such', 'incomprehensible', 'kind', 'same'], -5.338955561319987, ['VB', 'IN', 'JJ', 'VB', 'JJ', 'JJ'], ['be', 'before', 'phoebe', 'be', 'phoebe', 'bee-bee']), (['and', 'deteriorated', 'another', 'same'], -6.283439636230469, ['CC', 'VBD', 'DT', 'JJ'], ['and', 'shocked', 'the', 'ultra-fastidious'])]\n",
      "************\n",
      "there once was a young woman whose name was mame\n",
      "who came to the conservatory out game\n",
      "i have no expression way\n",
      "of any life or thought play\n",
      "if i can instantaneously look same\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[['there',\n",
       "   'once',\n",
       "   'was',\n",
       "   'a',\n",
       "   'young',\n",
       "   'woman',\n",
       "   'whose',\n",
       "   'name',\n",
       "   'was',\n",
       "   'mame']],\n",
       " (['who', 'came', 'to', 'the', 'conservatory', 'out', 'game'],\n",
       "  -4.073335102626255,\n",
       "  ['WHO', 'VBD', 'IN', 'DT', 'NN', 'IN', 'NNS'],\n",
       "  ['who', 'slipped', 'on', 'a', 'peel', 'of', 'bananas']),\n",
       " (['i', 'have', 'no', 'expression', 'way'],\n",
       "  -2.75305118560791,\n",
       "  ['PRP', 'VBP', 'DT', 'NN', 'NN'],\n",
       "  ['you', 'are', 'a', 'simpleton', 'loon']),\n",
       " (['of', 'any', 'life', 'or', 'thought', 'play'],\n",
       "  -3.58531920115153,\n",
       "  ['IN', 'DT', 'NN', 'CC', 'VBD', 'IN'],\n",
       "  ['with', 'a', 'yell', 'and', 'eloped', 'with']),\n",
       " (['if', 'i', 'can', 'instantaneously', 'look', 'same'],\n",
       "  -4.455282847086589,\n",
       "  ['IN', 'PRP', 'MD', 'RB', 'VB', 'RP'],\n",
       "  ['that', 'he', 'could', \"n't\", 'reach', 'up'])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.gen_poem_independent_matias('game', 11)\n",
    "lg.gen_poem_independent_matias('game', 11, storyline=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('diem', 'dream', 'kind', 'mind', 'beam')\n",
      "('scream', 'dream', 'pope', 'hope', 'theme')\n"
     ]
    }
   ],
   "source": [
    "print(lg.get_five_words('dream'))\n",
    "print(lg.get_five_words_henry('dream'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('remake', 'cake', 'staked', 'baked', 'awake')\n",
      "('flake', 'cake', 'raked', 'baked', 'steak')\n"
     ]
    }
   ],
   "source": [
    "print(lg.get_five_words('cake'))\n",
    "print(lg.get_five_words_henry('cake'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('smite', 'night', 'stark', 'dark', 'light')\n",
      "('wight', 'night', 'overnight', 'midnight', 'light')\n"
     ]
    }
   ],
   "source": [
    "print(lg.get_five_words('night'))\n",
    "print(lg.get_five_words_henry('night'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('meadow', 'snow', 'they', 'away', 'go')\n",
      "('potato', 'snow', 'rice', 'ice', 'below')\n"
     ]
    }
   ],
   "source": [
    "print(lg.get_five_words('snow'))\n",
    "print(lg.get_five_words_henry('snow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sabine', 'machine', 'return', 'turn', 'mean')\n",
      "('demean', 'machine', 'scenery', 'machinery', 'screen')\n"
     ]
    }
   ],
   "source": [
    "print(lg.get_five_words('machine'))\n",
    "print(lg.get_five_words_henry('machine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('severe', 'tear', 'start', 'apart', 'bear')\n",
      "('beer', 'tear', 'start', 'apart', 'there')\n"
     ]
    }
   ],
   "source": [
    "print(lg.get_five_words('tear'))\n",
    "print(lg.get_five_words_henry('tear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('marguerite', 'street', 'unlike', 'like', 'beat')\n",
      "('heartbeat', 'street', 'blocks', 'sidewalks', 'concrete')\n"
     ]
    }
   ],
   "source": [
    "print(lg.get_five_words('street'))\n",
    "print(lg.get_five_words_henry('street'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "********************************************\n",
    "--------------------------------------------\n",
    "********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "five words are: \n",
      "('doth', 'broth', 'scoop', 'soup', 'moth')\n",
      "['WHO', 'VBD', 'RP', 'PRP$', 'NNS', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'JJ', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'DT', 'JJ', 'NN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'AS', 'PRP', 'VBD', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WP$', 'NN', 'VBD', 'RB', 'JJR', 'THAN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "No templates for POS\n",
      "five words are: \n",
      "('transformation', 'probation', 'lenders', 'offenders', 'communication')\n",
      "['WHO', 'VBD', 'AS', 'PRP', 'VBD', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'PRP', 'RB', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'IN', 'JJ', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'DT', 'JJ', 'NN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WP$', 'NN', 'VBD', 'DT', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['IN', 'PRP$', 'NN', ',', 'PRP$', 'NNS']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'VBD', ',', 'RB', 'VBD']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['IN', 'PRP$', 'NNS', 'IN', 'DT', 'NNS']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['RB', 'VBD', 'IN', 'DT', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['VBG', 'DT', 'NNS', 'CC', 'NNS']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['JJ', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['CC', 'VBD', 'NNS', 'IN', 'NNS']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['IN', 'DT', 'NN', 'VBZ', 'VBN', 'RP', 'PRP$', 'NN']\n",
      "five words are: \n",
      "('athwart', 'passport', 'resistance', 'assistance', 'support')\n",
      "['WHO', 'VBD', 'DT', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'IN', 'CD', 'IN', 'PRP$', 'NNS']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'JJ', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'IN', 'JJ', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WP$', 'NN', 'VBD', 'DT', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['CC', 'IN', 'PRP$', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['DT', 'NN', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'VBD', 'RP', 'CD', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['VBD', 'DT', 'NN', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'VBD', ',', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['IN', 'PRP$', 'NN', 'CC', 'NN', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['IN', 'PRP$', 'NNS', 'CC', 'PRP$', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP$', 'NN', 'POS', 'JJ', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "five words are: \n",
      "('remake', 'stake', 'asleep', 'sleep', 'awake')\n",
      "['WHO', 'VBD', 'IN', 'DT', 'NN', 'IN', 'NNS']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WP$', 'NN', 'VBD', 'RB', 'JJR', 'THAN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'IN', 'CD', 'IN', 'PRP$', 'NNS']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'IN', 'JJ', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WP$', 'NN', 'VBD', 'DT', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "No templates for POS\n",
      "five words are: \n",
      "('heald', 'yield', 'devil', 'level', 'field')\n",
      "['WP$', 'NNS', 'RB', 'MD', 'VB']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['DT', 'NN', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['IN', 'JJ', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'VBD', ',', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'VBD', 'RB', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['VBD', 'PRP', 'IN', ',', 'WP', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['CC', 'AS', 'RB', 'AS', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['VB', 'RP', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['VBD', 'CD', 'NNS', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['IN', 'JJ', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['DT', 'CD', 'VBD', 'PDT', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WDT', 'VBZ', 'PRP', 'IN', 'RB', 'JJ', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['DT', 'VBN', 'TO', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "[]\n",
      "five words are: \n",
      "('hale', 'flail', 'amplitude', 'magnitude', 'scale')\n",
      "five words are: \n",
      "('secession', 'transgression', 'latter', 'matter', 'question')\n",
      "['WHO', 'VBD', 'IN', 'JJ', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'IN', 'DT', 'NN', 'IN', 'NNS']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'AS', 'PRP', 'VBD', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WHO', 'VBD', 'DT', 'PRP$', 'NN', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'JJ', 'NN', 'IN', 'NN']\n",
      "['PRP', 'VBZ', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['DT', 'NN', 'VBD', ',', 'RB', 'JJ']\n",
      "['CC', 'JJ', ',', 'CC', 'JJ']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP$', 'NNS', 'VBD', 'SO', 'JJ']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['CC', 'DT', 'CD', 'VBD', 'JJ']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['VBP', 'VBG', 'DT', 'NN', 'IN', 'PRP$', 'NN']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "statement=True\n",
    "word=random.choice(lg.pos_to_words['NN'])\n",
    "while statement:\n",
    "    try:\n",
    "        poem=lg.gen_poem_conditioned(word, 11)\n",
    "        statement=False\n",
    "    except:\n",
    "        word=random.choice(lg.pos_to_words['NN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gen_poem_conditioned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 2nd, 3rd and 5th lines independently, then generate 1st conditioned on second and 4th conditioned on 5th."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\anaconda2\\envs\\translator\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "five words are: \n",
      "('alternate', 'mate', 'dream', 'team', 'state')\n",
      "['WHO', 'VBD', 'PRP', 'RB', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'VBD', ',', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['VBP', 'VBG', 'DT', 'NN', 'IN', 'PRP$', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['IN', 'DT', 'JJ', 'NN', 'NN', 'VBP']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['CD', 'NNS', 'CC', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "************\n",
      "of the whole thing everything alternate\n",
      "who fascinated me now as a mate\n",
      "i continued , with a dream\n",
      "undertone eyes and the team\n",
      "cant sing the fascination of her state\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poem=lg.gen_poem_conditioned('mate', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\anaconda2\\envs\\translator\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "five words are: \n",
      "('bonfire', 'fire', 'kettle', 'metal', 'wire')\n",
      "['WHO', 'VBD', 'RP', 'PRP$', 'NNS', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'AS', 'PRP', 'VBD', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'PRP', 'RB', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'IN', 'JJ', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'DT', 'JJ', 'NN', 'IN', 'PRP$', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['THAN', 'DT', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['CC', 'IN', 'PRP$', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'VBP', 'DT', 'NN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['VBD', 'DT', 'CD', 'TO', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'VBD', 'IN', 'DT', 'NN']\n"
     ]
    }
   ],
   "source": [
    "poem2=lg.gen_poem_conditioned('fire', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['been', 'one', 'perturbations', 'of', 'his', 'liar'],\n",
       "  -6.998078028361003,\n",
       "  ['VBN', 'CD', 'NNS', 'IN', 'PRP$', 'NN']),\n",
       " (['who', 'initiated', 'at', 'last', 'fire'],\n",
       "  -5.47464599609375,\n",
       "  ['WHO', 'VBD', 'IN', 'JJ', 'NN']),\n",
       " (['in', 'his', 'tremulous', 'kettle'],\n",
       "  -3.5174553394317627,\n",
       "  ['IN', 'PRP$', 'JJ', 'NN']),\n",
       " (['of', 'my', 'eyes', 'and', 'his', 'metal'],\n",
       "  -5.591676712036133,\n",
       "  ['IN', 'PRP$', 'NNS', 'CC', 'PRP$', 'NN']),\n",
       " (['of', 'my', 'body', 'and', 'look', 'at', 'some', 'wire'],\n",
       "  -3.539680242538452,\n",
       "  ['IN', 'PRP$', 'NN', 'CC', 'NN', 'IN', 'DT', 'NN'])]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\anaconda2\\envs\\translator\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "five words are: \n",
      "('outright', 'height', 'indicate', 'weight', 'light')\n",
      "['WHO', 'VBD', 'DT', 'JJ', 'NN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'VBD', 'CD', 'TO', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['IN', 'PRP$', 'NN', 'CC', 'NN', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['NN', 'IN', 'PRP', 'MD']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['IN', 'PRP$', 'NNS', 'CC', 'PRP$', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "************\n",
      "individuality as we outright\n",
      "who initiated the light round each height\n",
      "i was favour to indicate\n",
      "in my eyes behemoth your weight\n",
      "of my philosophy and look in some light\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poem3=lg.gen_poem_conditioned('height', 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WHO', 'IN', 'NNS', 'VBD', 'JJ', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'IN', 'CD', 'IN', 'PRP$', 'NNS']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'DT', 'JJ', 'NN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'RP', 'PRP$', 'NNS', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'DT', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'PRP', 'RB', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'IN', 'JJ', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WP$', 'NN', 'VBD', 'DT', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n"
     ]
    }
   ],
   "source": [
    "from py_files.templates import get_templates\n",
    "dataset, second_line, third_line, last_two=get_templates()\n",
    "p=lg.gen_best_line('sky', set_of_templates=second_line, rand_templates=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['who', 'was', 'a', 'solitary', 'round', 'the', 'sky'],\n",
       "  -3.8050354548863004,\n",
       "  ['WHO', 'VBD', 'DT', 'JJ', 'NN', 'DT', 'NN'],\n",
       "  ['who', 'read', 'a', 'love', 'story', 'each', 'day']),\n",
       " (['who', 'fascinated', 'me', 'there', 'in', 'the', 'sky'],\n",
       "  -3.8535614013671875,\n",
       "  ['WHO', 'VBD', 'PRP', 'RB', 'IN', 'DT', 'NN'],\n",
       "  ['who', 'found', 'himself', 'quite', 'at', 'a', 'loss']),\n",
       " (['who', 'repeated', 'on', 'my', 'feet', 'in', 'the', 'sky'],\n",
       "  -4.04962682723999,\n",
       "  ['WHO', 'VBD', 'RP', 'PRP$', 'NNS', 'IN', 'DT', 'NN'],\n",
       "  ['who', 'sent', 'out', 'his', 'cards', 'for', 'a', 'party']),\n",
       " (['whose', 'life', 'was', 'the', 'reality', 'on', 'sky'],\n",
       "  -4.351373400006976,\n",
       "  ['WP$', 'NN', 'VBD', 'DT', 'NN', 'IN', 'NN'],\n",
       "  ['whose', 'pa', 'made', 'a', 'fortune', 'in', 'pork']),\n",
       " (['who', 'hesitated', 'in', 'one', 'of', 'my', 'sky'],\n",
       "  -4.458645139421735,\n",
       "  ['WHO', 'VBD', 'IN', 'CD', 'IN', 'PRP$', 'NNS'],\n",
       "  ['who', 'married', 'on', 'one', 'of', 'his', 'trips']),\n",
       " (['who', 'investigated', 'the', 'way', 'on', 'sky'],\n",
       "  -5.081632296244304,\n",
       "  ['WHO', 'VBD', 'DT', 'NN', 'IN', 'NN'],\n",
       "  ['who', 'hadnt', 'an', 'atom', 'of', 'fear']),\n",
       " (['who', 'at', 'years', 'deserted', 'last', 'night', 'on', 'sky'],\n",
       "  -5.279506206512451,\n",
       "  ['WHO', 'IN', 'NNS', 'VBD', 'JJ', 'NN', 'IN', 'NN'],\n",
       "  ['who', 'on', 'apples', 'was', 'quite', 'fond', 'of', 'feedin']),\n",
       " (['who', 'deteriorated', 'in', 'large', 'sky'],\n",
       "  -5.725870132446289,\n",
       "  ['WHO', 'VBD', 'IN', 'JJ', 'NN'],\n",
       "  ['who', 'lived', 'on', 'distilled', 'kerosene'])]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VBD', 'DT', 'NN', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['VBD', 'DT', 'CD', 'TO', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['MD', 'RB', 'VB', 'RP', 'TO', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'MD', 'VB', 'TO', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'VBD', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n"
     ]
    }
   ],
   "source": [
    "p=lg.gen_best_line('height', set_of_templates=third_line, rand_templates=5, num_sylls=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['i', 'hesitated', 'with', 'some', 'height'],\n",
       "  -3.943877410888672,\n",
       "  ['PRP', 'VBD', 'IN', 'DT', 'NN'],\n",
       "  ['it', 'said', 'on', 'the', 'door']),\n",
       " (['was', 'no', 'one', 'to', 'every', 'height'],\n",
       "  -4.294746081034343,\n",
       "  ['VBD', 'DT', 'CD', 'TO', 'DT', 'NN'],\n",
       "  ['said', 'the', 'two', 'to', 'the', 'tutor']),\n",
       " (['will', 'probably', 'come', 'back', 'to', 'height'],\n",
       "  -4.311198552449544,\n",
       "  ['MD', 'RB', 'VB', 'RP', 'TO', 'NN'],\n",
       "  [\"'did\", 'not', 'rush', 'off', 'to', 'town']),\n",
       " (['ourselves', 'will', 'come', 'to', 'each', 'height'],\n",
       "  -4.62187131245931,\n",
       "  ['PRP', 'MD', 'VB', 'TO', 'DT', 'NN'],\n",
       "  ['he', 'would', 'go', 'to', 'a', 'party'])]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gen Poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\anaconda2\\envs\\translator\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WHO', 'VBD', 'IN', 'DT', 'NN', 'IN', 'NNS']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WP$', 'NN', 'VBD', 'RB', 'JJR', 'THAN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'AS', 'PRP', 'VBD', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'RP', 'PRP$', 'NNS', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'DT', 'PRP$', 'NN', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "[(['who', 'came', 'to', 'the', 'elevator', 'out', 'height'], -3.9964888436453685, ['WHO', 'VBD', 'IN', 'DT', 'NN', 'IN', 'NNS'], ['who', 'slipped', 'on', 'a', 'peel', 'of', 'bananas']), (['who', 'came', 'on', 'my', 'hands', 'in', 'every', 'height'], -4.1248602867126465, ['WHO', 'VBD', 'RP', 'PRP$', 'NNS', 'IN', 'DT', 'NN'], ['who', 'sent', 'out', 'his', 'cards', 'for', 'a', 'party']), (['who', 'were', 'as', 'ourselves', 'seemed', 'to', 'some', 'height'], -4.955960750579834, ['WHO', 'VBD', 'AS', 'PRP', 'VBD', 'IN', 'DT', 'NN'], ['who', 'smiled', 'as', 'she', 'rode', 'on', 'a', 'tiger']), (['whose', 'life', 'was', 'absolutely', 'less', 'than', 'height'], -5.163310459681919, ['WP$', 'NN', 'VBD', 'RB', 'JJR', 'THAN', 'NN'], ['whose', 'speed', 'was', 'much', 'faster', 'than', 'light']), (['who', 'had', 'all', 'my', 'love', 'addition', 'some', 'height'], -5.454594135284424, ['WHO', 'VBD', 'DT', 'PRP$', 'NN', 'IN', 'DT', 'NN'], ['who', 'kept', 'all', 'his', 'cash', 'in', 'a', 'bucket'])]\n",
      "['VBD', 'DT', 'NN', ',', 'VB', 'PRP', 'VB']\n",
      "['VBD', 'DT', 'NN', ',', 'VB', 'RB', 'VB']\n",
      "['PRP', 'VBD', 'CD', 'TO', 'NN']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No lines can be constructed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-287535113fb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpoem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_poem_independent_matias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'height'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Poetix18\\py_files\\Limericks.py\u001b[0m in \u001b[0;36mgen_poem_independent_matias\u001b[1;34m(self, seed_word, first_line_sylls, rand_template)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m                 \u001b[0mthis_line_sylls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthird_line_sylls\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_best_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_sylls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthis_line_sylls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_of_templates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthird_line_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_best_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_sylls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthird_line_sylls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfourth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Poetix18\\py_files\\Limericks.py\u001b[0m in \u001b[0;36mgen_best_line\u001b[1;34m(self, w1, pos, templates, set_of_templates, rand_templates, num_sylls, state, score, return_state)\u001b[0m\n\u001b[0;32m    458\u001b[0m         \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No lines can be constructed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No lines can be constructed"
     ]
    }
   ],
   "source": [
    "poem=lg.gen_poem_independent_matias('height', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['who', 'saw', 'it', 'curiously', 'in', 'the', 'sky'],\n",
       "  -4.016473225184849,\n",
       "  ['WHO', 'VBD', 'PRP', 'RB', 'IN', 'DT', 'NN'],\n",
       "  ['who', 'found', 'himself', 'quite', 'at', 'a', 'loss']),\n",
       " (['i', 'believe', 'the', 'mine', 'birth'],\n",
       "  -3.178923797607422,\n",
       "  ['PRP', 'VBP', 'DT', 'NN', 'NN'],\n",
       "  ['you', 'are', 'a', 'simpleton', 'loon']),\n",
       " (['it', 'was', 'so', 'little', 'earth'],\n",
       "  -3.326568603515625,\n",
       "  ['PRP', 'VBD', 'SO', 'JJ', 'NN'],\n",
       "  ['she', 'ate', 'so', 'much', 'spice']),\n",
       " (['it', 'is', 'any', 'words', 'of', 'love', 'for', 'me', 'lie'],\n",
       "  -3.3755276997884116,\n",
       "  ['PRP', 'VBZ', 'DT', 'NNS', 'IN', 'NN', 'IN', 'PRP', 'VBP'],\n",
       "  ['it', \"'s\", 'the', 'people', 'in', 'front', 'that', 'I', 'jar'])]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\anaconda2\\envs\\translator\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "five words are: \n",
      "('goodbye', 'sky', 'birth', 'earth', 'lie')\n",
      "['WHO', 'VBD', 'AS', 'PRP', 'VBD', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'RP', 'PRP$', 'NNS', 'IN', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'IN', 'CD', 'IN', 'PRP$', 'NNS']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'DT', 'JJ', 'NN', 'IN', 'PRP$', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['WHO', 'VBD', 'IN', 'JJ', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['VBD', 'DT', 'NN', ',', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'VBD', 'RP', 'CD', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PDT', 'DT', 'NNS', 'VBD', 'IN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['VBN', 'TO', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['THAN', 'DT', 'NN', 'IN', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'VBZ', 'DT', 'NNS', 'IN', 'NN', 'IN', 'PRP', 'VBP']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['PRP', 'VBD', 'SO', 'JJ', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['IN', 'DT', 'JJ', 'NN', 'PRP', 'VBP']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n",
      "['IF', 'PRP', 'VBD', 'RB', 'VB', 'DT', 'NN']\n",
      "INFO:tensorflow:Restoring parameters from py_files/models/all_combined_back\\model.ckpt-120000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "no lines can be constructed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-69b31b4e077e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpoem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_poem_conditioned\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sky'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Poetix18\\py_files\\Limericks.py\u001b[0m in \u001b[0;36mgen_poem_conditioned\u001b[1;34m(self, seed_word, second_line_sylls, rand_template)\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[0mlast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no lines can be constructed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m         \u001b[0mline4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlast\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[0mscore4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlast\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: no lines can be constructed"
     ]
    }
   ],
   "source": [
    "poem=lg.gen_poem_conditioned('sky',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns = {\n",
    "            'he': 'she',\n",
    "            'him':'her',\n",
    "            'his': 'hers'\n",
    "            }\n",
    "inv_pronouns = {v: k for k, v in pronouns.items()}\n",
    "\n",
    "def postprocess_gender_continuity(poem):\n",
    "    found_pronoun = False\n",
    "    male_pronouns = set(pronouns.keys())\n",
    "    female_pronouns = set(inv_pronouns.keys())\n",
    "    for line in poem:\n",
    "        for i, word in enumerate(line):\n",
    "            if not found_pronoun:\n",
    "                if word in male_pronouns:\n",
    "                    found_pronoun = True\n",
    "                    is_female = False\n",
    "                if word in female_pronouns:\n",
    "                    found_pronoun = True\n",
    "                    is_female = True\n",
    "            else:\n",
    "                if is_female and word in male_pronouns:\n",
    "                    line[i] = pronouns[word]\n",
    "                if is_male and word in female_pronouns:\n",
    "                    line[i] = inv_pronouns[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
