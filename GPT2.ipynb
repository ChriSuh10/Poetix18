{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from py_files.Limericks import Limerick_Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "lg = Limerick_Generate(model_name='345M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.valid_permutation_sylls(6,['IN', 'DT', 'JJ', 'NN'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Enthusiastic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a8327b2854b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict_meters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Enthusiastic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'Enthusiastic'"
     ]
    }
   ],
   "source": [
    "lg.dict_meters['Enthusiastic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the entire poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "gen_poem_gpt() got an unexpected keyword argument 'num_sylls'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3c545ef0ea3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                           \u001b[0;34m[\u001b[0m\u001b[0;34m'IN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'JJ'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                           \u001b[0;34m[\u001b[0m\u001b[0;34m'CC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VBD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'IN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'JJ'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                          ], num_sylls = 9)\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: gen_poem_gpt() got an unexpected keyword argument 'num_sylls'"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"plane\", \"wind\", \n",
    "                        prompt_length=50, search_space=100,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'RP', 'CD', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ], num_sylls = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'once', 'was', 'an', 'enthusiastic', 'woman', 'named', 'germaine']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "['who', 'laid', 'eggs', 'on', 'a', 'grain']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "['i', 'came', 'up', 'one', 'mind']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "['in', 'a', 'un', 'kind']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "['and', 'lay', 'in', 'a', 'u', 'vein']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"plane\", \"wind\", \n",
    "                       first_line_sylls=14, prompt_length=50, search_space=150,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'RP', 'CD', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'once', 'was', 'a', 'woman', 'enjoying', 'her', 'life', 'in', 'lamar']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "['who', 'had', 'men', 'in', 'a', 'car']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "['i', 'took', 'up', 'one', 'tune']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "['of', 'a', 'new', 'moon']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\gwern\\model-519407\n",
      "['and', 'was', 'in', 'a', 'th', 'bar']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"star\", \"moon\", \n",
    "                       first_line_sylls=14, prompt_length=50, search_space=150,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'RP', 'CD', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'was', 'an', 'enthusiastic', 'man', 'that', 'lived', 'in', 'dakar']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['who', 'saw', 'things', 'from', 'another', 'star']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['i', 'found', 'out', 'one', 'afternoon']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['that', 'the', 'dark', 'moon']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['and', 'lost', 'in', 'the', 'dark', 'scar']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"star\", \"moon\", \n",
    "                       first_line_sylls=14, prompt_length=50, search_space=150,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'RP', 'CD', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'RP', 'CD', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ]\n",
    "rhyme1 = \"plane\"\n",
    "rhyme2 = \"wind\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\score.py:55: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['who', 'raised', 'funds', 'for', 'the', 'campaign']\n"
     ]
    }
   ],
   "source": [
    "# Generate second sentence\n",
    "f = open('gpt2.pkl', 'rb')\n",
    "prompt = pickle.load(f)\n",
    "new_sentence = lg.gen_line_gpt(w=None, encodes=prompt, default_template = default_templates[0], rhyme=rhyme1, search_space=75)\n",
    "prompt += new_sentence[1]\n",
    "print(new_sentence[0])\n",
    "f = open('gpt2.pkl', 'wb')\n",
    "pickle.dump(prompt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\score.py:55: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['she', 'set', 'up', 'one', 'mind']\n"
     ]
    }
   ],
   "source": [
    "# Generate third sentence\n",
    "f = open('gpt2.pkl', 'rb')\n",
    "prompt = pickle.load(f)\n",
    "new_sentence = lg.gen_line_gpt(w=None, encodes=prompt, default_template = default_templates[1], rhyme=rhyme2, search_space=60)\n",
    "prompt += new_sentence[1]\n",
    "print(new_sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\score.py:55: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['for', 'a', 'new', 'kind']\n"
     ]
    }
   ],
   "source": [
    "# Generate fourth sentence\n",
    "f = open('gpt2.pkl', 'rb')\n",
    "prompt = pickle.load(f)\n",
    "new_sentence = lg.gen_line_gpt(w=None, encodes=prompt, default_template = default_templates[2], rhyme=rhyme2, search_space=30)\n",
    "prompt += new_sentence[1]\n",
    "print(new_sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\score.py:55: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['and', 'moved', 'for', 'a', 'new', 'campaign']\n"
     ]
    }
   ],
   "source": [
    "# Generate fifth sentence\n",
    "f = open('gpt2.pkl', 'rb')\n",
    "prompt = pickle.load(f)\n",
    "new_sentence = lg.gen_line_gpt(w=None, encodes=prompt, default_template = default_templates[3], rhyme=rhyme1, search_space=10)\n",
    "prompt += new_sentence[1]\n",
    "print(new_sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'once', 'was', 'an', 'enthusiastic', 'woman', 'named', 'romaine']\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\sample.py:51: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\sample.py:53: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['who', 'told', 'stories', 'about', 'the', 'pain']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['she', 'felt', 'off', 'one', 'kind']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['of', 'a', 'high', 'wind']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['and', 'fell', 'off', 'a', 'high', 'plane']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"plane\", \"wind\", \n",
    "                       first_line_sylls=14, prompt_length=100, search_space=15,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'RP', 'CD', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'once', 'was', 'an', 'enthusiastic', 'man', 'named', 'roan']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['who', 'had', 'aspirations', 'of', 'a', 'loan']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['it', 'was', 'a', 'glue']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-6cdba9db1f54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                                           \u001b[1;33m[\u001b[0m\u001b[1;34m'PRP'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VBD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                           \u001b[1;33m[\u001b[0m\u001b[1;34m'IN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'JJ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                                           \u001b[1;33m[\u001b[0m\u001b[1;34m'CC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'VBD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'IN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'JJ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                                          ])\n",
      "\u001b[1;32mE:\\poetix\\py_files\\Limericks.py\u001b[0m in \u001b[0;36mgen_poem_gpt\u001b[1;34m(self, rhyme1, rhyme2, default_templates, first_line_sylls, story_line, prompt_length, save_as_pickle, search_space)\u001b[0m\n\u001b[0;32m    942\u001b[0m             \u001b[0mprompt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnew_sentence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 944\u001b[1;33m             \u001b[0mnew_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_line_gpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_template\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_templates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhyme_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfive_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    945\u001b[0m             \u001b[0mprompt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnew_sentence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\poetix\\py_files\\Limericks.py\u001b[0m in \u001b[0;36mgen_line_gpt\u001b[1;34m(self, w, encodes, default_template, rhyme_word, rhyme_set, search_space)\u001b[0m\n\u001b[0;32m    848\u001b[0m             \u001b[1;31m# Get the most probable N sentences by sorting the list according to probability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m             \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheapq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnsmallest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_sentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 850\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    851\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"joan\", \"\",\n",
    "                       first_line_sylls=12, prompt_length=75, search_space=150, story_line=True,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'DT', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'once', 'was', 'an', 'enthusiastic', 'man', 'named', 'case']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['who', 'did', 'wonders', 'for', 'the', 'birthplace']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['i', 'got', 'a', 'report']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['from', 'a', 'local', 'court']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['and', 'asked', 'for', 'a', 'special', 'grace']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"grace\",\n",
    "                       first_line_sylls=12, prompt_length=100, search_space=100, story_line=True,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'DT', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the sentence with highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['he', 'ordered', 'a', 'porterhouse', 'steak,', 'sauerkraut,', 'mince', 'pie', 'and', 'fruit', 'cake.', 'then', 'sat', 'down', 'to', 'dine,', 'drank', 'three', 'kinds', 'of', 'wine,', 'and', 'got', 'into', 'a', 'heated', 'argument']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"He ordered a porterhouse steak, sauerkraut, mince pie and fruit cake. Then sat down to dine, drank three kinds of wine,\", ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN'], False, 10)\n",
    "print(poem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['he', 'ordered', 'a', 'porterhouse', 'steak,', 'sauerkraut,', 'mince', 'pie', 'and', 'fruit', 'cake.', 'then', 'sat', 'down', 'to', 'dine,', 'drank', 'three', 'kinds', 'of', 'wine,', 'and', 'got', 'into', 'a', 'heated', 'argument']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"He ordered a porterhouse steak, sauerkraut, mince pie and fruit cake. Then sat down to dine, drank three kinds of wine,\", ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN'], False, 100)\n",
    "print(poem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "(['there', 'was', 'a', 'young', 'woman', 'named', 'kite,', 'whose', 'speed', 'was', 'much', 'faster', 'than', 'light,', 'she', 'set', 'out', 'one', 'day,', 'in', 'a', 'relative', 'way,', 'and', 'come', 'from', 'the', 'other', 'world'], [8117, 9776, 64, 35465, 8580, 13190, 74, 38159, 12287, 9776, 29482, 69, 14813, 2971, 7091, 2617, 448, 505, 820, 259, 64, 43762, 1014, 392, 2958, 6738, 1169, 847, 6894], -19.603738605976105)\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"There was a young woman named Kite, whose speed was much faster than light, she set out one day, in a relative way,\", \n",
    "                ['CC', 'VBN', 'IN', 'DT', 'JJ', 'NN'], False, 10)\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['a', 'man', 'and', 'his', 'lady-love,', 'min,', 'skated', 'out', 'where', 'the', 'ice', 'was', 'quite', 'thin,', 'had', 'a', 'quarrel,', 'no', 'doubt,', 'for', 'i', 'hear', 'they', 'fell', 'out', 'what', 'the', 'hell', 'he', 'going']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"A man and his lady-love, Min, Skated out where the ice was quite thin, Had a quarrel, no doubt, For I hear they fell out\", \n",
    "                ['WP', 'DT', 'NN', 'PRP', 'VBG'] ,False, 10)\n",
    "print(poem[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhyme Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['why', 'do', 'we', 'have', 'homework', 'after', 'school?', 'this', 'is', 'so', 'uncool.', 'i', 'so', 'want', 'to', 'cry.', 'you', 'need', 'to', 'do', 'this', 'in', 'the', 'middle', 'of', 'school']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"Why do we have homework after school? This is so uncool. I so want to cry.\", \n",
    "               ['PRP', 'VBP', 'TO', 'VB', 'DT', 'IN', 'DT', 'NN', 'IN', 'NN'], 'school', 100)\n",
    "print(poem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['he', 'ordered', 'a', 'porterhouse', 'steak,', 'sauerkraut,', 'mince', 'pie', 'and', 'fruit', 'cake.', 'then', 'sat', 'down', 'to', 'dine,', 'drank', 'three', 'kinds', 'of', 'wine,', 'and', 'got', 'into', 'a', 'little', 'break']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"He ordered a porterhouse steak, sauerkraut, mince pie and fruit cake. Then sat down to dine, drank three kinds of wine,\", ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN'], 'cake', 10)\n",
    "print(poem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "['there', 'was', 'a', 'young', 'woman', 'named', 'kite,', 'whose', 'speed', 'was', 'much', 'faster', 'than', 'light,', 'she', 'set', 'out', 'one', 'day,', 'in', 'a', 'relative', 'way,', 'and', 'come', 'from', 'the', 'first', 'night']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"There was a young woman named Kite, whose speed was much faster than light, she set out one day, in a relative way,\", \n",
    "                ['CC', 'VBN', 'IN', 'DT', 'JJ', 'NN'], 'light', 10)\n",
    "print(poem[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Approach (generate only one setentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "[' and', ' smoked', ' in', ' the', ' same', ' room']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"He ordered a porterhouse steak, sauerkraut, mince pie and fruit cake. Then sat down to dine, drank three kinds of wine,\", \n",
    "                (['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN'], \n",
    "                 ['and', 'retired', 'with', 'a', 'bad', 'stomachache']),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "[' and', ' sat', ' near', ' the', ' main', ' kitchen']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"He ordered a porterhouse steak, sauerkraut, mince pie and fruit cake. Then sat down to dine, drank three kinds of wine,\", \n",
    "                (['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN'], \n",
    "                 ['and', 'retired', 'with', 'a', 'bad', 'stomachache']),)\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "[' Who', ' all', ' fall', ' he', ' heard', ' in']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"A man and his lady-love, Min, Skated out where the ice was quite thin, Had a quarrel, no doubt, For I hear they fell out\", \n",
    "                (['WP', 'DT', 'NN', 'PRP', 'VBP', 'IN'], ['what', 'a', 'blessing', 'they', 'didnt', 'fall', 'in']) ,rhyme=\"thin\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\poetix\\gpt2\\src\\score.py:54: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "[' and', ' found', ' that', ' the', ' young', 'Knight']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"There was a young woman named Kite, whose speed was much faster than light, she set out one day, in a relative way,\", \n",
    "               (['CC', 'VBN', 'IN', 'DT', 'JJ', 'NN'], \n",
    "                ['and', 'returned', 'on', 'the', 'previous', 'night']),rhyme=\"light\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "[' but', ' found', ' at', ' all', ' horrible', ' plight']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"There was a young woman named Kite, whose speed was much faster than light, she set out one day, in a relative way,\", \n",
    "               (['CC', 'VBN', 'IN', 'DT', 'JJ', 'NN'], \n",
    "                ['and', 'returned', 'on', 'the', 'previous', 'night']),rhyme=\"light\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "[' and', ' stayed', ' with', ' the', ' other', ' night']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"There was a young woman named Kite, whose speed was much faster than light, she set out one day, in a relative way,\", \n",
    "               (['CC', 'VBN', 'IN', 'DT', 'JJ', 'NN'], \n",
    "                ['and', 'returned', 'on', 'the', 'previous', 'night']),rhyme=\"light\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Template Constraint\n",
    "There was a young lady named Perkins, Who just simply doted on gherkins. In spite of advice, she ate so much spice, which favour the youngsters, and greatly mortified the obstinate young girl, who turned out to be a pauper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models\\117M\\model.ckpt\n",
      "[' and', ' the', ' lady', ' from', ' the', ' festival', ' of', ' the', ' Tiger']\n"
     ]
    }
   ],
   "source": [
    "poem = lg.gen_line_gpt(\"There was a young lady from Niger, Who smiled as she rode on a tiger. They came back from the ride with the lady inside,\", \n",
    "               (['CC', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN'], \n",
    "                ['and', 'the', 'smile', 'on', 'the', 'face', 'of', 'the', 'tiger'], 3), rhyme=\"tiger\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate with prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('prompt2.txt','r')\n",
    "template = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1326], [1326], [72], [1326], [258], [732], [270], [18855], [732], [1326], [258]]\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "[[1326, 83], [1326, 46037], [72, 7174], [1326, 65], [258, 83], [732, 66], [270, 83], [18855, 28895], [732, 28895], [1326, 4529], [258, 9776]]\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "[[1326, 83, 505], [1326, 46037, 505], [72, 7174, 505], [1326, 65, 505], [258, 83, 505], [732, 66, 505], [270, 83, 505], [18855, 28895, 505], [732, 28895, 505], [1326, 4529, 505], [258, 9776, 505]]\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "[[1326, 83, 505, 1084], [1326, 46037, 505, 37330], [72, 7174, 505, 9979], [1326, 65, 505, 46037], [258, 83, 505, 9979], [732, 66, 505, 12001], [270, 83, 505, 1904], [18855, 28895, 505, 14664], [732, 28895, 505, 489], [1326, 4529, 505, 23913], [258, 9776, 505, 12543]]\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "[[1326, 83, 505, 1084, 85], [1326, 46037, 505, 37330, 28895], [72, 7174, 505, 9979, 22680], [1326, 65, 505, 46037, 19205], [258, 83, 505, 9979, 17319], [732, 66, 505, 12001, 28895], [270, 83, 505, 1904, 4853], [18855, 28895, 505, 14664, 86], [732, 28895, 505, 489, 28895], [1326, 4529, 505, 23913, 9688], [258, 9776, 505, 12543, 22932]]\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "[[1326, 83, 505, 1084, 85, 448], [1326, 46037, 505, 37330, 28895, 1659], [72, 7174, 505, 9979, 22680, 2502], [1326, 65, 505, 46037, 19205, 1525], [258, 83, 505, 9979, 17319, 6738], [732, 66, 505, 12001, 28895, 361], [270, 83, 505, 1904, 4853, 1659], [18855, 28895, 505, 14664, 86, 1640], [732, 28895, 505, 489, 28895, 13893], [1326, 4529, 505, 23913, 9688, 1525], [258, 9776, 505, 12543, 22932, 4480]]\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "[[1326, 83, 505, 1084, 85, 448, 5562], [1326, 46037, 505, 37330, 28895, 1659, 3919], [72, 7174, 505, 9979, 22680, 2502, 27218], [1326, 65, 505, 46037, 19205, 1525, 5562], [258, 83, 505, 9979, 17319, 6738, 5562], [732, 66, 505, 12001, 28895, 361, 25591], [270, 83, 505, 1904, 4853, 1659, 64], [18855, 28895, 505, 14664, 86, 1640, 27218], [732, 28895, 505, 489, 28895, 13893, 1169], [1326, 4529, 505, 23913, 9688, 1525, 64], [258, 9776, 505, 12543, 22932, 4480, 64]]\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "[[1326, 83, 505, 1084, 85, 448, 5562, 14261], [1326, 46037, 505, 37330, 28895, 1659, 3919, 29468], [72, 7174, 505, 9979, 22680, 2502, 27218, 2382], [1326, 65, 505, 46037, 19205, 1525, 5562, 29468], [258, 83, 505, 9979, 17319, 6738, 5562, 9509], [732, 66, 505, 12001, 28895, 361, 25591, 13424], [270, 83, 505, 1904, 4853, 1659, 64, 1904], [18855, 28895, 505, 14664, 86, 1640, 27218, 9979], [732, 28895, 505, 489, 28895, 13893, 1169, 31642], [1326, 4529, 505, 23913, 9688, 1525, 64, 33282], [258, 9776, 505, 12543, 22932, 4480, 64, 44460]]\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "[['me', 'took', 'one', 'minor', 'vocation', 'out', 'that', 'big', 'year'], ['me', 'interrupted', 'one', 'supreme', 'thought', 'of', 'no', 'daily', 'city'], ['i', 'called', 'one', 'constant', 'business', 'over', 'these', 'american', 'insult'], ['me', 'brought', 'one', 'interrupted', 'city', 'by', 'that', 'daily', 'way'], ['he', 'tried', 'one', 'constant', 'course', 'from', 'that', 'electrical', 'while'], ['we', 'came', 'one', 'local', 'thought', 'if', 'those', 'black', 'shift'], ['it', 'took', 'one', 'useful', 'equipment', 'of', 'a', 'useful', 'question'], ['them', 'thought', 'one', 'musical', 'wicked', 'for', 'these', 'constant', 'vocation'], ['we', 'thought', 'one', 'plush', 'thought', 'because', 'the', 'same', 'mission'], ['me', 'mailed', 'one', 'average', 'start', 'by', 'a', 'brown', 'equipment'], ['he', 'was', 'one', 'funny', 'guy', 'with', 'a', 'nice', 'car']]\n",
      "[-71.72274684906006, -84.4507827758789, -87.47336006164551, -77.24297523498535, -80.71968078613281, -83.54064512252808, -75.2580795288086, -76.95113897323608, -70.17250204086304, -83.5114426612854, -64.13277053833008]\n"
     ]
    }
   ],
   "source": [
    "lg.gen_line_with_template(template, (['PRP', 'VBD', 'CD', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'NN'], \n",
    "                                     ['he', 'was', 'one', 'funny', 'guy', 'with', 'a', 'nice', 'car'], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n",
      "[('he was one funny brit with a nice head of hair on his pate', -176.0026502609253)]\n"
     ]
    }
   ],
   "source": [
    "lg.gen_line_with_template(template, (['PRP', 'VBD', 'CD', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'NN', 'IN', 'NN', 'IN', 'PRP$', 'NN'], \n",
    "                                     ['he', 'was', 'one', 'funny', 'brit', 'with', 'a', 'nice', 'head', 'of', 'hair', 'on', 'his', 'pate'], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|        | 1/5 [00:06<00:25,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|      | 2/5 [00:11<00:18,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|    | 3/5 [00:17<00:11,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|  | 4/5 [00:23<00:05,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|| 5/5 [00:29<00:00,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-33.64236831665039:['it', 'could', 'read', 'to', 'the', 'universe']\n",
      "-37.41541051864624:['he', 'would', 'go', 'to', 'a', 'party']\n",
      "-37.79438257217407:['she', 'could', 'make', 'to', 'this', 're']\n",
      "-38.859190940856934:['me', 'shall', 'do', 'to', 'the', 'world']\n",
      "-38.904462575912476:['you', 'would', 'have', 'to', 'every', 'part']\n",
      "-39.291123390197754:['they', 'must', 'create', 'to', 'the', 'head']\n",
      "-39.50753688812256:['us', 'would', 'have', 'to', 'either', 'key']\n",
      "-39.595194816589355:['oftener', 'could', 'change', 'to', 'either', 'look']\n",
      "-40.514989376068115:['themselves', 'shouldnt', 'want', 'to', 'both', 'perspective']\n",
      "-40.55293893814087:['i', 'can', 'stare', 'at', 'the', 'sky']\n",
      "-40.98474740982056:['them', 'could', 'get', 'to', 'each', 'create']\n",
      "-40.98748826980591:['it', 'will', 'answer', 'to', 'that', 'joy']\n",
      "-41.257362842559814:['themselves', 'will', 'make', 'to', 'all', 'someone']\n",
      "-41.304943323135376:['itself', 'ought', 'read', 'to', 'the', 'something']\n",
      "-41.317829608917236:['self', 'shall', 'get', 'to', 'that', 'joy']\n",
      "-41.840683460235596:['self', 'will', 'read', 'to', 'any', 'part']\n",
      "-41.86216688156128:['itself', 'ought', 'look', 'to', 'this', 'object']\n",
      "-42.13162326812744:['i', 'couldnt', 'have', 'to', 'all', 'answer']\n",
      "-42.2010064125061:['she', 'shouldnt', 'read', 'to', 'no', 'right']\n",
      "-42.223740100860596:['meltst', 'shouldnt', 'read', 'to', 'any', 'key']\n",
      "-42.31282567977905:['himself', 'dare', 'answer', 'to', 'both', 'world']\n",
      "-42.403303146362305:['herself', 'could', 'do', 'to', 'each', 'understood']\n",
      "-42.44603967666626:['me', 'couldnt', 'see', 'to', 'every', 'love']\n",
      "-42.65145015716553:['yourself', 'shouldnt', 'see', 'to', 'any', 'mind']\n",
      "-42.68892478942871:['massacred', 'shouldnt', 'read', 'to', 'all', 'nature']\n",
      "-43.08396530151367:['themselves', 'dare', 'get', 'to', 'those', 'someone']\n",
      "-43.51232147216797:['yourself', 'shall', 'look', 'to', 'such', 'object']\n",
      "-43.79765319824219:['thyself', 'might', 'look', 'to', 'that', 'nothing']\n",
      "-43.93553352355957:['onesself', 'would', 'do', 'to', 'these', 'luck']\n",
      "-44.05070638656616:['handfuls', 'cannot', 'realize', 'to', 'this', 'object']\n",
      "-44.1845645904541:['itself', 'ought', 'be', 'to', 'a', 'place']\n",
      "-44.35441732406616:['she', 'need', 'have', 'to', 'those', 'world']\n",
      "-44.52108573913574:['overthrow', 'may', 'feel', 'to', 'that', 'kindness']\n",
      "-44.54827404022217:['they', 'dare', 'know', 'to', 'that', 'someone']\n",
      "-44.77217674255371:['me', 'shouldnt', 'make', 'to', 'either', 'head']\n",
      "-44.9534478187561:['they', 'may', 'have', 'to', 'no', 'everyone']\n",
      "-45.041504859924316:['yourself', 'could', 'create', 'to', 'an', 'friendship']\n",
      "-45.098647594451904:['handfuls', 'shall', 'know', 'to', 'both', 'kind']\n",
      "-45.13144874572754:['i', 'may', 'change', 'to', 'that', 'change']\n",
      "-45.14540910720825:['he', 'would', 'look', 'to', 'an', 'share']\n",
      "-45.271042823791504:['us', 'might', 'make', 'to', 'neither', 'joy']\n",
      "-45.50499963760376:['yelps', 'will', 'know', 'to', 'another', 'key']\n",
      "-45.84663486480713:['elf', 'shall', 're', 'to', 'the', 'look']\n",
      "-45.968549728393555:['him', 'dare', 'feel', 'to', 'a', 'kindness']\n",
      "-46.05663013458252:['ye', 'will', 'see', 'to', 'some', 'thought']\n",
      "-46.13122606277466:['yelps', 'can', 'be', 'to', 'all', 'head']\n",
      "-46.2157564163208:['ye', 'couldnt', 'feel', 'to', 'neither', 'meant']\n",
      "-46.24919605255127:['they', 'couldnt', 'realize', 'to', 'each', 'thought']\n",
      "-46.40546894073486:['it', 'cannot', 'see', 'to', 'that', 'object']\n",
      "-46.50616121292114:['you', 'cannot', 'look', 'to', 'each', 'answer']\n",
      "-46.782352447509766:['overthrow', 'shouldnt', 'look', 'to', 'either', 'question']\n",
      "-47.02110147476196:['meltst', 'must', 'get', 'to', 'this', 'luck']\n",
      "-47.06746768951416:['him', 'can', 'have', 'to', 'those', 'object']\n",
      "-47.08656597137451:['meltst', 'would', 'create', 'to', 'another', 'nothing']\n",
      "-47.32706594467163:['massacred', 'need', 're', 'to', 'either', 'friendship']\n",
      "-47.383381366729736:['handfuls', 'cannot', 'create', 'to', 'both', 'friendship']\n",
      "-47.40849232673645:['i', 'shall', 'want', 'to', 'either', 'someone']\n",
      "-47.463990211486816:['you', 'can', 'object', 'to', 'those', 'kindness']\n",
      "-47.72133445739746:['ont', 'ought', 'see', 'to', 'an', 'friendship']\n",
      "-47.87050533294678:['himself', 'dare', 'know', 'to', 'half', 'mind']\n",
      "-47.93333196640015:['thyself', 'will', 'read', 'to', 'no', 'part']\n",
      "-48.37499809265137:['them', 'ought', 'create', 'to', 'every', 'object']\n",
      "-48.43808650970459:['me', 'will', 'object', 'to', 'any', 'question']\n",
      "-48.50966787338257:['you', 'need', 'have', 'to', 'these', 'everyone']\n",
      "-48.697081565856934:['meltst', 'might', 'change', 'to', 'both', 'something']\n",
      "-48.89209771156311:['onesself', 'need', 'want', 'to', 'these', 'nothing']\n",
      "-48.89372682571411:['we', 'dare', 'be', 'to', 'either', 'mind']\n",
      "-48.90936231613159:['me', 'may', 're', 'to', 'these', 'meaning']\n",
      "-48.98923301696777:['it', 'can', 'object', 'to', 'both', 'create']\n",
      "-49.0537314414978:['itself', 'ought', 'object', 'to', 'another', 'answer']\n",
      "-49.080400466918945:['elf', 'shall', 're', 'to', 'any', 'key']\n",
      "-49.16201734542847:['yourself', 'ought', 'create', 'to', 'both', 'head']\n",
      "-49.20561408996582:['myself', 'could', 'perspective', 'to', 'an', 'kind']\n",
      "-49.309041023254395:['wither', 'will', 'do', 'to', 'some', 'create']\n",
      "-49.42597198486328:['theirs', 'ought', 'look', 'to', 'neither', 'compassion']\n",
      "-49.512078285217285:['we', 'cannot', 'perspective', 'to', 'another', 'compassion']\n",
      "-49.572465896606445:['mantelshelf', 'may', 're', 'to', 'each', 'look']\n",
      "-49.969780921936035:['theirs', 'may', 'perspective', 'to', 'the', 'thought']\n",
      "-50.05227088928223:['himself', 'may', 'feel', 'to', 'half', 'something']\n",
      "-50.07360601425171:['he', 'may', 'object', 'to', 'this', 'sense']\n",
      "-50.110952377319336:['herself', 'cannot', 'perspective', 'to', 'this', 'perspective']\n",
      "-50.390286445617676:['mantelshelf', 'shall', 'do', 'to', 'either', 'meant']\n",
      "-50.51639938354492:['overthrow', 'shall', 'object', 'to', 'those', 'thought']\n",
      "-50.551188468933105:['herself', 'shouldnt', 'create', 'to', 'no', 'right']\n",
      "-50.56462478637695:['ye', 'shall', 'know', 'to', 'this', 'everyone']\n",
      "-50.61376953125:['onesself', 'shall', 'do', 'to', 'no', 'meaning']\n",
      "-50.62317132949829:['himself', 'must', 'realize', 'to', 'each', 'create']\n",
      "-51.0150032043457:['ye', 'will', 'create', 'to', 'such', 'thought']\n",
      "-51.46578598022461:['themselves', 'shall', 'object', 'to', 'some', 'acceptance']\n",
      "-51.476492404937744:['oftener', 'ought', 're', 'to', 'both', 'thought']\n",
      "-51.75570297241211:['mantelshelf', 'may', 'make', 'to', 'either', 'spirit']\n",
      "-51.868536949157715:['us', 'ought', 'object', 'to', 'every', 'someone']\n",
      "-52.84356117248535:['ont', 'shall', 'read', 'to', 'no', 'spirit']\n",
      "-53.09879684448242:['himself', 'will', 'perspective', 'to', 'every', 'look']\n",
      "-54.41274547576904:['ont', 'ought', 're', 'to', 'those', 'change']\n",
      "-54.6750431060791:['massacred', 'must', 'realize', 'to', 'each', 'luck']\n",
      "-54.75090456008911:['i', 'ought', 'create', 'to', 'each', 'joy']\n",
      "-55.006789207458496:['us', 'ought', 'perspective', 'to', 'any', 'create']\n",
      "-56.020450592041016:['ye', 'may', 'realize', 'to', 'no', 'place']\n",
      "-56.20230579376221:['overthrow', 'shall', 'perspective', 'to', 'those', 'power']\n",
      "-56.75651454925537:['yelps', 'might', 'perspective', 'to', 'this', 'friendship']\n",
      "-58.6817512512207:['theirs', 'shall', 'perspective', 'to', 'every', 'share']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lg.gen_line_with_template(template,['PRP', 'MD', 'VB', 'TO','DT', 'NN'],100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate First Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['010']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.dict_meters['idea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_files.Limericks import Limerick_Generate\n",
    "lg = Limerick_Generate(model_name='117M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'was', 'a', 'bright', 'person', 'named', 'mary']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['who', 'spent', 'years', 'as', 'a', 'loan']\n",
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from gpt2/models/117M/model.ckpt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-179833ad824d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                           \u001b[0;34m[\u001b[0m\u001b[0;34m'IN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'JJ'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                           \u001b[0;34m[\u001b[0m\u001b[0;34m'CC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VBD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'IN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'JJ'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                          ],enforce_syllables = False, enforce_stress = True)\n\u001b[0m",
      "\u001b[0;32m~/Desktop/poetix/py_files/Limericks.py\u001b[0m in \u001b[0;36mgen_poem_gpt\u001b[0;34m(self, rhyme1, rhyme2, default_templates, story_line, prompt_length, save_as_pickle, search_space, enforce_syllables, enforce_stress)\u001b[0m\n\u001b[1;32m   1479\u001b[0m                 \u001b[0msearch_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_space\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msearch_space_coef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m                 num_sylls = curr_sylls, stress=stress)\n\u001b[0;32m-> 1481\u001b[0;31m             \u001b[0mprompt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgen_line_with_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/poetix/py_files/Limericks.py\u001b[0m in \u001b[0;36mgen_line_gpt\u001b[0;34m(self, w, encodes, default_template, rhyme_word, rhyme_set, search_space, num_sylls, stress, use_nltk)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;31m# Logits is the output of GPT model, encoder is used to decode the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mPOS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/poetix/gpt2/src/score.py\u001b[0m in \u001b[0;36mscore_model\u001b[0;34m(model_name, seed, nsamples, length, temperature, top_k, context_token)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         out = sess.run(logits, feed_dict={\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontext_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         })\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "poem = lg.gen_poem_gpt(\"mary\", \"mary\",\n",
    "                       prompt_length=100, search_space=50, story_line=True,\n",
    "                       default_templates=[['WHO', 'VBD', 'NNS', 'IN', 'DT', 'NN'],\n",
    "                                          ['PRP', 'VBD', 'DT', 'NN'],\n",
    "                                          ['IN', 'DT', 'JJ', 'NN'],\n",
    "                                          ['CC', 'VBD', 'IN', 'DT', 'JJ', 'NN']\n",
    "                                         ],enforce_syllables = False, enforce_stress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['there', 'was', 'a', 'kind', 'lady', 'named', 'mary']\n",
    ",['who', 'was', 'friends', 'with', 'a', 'loan']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
