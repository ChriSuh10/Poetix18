{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generated_line_dictionary(in_paths, poem_type):\n",
    "    lines = {'keyword': [],\n",
    "             'line1': [],\n",
    "             'line2': [],\n",
    "             'line3': [],\n",
    "             'line4': [],\n",
    "             'line5': [],\n",
    "             'score': []}\n",
    "    for in_path in in_paths:\n",
    "        in_txt = open(in_path, 'rb')\n",
    "\n",
    "        counter = 0\n",
    "        curr_keyword = None\n",
    "        # We only write to csv if it is the first poem in the \n",
    "        should_write_to_csv = False\n",
    "        for line in in_txt:\n",
    "            line = line.rstrip().decode('utf-8')\n",
    "            # Process keyword\n",
    "            if len(line.split(':')) == 2:\n",
    "                new_keyword, score = line.split(':')\n",
    "                if new_keyword != curr_keyword:\n",
    "                    should_write_to_csv = True\n",
    "                    lines['keyword'].append(new_keyword)\n",
    "                    lines['score'].append(score)\n",
    "                else:\n",
    "                    should_write_to_csv = False\n",
    "                curr_keyword = new_keyword\n",
    "            # Write line to dictionary\n",
    "            elif len(line) >= 5 and should_write_to_csv:\n",
    "                # Process line\n",
    "                line = line.strip()\n",
    "                line = line[0].upper() + line[1:]\n",
    "                if not line[-1].isalpha():\n",
    "                    line = ' '.join(line.split()[:-1]) + line[-1]\n",
    "                lines['line' + str(counter+1)].append(line)\n",
    "                counter += 1\n",
    "                counter %= 5\n",
    "    poem_count = len(lines['line1'])\n",
    "    lines['type'] = [poem_type] * poem_count\n",
    "    print(\"Dictionary created with \" + str(poem_count) + \" poems\")\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_line_dictionary(in_paths, poem_type):\n",
    "    lines = {'line1': [],\n",
    "             'line2': [],\n",
    "             'line3': [],\n",
    "             'line4': [],\n",
    "             'line5': []}\n",
    "    for in_path in in_paths:\n",
    "        in_txt = open(in_path, 'rb')\n",
    "\n",
    "        counter = 0\n",
    "        for line in in_txt:\n",
    "            line = line.rstrip().decode('utf-8')\n",
    "            if len(line) < 5 or len(line.split()) == 1:\n",
    "                continue\n",
    "            lines['line' + str(counter+1)].append(line)\n",
    "            counter += 1\n",
    "            counter %= 5\n",
    "    poem_count = len(lines['line1'])\n",
    "    lines['type'] = [poem_type] * poem_count\n",
    "    print(\"Dictionary created with \" + str(poem_count) + \" poems\")\n",
    "    return lines\n",
    "\n",
    "def print_single_poem(poem_dict, index):\n",
    "    for key in poem_dict:\n",
    "        print(poem_dict[key][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary created with 87 poems\n",
      "Dictionary created with 59 poems\n",
      "Dictionary created with 51 poems\n",
      "Dictionary created with 58 poems\n",
      "Dictionary created with 60 poems\n",
      "Dictionary created with 48 poems\n",
      "------EXAMPLE------\n",
      "There was a lively man named Clyde\n",
      "Who stayed a long time on our side.\n",
      "He came back from the sea,\n",
      "He was able to see,\n",
      "He saw through the clouds and looked outside.\n",
      "GENERATED\n"
     ]
    }
   ],
   "source": [
    "HUMAN = create_line_dictionary(['py_files/saved_objects/limericks.txt'], 'HUMAN')\n",
    "DTS_NO_STORY = create_generated_line_dictionary(['new_final_testing_DTS_no_story1/25_30_0.1_multi_True_no_story.txt'], 'DTS_NO_STORY')\n",
    "DTS_STORY = create_generated_line_dictionary(['new_final_testing_DTS_storyline1/25_30_0.1_multi_True_original.txt'], 'DTS_STORY')\n",
    "SINGLE_NO_STORY = create_generated_line_dictionary(['final_testing_single_no_story1/20_30_0.1_5_True_no_story.txt'], 'SINGLE_NO_STORY')\n",
    "SINGLE_STORY = create_generated_line_dictionary(['new_final_testing_single_no_story3/25_30_0.1_single_True_no_story.txt'], 'SINGLE_STORY')\n",
    "BEST_GENERATED_POEM = create_line_dictionary(['py_files/saved_objects/curated_poems.txt'], 'GENERATED')\n",
    "\n",
    "print(\"------EXAMPLE------\")\n",
    "print_single_poem(BEST_GENERATED_POEM, 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poem_list(dictionary, index, batch):\n",
    "    return [[dictionary[key][i] for key in dictionary] for i in range(index, index + batch)]\n",
    "\n",
    "def export_poetic_measure_experiment(batch, DTS_NO_STORY, DTS_STORY, SINGLE_NO_STORY, SINGLE_STORY, name=\"\"):\n",
    "    length = min(len(DTS_NO_STORY['line1']), len(DTS_STORY['line1']), len(SINGLE_NO_STORY['line1']), len(SINGLE_STORY['line1']))\n",
    "    index = 0\n",
    "    while index + batch <= length:\n",
    "        poem_list = get_poem_list(DTS_NO_STORY, index, batch) + get_poem_list(DTS_STORY, index, batch) + \\\n",
    "                    get_poem_list(SINGLE_NO_STORY, index, batch) + get_poem_list(SINGLE_STORY, index, batch)\n",
    "        random.shuffle(poem_list)\n",
    "        index += batch\n",
    "        out_path = 'csv/poetic_measure_'+ name + str(int(index/batch)) + '.csv'\n",
    "        df = DataFrame(poem_list, columns= ['keyword', 'line1', 'line2', 'line3', 'line4', 'line5', 'score', 'type'])\n",
    "        export_csv = df.to_csv (out_path, index = None, header=True)\n",
    "\n",
    "def export_turing_test_experiment(batch, HUMAN, GENERATED, name=\"\"):\n",
    "    length = min(len(HUMAN['line1']), len(GENERATED['line1']))\n",
    "    index = 0\n",
    "    while index + batch <= length:\n",
    "        poem_list = get_poem_list(HUMAN, index, batch) + get_poem_list(GENERATED, index, batch)\n",
    "        random.shuffle(poem_list)\n",
    "        index += batch\n",
    "        out_path = 'csv/turing_test_'+ name + str(int(index/batch)) + '.csv'\n",
    "        df = DataFrame(poem_list, columns= ['line1', 'line2', 'line3', 'line4', 'line5', 'type'])\n",
    "        export_csv = df.to_csv (out_path, index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_poetic_measure_experiment(5, DTS_NO_STORY, DTS_STORY, SINGLE_NO_STORY, SINGLE_STORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_turing_test_experiment(5, HUMAN, BEST_GENERATED_POEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = min(len(DTS_NO_STORY['line1']), len(DTS_STORY['line1']), len(SINGLE_NO_STORY['line1']), len(SINGLE_STORY['line1']))\n",
    "export_poetic_measure_experiment(length, DTS_NO_STORY, DTS_STORY, SINGLE_NO_STORY, SINGLE_STORY, \"complete_\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
